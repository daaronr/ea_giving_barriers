# Barriers: Signaling and social pressures/social identity {#social}

## Signaling concern for effectiveness/impact versus other values

### Theory and argument
Social signaling is seen to be a major driver of human behavior,  particularly in the charitable domain. ^[REF] Essentially, we may make choices that we would not have otherwise made in order to boost our reputation among our peers, colleagues, etc.. Reputation may be valued for its own sake or instrumentally, as a means  to inducing others to act more favorably to us. Game theory (see esp. [@Spence1973]) offers a precise conception of this signaling as a costly way to demonstrate one's positive "type"  in a context with asndymmetric information.

Several authors (can be interpreted to) suggest that valuing ''effectiveness in generosity'', i.e., moral-utilitarianism, is seen as a negative signal by peers and lowers fitness in the cooperation market, at least in comparison to signaling compared to deontological or ‘sacred values’. The exchange below captures the basic argument... 

```{block2,  type='note'}

*From Robin Hanson and Rob Wiblin exchange on 80000 hours podcast; see Chapter 12 of   “The Elephant in the Brain” (Hanson)*
\


Hanson: But of course people spend a lot of time directly helping even when they’re relatively well-paid and they could pay other people who earn much lower wages to do a lot more.

\

Wiblin: This is the example of the high-flying lawyer dishing out soup in a soup kitchen.

\

Hanson: ... the alternative theory that we suggest is that you are trying to show that you feel empathy. That is you want to show there is an emotional capacity in you such that if you see someone around you in need you will feel like you want to do something about that. And existing charities do tend to successful show that. They show somebody who needs help in a direct way that invokes your emotions and you do help to some degree, you do the thing that people would say would help and that shows people around you that you’re not an uncaring person and it might show them, for example, that if they were in need of help later and they were near you you would see them and you would feel about them too. You want to show people that you will be useful ally. If either of you is in trouble the other will come to their aid.

\

Wiblin: So why is it more important to show the people that you’re the kind of person who if they someone in pain that they’re going to try to help them right then and there than to show that you’re the kind of person who’s smart enough to think about which charities are useful and does their research and actually tries to help people? Because if you don’t care about whether charities are effective or not, my thoughts would just be that you’re not really going to pay attention to whether you’re actually helping your friends or not?

\
Hanson: Right, but at least if I want your help and I’m your friend it will be my job to put myself in your face and to tell you about my problem. And maybe I figure I coul successfully get myself in front of your face and make you pay attention to my problem and help you understand what I think is effective and then you would just do what I say, and that’s maybe what I’m mostly hoping for. And if you were this person who thinks carefully about how to help the best person in the world who needs help, well I’m plausibly not going to be that best person in the world who needs help so I’m not going to win out in that contest so it’s not actually going to be that useful to know you as the sort of person who will help the person in the world who needs the most help.

```  


[@everettInferenceTrustworthinessIntuitive2016] argue that deontological ethics signal stable cooperative behavior to others, which enhances fitness in mutualistic partner choice models. The basic argument is "An individual who claims [and believes] that stealing is always morally wrong ... seems much less likely to steal from me than an individual who believes that the stealing is sometimes morally acceptable depending on the consequences."



Background and further discussion ... in fold
```{block2,  type='fold'}

The authors' motivation is to explore why "intuitive moral judgments often "share characteristics with deontological theories while  "consequentialist judgments are often the result of slow, deliberative cognitive processes". Their key theoretical argument cites "mutualistic partner choice models of the evolution of morality", which...

> posit a cooperation market such that agents who can be relied upon to act in a mutually beneficial way are more likely to be chosen as cooperation partners, thus increasing their own fitness

> the typical deontological reason for why specific actions are wrong is that they violate duties to respect persons and honor social obligations-features that are crucial when selecting a social partner. An individual who claims that stealing is always morally wrong and believes themselves morally obligated to act in accordance with this duty seems much less likely to steal from me than an individual who believes that the stealing is sometimes morally acceptable depending on the consequences. Actors who express characteristically deontological judgments may therefore be preferred to those expressing consequentialist judgments because these judgments may be more reliable indicators of stable cooperative behavior.

> And recent theoretical work has demonstrated that -"cooperating without looking”—that is, without considering the costs and benefits of cooperation—is a subgame perfect equilibrium (Hoffman, Yoeli, & Nowak, 2015). Therefore, expressing characteristically deontological judgments could constitute a behavior that enhances individual fitness in a cooperation market because these judgments are seen as reliable indicators of a specific valued behavior-cooperation.

```

Hoffman et al (2015) present an evolutionary game theoretic analysis of an indefinitely repeated game where 

<div class="marginnote">
Here the analogy to effective versus ineffective giving is not clear...
</div>
 
- Player 1 can publicly 'look' to see the cost of cooperation,
- Player 1 next chooses to cooperate or defect, and then  
- Player 2 chooses whether to continue repeating the above game, or end the relationship. 

They provide conditions under which 'cooperating without looking' (CWOL) is part of a subgame-perfect Nash equilibrium, and an evolutionarily stable equilibrium can involve a substantial rate of CWOL play.

However, the analogy to effective versus ineffective giving is not clear. Perhaps a connection could be made *if considering the charity effectiveness tended to provide a motivation to give less*, but this is not obviously the case.  In general, an 'excuse not to do something' is not the same as a 'choice to be effective'.


### Evidence 

### Evidence that "consequentialist choices lead to negative signals and less-favorable treatment relative to deontological/emotionally intuitive choices "

**[@everettInferenceTrustworthinessIntuitive2016]**

@everettInferenceTrustworthinessIntuitive2016 ran a series of experiments on the Mturk platform, involving hypothetical dilemmas paired with low-stakes (or no) Trust games.
In each, participants were asked to make and justify their judgement in a moral dillemma such as the famous 'trolley dillemma.' In each case, this was a (hypothetical) choice between inaction and taking an action that sacrifices a small number of lives to save a larger number of lives. 

<div class="marginnote">
Would you "push a man off a footbridge to stop an oncoming train from hitting five"?
</div>
 
> We then had our participants rate the morality and trustworthiness of each agent on a scale (Study 1a), play a hypothetical trust game (TG) with the agents (Study 1b), and, finally, play a TG involving real monetary stakes with the agents (Study

Across several studies deontologist agents were preferred in partner choices by participants endorsing the same values; even moral-utilitarians seem to favor peers who express emotional empathy and deontological ethics (ibid.,  p. 45). 

However, this difference was not present in the track-switching dilemma, the only dilemma in which a majority favored the consequentialist choice.

#### Considerations 

Even if we accept the above evidence (that those who make consequentialist active choices in "sacrificial dilemmas" are seen as less trustworthy and less moral) this may not generalize to *effective giving*. Researching and selecting a more effective charity is closest to the 'track switching' scenario in these experiments, in which no substantial difference was observed, and even here it is a stretch. Choosing a more effective charity instead of a more local one (e.g., river blindess prevention in Africa versus local guide Dogs) would be hard to cast seen as taking an active step to *harm someone*. 

<div class="marginnote">
True, a local blind person may fail to get an additional (fraction of a) dog as a result of this choice. However, there is little sense in which "you funding his dog" would be seen as the status quo absent your intervention.  
</div>
 
### Indirect evidence

(Kahane et al 2018; Jordan et al; Hoffman et al)



