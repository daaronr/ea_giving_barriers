# Barriers: Quantitative biases {#quant-biases}


## Biases in perceiving impact

Cognitive biases: Overweighting and underweighting probabilities, misunderstanding marginality, scope-insensitivity, Opportunity-cost Neglect. etc. Identifiable victims effect.

<!-- Responses: De-biasing, etc. -->

small2007sympathy_s3_s4, Gneezy2014, small2007sympathy_s1_s2

kogut2005identified, kogut_2005b, Kinsbergen_tolsma_13, summers_1997, galanter_1962

## Other  biases driving departures from efficiency


## Proportional dominance effect {#prop-dom}

<div class="marginnote">
AKA 'drop in the bucket', 'psychosocial numbing', 'psychophysical numbing'
</div>


Proportional dominance effect/drop in bucket/psychosocial numbing/psychophysical numbing	2.7 Quantitative biases


<!-- See also (Ari's writeup
[[HERE]{.underline}](https://docs.google.com/document/d/1zzGTkF5sZnDUtzE-NS3sYOHOLQw8eDxC5Qt3_Wy62wA/edit#heading=h.r4qi0rwohl6r)) -->

### Definition

Related Terms include:   Drop in the bucket; mechanisms include "futility thinking" (Unger?), psychosocial numbing, quantitative confusion/innumeracy


<!-- *1-4 sentence description/definition of the barrier* -->

This claim can be summarized as follows: 

(For a given per-dollar impact on the outcome), people are be less
willing to donate towards a cause when the magnitude of the underlying
problem is (framed as) larger. 

Mechanism: Underlying this is the idea that a certain amount of impact (e.g., relieving suffering) is perceived as smaller and thus less valuable when the underlying problem is larger.

### Conceptual Discussion

<div class="marginnote">
Overview of findings from papers, caveats, how the concept works, etc. Provides context for evidence section; Discussion of the relevant mechanisms at play; Discussion of the relevant established theories.
</div>


*[Definitional issues and disambiguation]{.underline}*

This needs to be distinguished from scope insensitivity. Note that if people are being analytical, they must *care* about scope in order to care about their impact, and thus (mistakenly) react to the perceived lower impact of donating when the needs are much greater. 
PD arguments may also be used as vehicle for motivated reasoning, and thus not be an important driver in itself: E.g., I don't want to donate so I focus on my impact being a share of the overwhelming need (which I might opportunistically define broadly) to conclude that helping is futile.

Note (unfold)...

```{block2,  type='fold'}

BG:  My thought was that people who do not value saving lives (or are in general unwilling to contribute to it or oppose policies spending money on foreign aid for some other reason, e.g. prejudice) exercise a form of motivated reasoning to justify this (perhaps in a nonstandard way). They choose to reason according to the 'proportional' standard in order to conclude that it is not worth mdonating to these causes because 'the scope of the problem is too large and they will never be completely solved'. I suggest that people apply this reasoning to problems specifically when they do not want to take action to address these problems. (In contrast, in domains where they do want to make a change, they may use a different, more marginal and \'consistent\' sort of reasoning.) E.g., (to be stereotypical) imagine a MAGA person who wants to end foreign aid because \"Africa will always have endless problems\" but who wants to impose restrictions on abortion (even knowing millions of abortions will continue to occur) because \"every unborn life matters. 
```

To operationalize this, we need to define what the numerator and denominator represent. For the numerator, an (EA) impact-driven individualist donor might consider of her *own* contribution (per dollar or overall) relative to the size of the need. In contrast, a more collectivist/team-reasoning/communitarian thinker might consider the impact of the *total* expected donation relative to the size of the need. We also need to better define the denominator; how do individuals lump together different groups/problems to define the overall scale of the need, and how sensitive is this to the fundraisers' framing? 
*[Mechanisms]{.underline}*

Fetherstonhaugh et al (1997) highlight "Weber's law": Humans are sensitive to proportional changes/proportional differences in stimuli (loudness, brightness, etc); thus we are less sensitive to small changes relative to a larger baseline. There is evidence this also holds in assessing losses of life. \... the "subjective value of saving the specified number of lives is greater for a smaller tragedy than for a larger one" . 

Baron attributes PD to quantity confusion and classifies this as "contamination by an irrelevant factor"; more generally, this could be seen in terms of *innumeracy*. 

This may lead to a lower willingness to contribute to a problem when the apparent scale (or "denominator") of the problem is larger (e.g., more lives at risk), holding constant the benefit per dollar contributed (cost per life saved). The *perceived* scale of the problem may depend on how it is framed by fundraisers, charities, and the media. However, this may not be completely manipulable: e.g., massive global problems may not be easy to "frame down." 
"Loewenstein and Small (2007) suggested that the PDE is driven by
increased sympathy towards the victims when one can help a large
proportion of the victim reference-group." \-- Erlandsson et al

### EG Relevance

<div class="marginnote">
How this particular barrier proves problematic for effective giving.
</div>

This effect represents a general departure from appropriate assessment of the marginal benefit (per cost) of a particular charity/intervention. Thus this is a general barrier to accurate assessment of effectiveness ergo a barrier to effective giving. 

In addition, it might be argued that more effective interventions (e.g., targeting poor Africans versus US poverty) may tend to address problems that are inherently larger in scale and magnitude. These may be intrinsically harder to "frame down", implying EG will suffer more from this bias. 

### State of Evidence

<div class="marginnote">
Key papers: Summarize findings and key takeaways, Short description of
methods for relevant studies, Make sure to include both description of
evidence and evaluation of evidence
</div>

**Fetherstonhaugh et al 1997** (notes
[[HERE]{.underline}](https://docs.google.com/document/d/1YHaF4phpqthCEwwNdgd_QBZp5np0pHwHEJm3U2G1cxA/edit#heading=h.8ax2rgfz70of))

[Methods]{.underline}

Range of hypothetical scenariae and evaluations, within-subject
manipulations only (with clear contrasts), framed as aid/targeting not
charitable donations, standard (mostly Economics) student subject pools.

These authors conducted survey experiments on standard (fairly small
sample?) student participants. They presented a variety of hypothetical
scenariae (e.g., "imagine themselves as a government official of a
small, developing country"\...), asking for ratings, rankings, etc.

\
**Findings**

> Studies 1 and 2 found that an intervention saving a fixed number of
lives was judged significantly more beneficial when fewer lives were at
risk overall. Study 3 found that respondents wanted the minimum number
of lives a medical treatment would have to save to merit a fixed amount
of funding to be much greater for a disease with a larger number of
potential victims than for a disease with a smaller number.


**Evaluation of paper's evidence:*]{.underline}**

Strengths - Reasonably realistic frames, (mostly) consistent results
across a variety of frames

Limitations - Hypothetical, framed, nonrepresentative, and does not
directly address *own* contributions

Within-subject treatments here:

(+) allow estimation of heterogeneous responses,

(+/-) highlight the difference in denominators/proportions, making them
salient; but this might also be expected to be an inhibitor of this
(seemingly non-rational) effect, especially for the Economics-trained
sample

Statistical tests (ANOVA) appear strong and highly significant in most
cases, but further investigation warranted (e.g., pre-registration?
Evidence of specification fishing and MHT?)

**Erlansson et al (2015)**

(Study 4)

> The PDE-ad was in part based on text from the homepage of a
> well-known global charity organization focusing on poverty in
> developing countries. Participants read about Polio and were told that
> if receiving the expected amount of private donations, it would be
> possible to vaccinate children so the death rate would decrease by
> approximately 500 children per year. In the large reference-group
> version, participants read that 60,000 children in Africa annually die
> from Polio so the project had a potential rescue proportion of 0.83%.
> In the small reference-group version, partici pants read that around
> 500 children in Botswana annually die from Polio so the project had a
> potential rescue proportion of more than 99%.
>
> \...followed by eight questions about participants' reactions towards
> the advertisement. The suggested mediators (distress, sympathy,
> perceived impact and perceived responsibility) were measured with two
> questions each
>
> \...after reading and responding to the three ads, participants were
> told that thanks to their participation, 10 Swedish Kronor (SEK)
> (1.50 USD) would be donated to charity. The participants were asked to
> allocate the money between the three organizations by writing an
> amount (0--10) after each ad and the sum had to be 10 SEK
>
> \...All participants read either one ad from the low end of the
> effects (statistical victim, large reference-group, out-group victims)
> plus two ads from the high end of the effects (identified victim,
> small reference-group, in-group victims) or two ads from the low end
> plus one ad from the high end.
>
> [Results]
>
> Participants who read the PDE-ad in the small reference-group version
> had higher helping intentions (M = 3.77, SD = 1.64) than participants
> who read the large reference-group version, M = 3.46, SD = 1.57;
> t(430) = 2.01, p = .045. However, participants who read the small
> reference-group version did not write that they would donate more
> money if asked (Mean rank = 213.68) than participants who read the
> large reference-group version (Mean rank = 218.31; Mann--Whitney U =
> 22720.50, Z = 0.40, p = .686). Despite this, participants who read the
> small reference-group version allocated more money to the organization
> distributing Polio- vaccines (M = 4.30 SEK, SD = 2.85) than the
> participants who read the large reference-group version, M = 3.50 SEK,
> SD = 2.87; t(430) = 2.91, p = .004. Although not perfectly consistent
> between the different outcome variables, the results suggest that we
> replicated the PDE.

[Evaluation of evidence (Study 4):]{.underline}

Strengths - Realistic charity frame, reasonable implementation of
small/large "reference group" frames, outcomes record both
intentional/attitudinal and actual (small) donation measures

Limitations - A choice *among* charities only

Statistical tests -

**[Brief on tangential papers (non charity) and papers supporting the
mechanism]{.underline}**

**Baron, 1997: "Confusion of Relative and Absolute Risk in Valuation"**

[Methods]{.underline}

Hypothetical willingness to pay (wtp) questions. Within-subject
manipulations only; standard student subject pools, small samples.

<div class="marginnote">
They do reverse order of presentations for half the participants.
  They report a lack of significant order effects, but fail to discuss
  the power of such tests or examine first-presented choices in
  isolation.
</div>


S1: Questions about (hypothetical wtp for components of government
government health insurance. "[Denominator] people die from this
disease each year. Their average age is 60. How much are you willing to
pay to cover a treatment that will save the lives of [Numerator] of
these people?"... (Numerator=90 or 900; Denominator=100, 1000, or
10,000), all combinations presented to all participants.

S2: Set of causes, each gave wtp for a government program for a 5%
reduction in that cause of death and for saving 2,600 lives, also rating
prevalence and importance. He reports a very high correlation between
wtp by these two measures, an "insensitivity to quantity", and both wtp
measures are higher when subjects report a higher prevalence (even
controlling for stated importance).

[Evaluation of paper's evidence]{.underline}: This evidence appears
highly limited. There is some evidence that denominators matter when
they (arguably) should not, and participants show confusion between
proportions and absolute amounts. The second experiment is highly
cognitively demanding and participants have no strong incentive to "get
this right." The first experiment has arguable confounds: e.g., one
might question the scientific credibility of the treatment that (claims
to) save only a small number of lives out of a very large population.
The evidence does not seem to offer much strength over and above the
Fetherstonhaugh paper. I also found much of the statistical reporting to
be incomplete or unclear, especially for study two. In general, this is,
at its best, evidence of quantitative confusion which may go in either
direction in any given context.

It is also detached from the charity realm, considering the domain of
government expenditure and benefits that will accrue to the participant
him or herself. For this reason, I listed it is tangential evidence and
not charity specific evidence.

**Jenni and Loewenstein (1997)** Provides support for the "reference
group effect" (proportional dominance) as an explanation for the
identifiable victims bias. (notes
[[HERE]{.underline}](https://docs.google.com/document/d/1YHaF4phpqthCEwwNdgd_QBZp5np0pHwHEJm3U2G1cxA/edit#))

**Friedrich et al (2008)**

> PN was investigated by varying the supposed number of brak-
ing-related traffic fatalities each year as a within-subjects variable
and then obtain- ingjudgments of support for a new antilock brake
requirement.

> Experiment 1 manipulated respondents' accountability ["...the
experimenter will ask you at this time to explain the reasoning behind
your decisions and to justify how you arrived at your recommendations"]
as a way of exploring whether PN responding is the result of careless or
heuristic processing. Extensive work with accountability manipulations
has shown them to be effective in debiasing... [other stuff]. ...
when they expect to have to justify their reason- ing to others, should
also be revealing in terms of what they believe constitutes a
defensible, normative strategy.

> [also] a manipulation designed to highlight the salience of the
individual lives at risk ... [a] description of a preventable, fatal
accident with named individuals...

> , par- ticipants read that the "Federal Transportation Board"
estimated annual fatalities due to driver error in the use of
conventional braking systems to be approximately 41,000 ("large
problem") or 9,000 ("small problem").
\

**Outcome measures:**

-   "support-for-intervention", 7-point scale

-   "Lives-to-save" 

> "What is the minimum number of these (9,000/41,000) lives at risk ... saved each year before you... require consumers > to pay for anti-lock brakes"

Treatments started with one size, then presented a "task force's new
estimate" with the reverse.

***[Overall evaluation of evidence]{.underline}***

***[Evidence gap and suggestions for future work and
approaches]{.underline}***

### Potential Solutions

```{block2,  type='fold'}

1.  Framing

a.  Frame down denominator (suggestive evidence from Fetherstonhaugh, etc)

b.  Report absolute or proportional number of lives that could be
   saved by an intervention depending on which suggests a smaller
   denominator (how do you know?)

c.  Highlight numerator (impact) (evidence?)

d.  (Ari:) "Increase evaluability: putting interventions on same
   page instead of separate pages"

2.  De-biasing (discussed further in Friedrich et al - expand)

*Consider:*

-   *"The proportion dominance effect was primarily mediated by
   perceived impact." (Erlandsson et al, 2015, OBHDP)*

-   *"Perceived Utility (not Sympathy) Mediates the Proportion Dominance
   Effect in Helping Decisions" (Erlandsson et al, 2013)*


```

## Statistical/identifiable victim effect

Cite: Hsee13, small2003helping, kogut2011identifiable, small2007sympathy_s3_s4

## Availability heuristic 

(in probabilities?)

People judge the probability of events and the importance of problems by the ease by which they can be brought to mind.  This may  impact  the importance they ascribe to causes and charities.	Effective  causes may be distant and underreported, for various reasons. Furthermore there may be a set of charities that are for a variety of reasons underreported or unconnected to the lives of the majority of donors; these will be neglected (and thus  more effective by dint of a lack of funding).

Effective causes may be distant and underreported, for various reasons. Furthermore there may be a set of charities that are for a variety of reasons underreported or unconnected to the lives of the majority of donors; these will be neglected (and thus  more effective by dint of a lack of funding).

## Overhead aversion


### Related Terms {-}

-   Similar terms: Overhead bias

-   Possible mechanisms: waste aversion, perfectionism; evaluability bias (for this versus other metrics); excuse-driven/motivated reasoning

-   Distinct but related: corruption aversion

### Description {-}

Potential donors may have a negative feeling towards a charity's costs
that are considered "overhead" rather than "direct spending on program
activities." This may make them reluctant to donate to charities that
express a high "overhead ratio" and/or when they believe their donation
will go to "pay for overhead", and to favor instead charities that
report low "overhead ratios".

Discussion: There are some clear flaws in this logic (thus we may call
it "overhead bias"): many things considered overhead are fixed or sunk
costs which will not be changed by the amounts donated; thus, at the
*margin* the donation may not actually go towards this overhead.

Marginal overhead is also possible. Suppose, e.g., the cost of an
additional year of school tuition fees for a child are £200, but this
requires an additional administrative cost of £50 to vet the student
and her family, pay money transfer fees, fill out additional forms, etc.
A donation of £200 earmarked for "tuition only" would require an
additional £50 of these costs, which might be labled "overhead".
However, as this example suggests, many such "overhead" expenses are
necessary parts of the mission, an increase its effectiveness (e.g.,
training employees, auditing, evaluating and targeting programs). On the
other hand, we cannot rule out that in some cases high overhead might be
a signal of inefficient practices. Where organizations have bloated
annual operating expenses it might be more efficient for them to close
down in the medium term and for that money to be used for leaner
charities. (Several theoretical papers [ref: Steinberg ?1986 and later
work] discuss whether or not the overhead ratios are a sign of
efficiency.)

### Overview of Evidence {-}

Survey and observational evidence suggests that donors focus on
potentially misleading measures of overhead. Gneezy et al (2014) present
a credible piece of field-experimental evidence suggesting that having a
"lead donor" and framing this as "covering overhead" may increase
donations. Metzger and Gunther's (2019) lab participants donate
(marginally) significantly less when presented with (the option to buy)
information about a NGO's administrative costs (perhaps because such
costs were made salient). Caviola et al's (hypothetical?) experiments
suggest that *evaluability* may drive the focus on overhead rather than
effectiveness. Portillo and Stinn's lab participants favored
overhead-free charities and preferred fundraising-related to
salary-related overhead. Kinsbergen et al's representative (Dutch)
survey participants "have a strong aversion regarding overhead costs,
[but]\... seem to value the capacities of paid staff members and are,
to a certain extent, willing to pay a price for these."


### Relevance to effective giving

-   How this particular barrier proves problematic for effective giving?

Study [ref] finds 'no correlation' between overhead and
effectiveness\-- is it convincing?

As noted above, overhead is an important input to the charity's
production function, enabing it to be effective. A biases against
overhead therefore distort's the donor choice of charity away from
effectiveness. The other side of this coin: in an efficient market firms
provide the services consumers demand. If consumers have a preference
for firms that use a lower share of some input, this will "distort" the
production process away from this input, making it seem artificially
costly [ref: Reinstein and Song, others]. Similarly, if donors punish
charities for excessive overhead, charities will use "too little" of
inputs deemed to be overhead.

Note that doing impact evaluation will itself increase overhead. I.e.,
aversion to overhead will lead people to be biased against
evidence-based charities that evaluate their own programs.

While the above concerns do not necessarily tilt against charities
targeting overeas or lower-profile causes, it nonetheless represents a
departure from efficiency in choice/provision of charitable services.

Furthermore, there is a reasonable case [todo: get evidence] that
working in poor countries, countries that are further from the charity's
headquarters, and countries more distant from legal, financial, and
other services *will* lead to a greater overhead ratio. This may be
accentuated if the *basic* service (e.g., food, housing, or education)
is cheaper in poor countries. E.g., sending a poor child in Chicago to a
summer enrichment program might cost £4000 in fees and £500 to
administer the scholarship, roughly 11% "overhead share" . Sending a
poor Ghanaian child for a year might cost £300 plus £100 in
administration, a 25% share.

### State of Evidence; key papers {-}

**Methodological issues** 


-   Observational (correlational) studies: Overhead varies across
charities in non-random ways; may be correlated to unobservable
characteristics. There may also be reverse causality --
fundraising expenses both increase reported overhead and
(presumably) drive donations.

-   Meer (2017) identified plausibly exogenous variation; but this
pertained to *actual* incremental costs/prices, rather than
the "overhead" costs at issue

-   Field experiments can vary *presentation* or *framing* of overhead
but not (typically) a charity' *actual* administration processes
(thus "overhead")

-   Lab experiments can vary the actual price of giving but this doesn't
represent the real-world "overhead" issue; others

-   In contrast, Metzger and Gunther varied the charity the subjects
could donate to, but imposed a strong framing of the
administrative costs as a marginal price).

-   Survey and hypothetical vignette evidence (usual issues)

#### Gneezy, Uri, Elizabeth A. Keenan, and Ayelet Gneezy. "Avoiding overhead aversion in charity." Science 346.6209 (2014): 632-635.\| {-}

Gneezy et al (2014) ran a large-scale (N=40,000 [check]) mail solicitation on behalf of an organization seeking to fund as many US educational projects (each costing `$20,000` US) as possible. Recipients were asked to give 20/50/100 USD. They found that framing a lead donation as "covering[ing] all the overhead costs associated with raising the needed donations" lead to a significantly greater share donating and amount raised than either the control condition (no lead donation?) or a seed ("has given this campaign seed money") or matching frame ("will match every dollar given... up to a total of `$10,000`").



<div class="marginnote">
 Results

Share donating: Overhead (8.5%) $>$ \*\*\* $\geq$    Match $>$ Control (3.4%)

Amount raised: Overhead (`$`2.31) \> \*\* Seed, Match > \*\*\* Control (`$0.80`)

</div>
 

Note that while the framing differed, the *actual* treatment of the seed money in each case was the same; unless the charity could change the way it *administered* its programs between treatment, there is no clear way to experimentally vary the *actual* overhead. 

This amounts to a clear piece of evidence that in such contexts
*framing* overhead as being "covered" in this way may increase
donations. However, it doesn't reveal donors' reaction to the reported
measure of overhead *itself*. The effect may come from the particular
salience of the way the lead donor's (particularly selfless) act is
portrayed, or it may be specific to overhead "*associated with raising
... donations"* rather than administrative overhead, salaries, etc.

The same authors ran a *lab* experiment where they were able to vary the
share of the subjects' donation that actually went to the charity,
labeling the difference (donation - amount passed) as "overhead", and in
a second treatment arm, whether this "overhead" was covered by a third
party. The results were similar to the field experiment [CHECK, go into
more detail]. However, this transparent "donation reduction" has little
in common with the real-world costs usually depicted as "overhead". In
this lab experiment, a donor who cares about her marginal impact
*should* consider the pass-through rate or "price"; this is not
"overhead illusion".

<div class="marginnote">
 Other standard critiques of lab experiments in this domain apply    here.
 </div>
 

#### Portillo, Javier E.; Stinn, Joseph, (2018). "Overhead Aversion: Do Some Types Of Overhead Matter More Than Others?". Journal Of Behavioral And Experimental Economics, 72, , 40\--50. {-}

Lab experiment

> If an overhead-free donation is readily available, then the average
donor in our experiment (70--80% of subjects) prefers that charity to
receive the donation. However, if donations are not overhead-free, most
(approximately two-thirds of subjects) prefer the donation go toward
fundraising efforts instead of salary-related expenditures.

\



#### Kinsbergen, Sara; Tolsma, Jochem, (2013) {-}

"Explaining Monetary Donations To International Development Organisations: A Factorial Survey Approach". Social Science Research, 42, 6, 1571\--1586. 

Hypothetical survey (vignettes, scenarios) "We constructed 960 scenarios in which a fictive international development organisation was described. ... A large representative sample of the Dutch population (N = 2,758) received six randomly allocated scenarios and had to decide if, and if so, how much they would donate to the depicted (fictive) organisation.... Although donors have a strong aversion regarding overhead costs, we find that donors seem to value the capacities of paid staff members and are, to a certain extent, willing to pay a price for these.

\

#### Meer, Jonathan, 2017 {-}

"Effects of the price of charitable giving: Evidence from an online crowdfunding platform 
"

-   DonorsChoose platform involves plausibly exogenous variation in the providing (the same) goods to teachers across projects (varying sales taxes, fullfillment, payment processing fees, etc).[^3] Fees are 'explicit and salient'.

-   Robust analysis (e.g., teacher fixed-effects) to address a potential
    > endogeneity concern (saavy teachers economize on fees)

-   An increased price of giving results in a lower likelihood of a
    > project being funded. We also calculate the price elasticity of
    > giving, finding estimates between −0.8 and −2.

However, this does *not* typify the overhead we are considering. Here,
we see variation in the donot's *actual* costs of providing outputs; as
in Gneezy et al's lab experiments, this is not "illusion". While donor
responses to e.g., greater fixed costs of maintaining an office in
Malawi, or greater costs of identifying legitimately poor families
*might* be similar, we do not know.[^4]

<div class="marginnote">
"...variation in the payment processing, optional support, and
    fulfillment fees described above; along with sales taxes and
    shipping fees charged by vendors. ... the optional support fee
    changed twice over the course of our data and the payment processing
    fee changed once. The fulfillment fee, a fixed amount, changed three
    times in the time covered by the data. In addition, this fee affects
    the efficiency price of different-sized projects differently. The
    changes affected only newly posted projects; therefore, for nearly
    half a year after each change was implemented, active projects that
    might be otherwise identical had different fee levels."
</div>
 


#### Solutions (add section)

-   "Seed donor covering overhead"

-   Simultaneous comparisons and evaluation of impact and overhead where
    > relevant (Caviola et al)

-   De-biasing?


Other papers to look into and incorporate (unfold)

```{block2,  type='fold'}

Borgloh, S., Dannenberg, A., Aretz, B., 2013. Small is beautiful -
experimental evidence

of donors' preferences for charities. Econ. Lett. 120 (2), 242--244.

Hope Consulting Survey:

"a recent survey found that only 35 percent of donors do any research
before giving (Hope Consulting, 2012), this is a valid concern -- though
among those who did research, the most commonly sought information was
some type of overhead ratio, and two-thirds were seeking some sort of
information related to efficiency."-Meer

"Making an impact? The relevance of information on aid effectiveness for charitable giving. A laboratory experiment" Metzger L Günther, *Journal of Development Economics (2019) 136* 

**"**We thus clarified that a decrease in administrative costs from 40%
to 10% is equivalent to a 50% increase in net transfers to the
recipient, in an attempt to make the administration costs group as
comparable to the aid impact group as possible." \-- this oversimplified
framing may be driving their results.

"A. a relatively small share of people makes a well-informed donation
decision. B. the demand for information about aid impact is lowest, and
it is highest for information about the recipient type. C. impact info
didn\'t affect average donation, while information about the exact
recipient type and administrative costs led to a significant change in
donation levels."

"In the recipient type group, informed participants donated
significantly more than uninformed participants because they "rewarded"
the preferred recipient with higher-than- average transfers. In the
administration costs group, informed participants donated significantly
less than uninformed participants because they used the information to
"punish" NGOs with high administration costs."

"only 28% of the participants in the bought ANY information (impact, who
benefits overhead). Within that, highest demand for beneficiary, lowest
for impact. Impact info no effect on giving. Knowing who benefits info
increased giving. Overhead info decreased giving."

**Caviola, L., Faulmüller, N., Everett, J. A., Savulescu, J., & Kahane,
G. (2014). The evaluability bias in charitable giving: Saving
administration costs or saving lives?. Judgment and decision making,
9(4), 303.**

"When presented with a single charity, people are willing to donate more
to a charity with low overhead ratio, regardless of cost-effectiveness.
When presented with two charities simultaneously, they base their
donation behavior on cost-effectiveness"

**Bowman, W., 2006. Should donors care about overhead costs? Do they
care? Nonprofit Volunt. Sect. Q. 35 (June (2)), 288--310.**

Meer... Are overhead costs a good guide for charitable giving?

Trussel, J. M., & Parsons, L. M. (2007). Financial reporting factors
affecting donations to charitable organizations. Advances in Accounting,
23, 263-285.

Tinkelman, D. (1998). Differences in sensitivity of financial statement
users to joint cost allocations: The case of nonprofit organizations.
Journal of Accounting, Auditing & Finance, 13(4), 377-393.

Parsons, L. M. (2007). The impact of financial information and voluntary
disclosures on contributions to not-for-profit organizations. Behavioral
research in accounting, 19(1), 179-196.

Yörük, B.K. (2013). Charity ratings [this literature is not
specifically on 'overhead'; I should check how Charity Navigator factors
this in]

Frumkin, P., & Kim, M. T. (2001). Strategic positioning and the
financing of nonprofit organizations: Is efficiency rewarded in the
contributions marketplace?. Public administration review, 61(3),
266-275.

van Iwaarden, J., Van Der Wiele, T., Williams, R., & Moxham, C. (2009).
Charities: how important is performance to donors?. International
Journal of Quality & Reliability Management, 26(1), 5-22.


```




[^4]: Furthermore, DonorsChoose doesn't have clearly separate variation
    in effectiveness of the outputs which we could compare to the
    differential prices of providing particular outputs (fees, etc.), to
    potentially detect oversensitivity to the former.


<div class="marginnote">
Study finds ‘no correlation’ between overhead and effectiveness-- is it convincing? Does working abroad increase overhead? Most relevant tie: doing impact evaluation will itself increase overhead.
</div>

References: Gneezy2014, Portillo_Stinnb2018, Kinsbergen_tolsma_13, Mayo2009, Meer2017	Chhaochharia_Ghosh_08?, Caviola2014, Qu?

<!-- ## Possible: Altruistic opportunity cost neglect -->
 
 
## Possible: Misunderstanding need (and misunderstanding marginality/tractability/sunk costs?)

```{block2,  type='fold'}


Related terms: misunderstanding marginality, misunderstanding tractability, sunk cost fallacies

**Misperceiving tractability:**

1) donations may respond to number of *deaths* from a disaster rather than to the scale of the need of *survivors* (sunk losses)

2) donations may respond to average cost per life saved, rather than marginal cost per life 

General barrier to accurate assessment of effectiveness ergo a barrier to effective giving.
```

## Scope insensitivity/embedding effect/part-whole effect

```{block2,  type='note'}
"People's stated valuation or "willingness to pay" for an outcome seems not to strongly increase in the magnitude of that outcome.  For example,  when asked in isolation people might say they are willing to pay $50 to save 100 eagles.  Other people asked in isolation may  say they are willing to pay $50 to save 5000 eagles.

Kahneman1992 (Part I: Embedding effect):
the expressed willingness of Toronto residents to pay increased taxes to prevent the drop in fish populations in all Ontario lakes was only slightly higher than the willingness to pay to preserve the fish stocks in only a small area of the province."
```  

```{block2,  type='note'}
When assessing effectiveness  in determining which charity to donate to (and how much),  a utilitarian  should be very sensitive to the scale of the impact (essentially the benefit per cost). If people  are scope insensitive they will be bad at making these judgments (particularly when presented in isolation).
```  

Ref: Hsee13

## Other possibilities: "Risk aversion",  Lack of tangibility, Corruption aversion

See Airtable
