
# Previous approaches and evidence

There is a **lack of data** on donations at the individual-charity level.

For identification: Lack of **independent observable variation** in price, shocks, or appeals.

**Intertemporal substitution** is an issue, and we typically **cannot observe 'lifetime giving.' **

Estimation of Expenditure substitution is complicated by issues of extensive vs intensive margins, as well as  heterogeneity


### Observational work

- [@Reinstein2011d]  -  fixed effects, bounding arguments

- With 'exogenous' shocks:  [@Deryugina2015b]


Donations in state affected by tornado increase  1.7-2 percent in that year and 1.9-2 percent in the 2 years after Can only reject 'full crowding out'

[@Scharf2017]

- CAF accounts all donations over substantial period
- Reject 'full crowd-out', tight zero LR crowdout

$\rightarrow$ non-disaster giving pre-poned (!), esp. for disaster/intl donors; "halo effect?"

Estimates: +.537 log donations to DEC-13, se .032; -0.008 log donations to 'other charities', se 0.017 $\rightarrow$  Reject 'full crowd-out', tight zero LR crowdout

*Interpretation...*

consistent with...  for (only) people responding to the DEC appeal ... the disaster appeal increased the effectiveness with which donating to all charities, including Other charities, produces warm glow utility—a halo effect

They argue that their data allows them to reject the transactions cost explanation because they see i.  less bunching than usual, ii. shifts in amounts given and not just at the extensive margin and
iii.  a particular shift from certain categories.

Issues:  Specific CAF population; disaster-specific; time-series variation issues (6 disasters=lumpy?)


<!--
Todo: add pictures of the relevant environments for these studies here
-->

### Simultaneous/proximate ‘lab’ experiments**

(esp. Reinstein 2006/11; Ozbay-Uler)


*Figures: Berkeley design, types*

Vary choice sets/prices, shocks $\rightarrow$ crowd-out, esp.  similar causes


*Figures: Berkeley line graphs*

(Reinstein, 2011)  $\rightarrow$ Strong "expenditure substitution" responses to shocks, esp for similar charities; approx 50\% crowd-out; 2.59 cross-price-elast)

- Heterogeneity; mix of 'fixed purse', 'flexible purse/never substitute']

Filiz-Ozbay and Uler, 2018 : Five paired choices, varying 'rebate rate' for one only; price-focus
   - 'Stealing' almost always
   - +0.35 net cross-price elast for 'substitute' charities

-  Harwell ea '15; Schmitz '18: somewhat related designs, similar results in flavor


### Lab/framed experiments with time gaps

- Schmitz 2019 (ExpEcon)

- Vance-Mullen component of Reinstein et al

### Field/natural experiments

- Meer 2014, 2017: DonorsChoose.org competition, matching campaigns

2017: Increased funding for project, no significant impact on donations to other projects

Meer 2014: "increased competition reduces the likelihood of a project being funded"



- Donkers et.al. 2017: Extra mailings to existing donors in a week, top-NL charities
  - Extra mailings +1.81 EUR for charity,
  - -0.10 EUR per 'regular' mailing for *other* charity in *same week*
  - loss of 10\% of revenues via competitive effects
  - can't reject zero-crowding, but wide CI's

- Anticipated second asks:  [@adenaGivingOnceGiving2019; @Cairns2011]

Cairns and Slonim: *Anticipated* `2nd collection' at Mass raised 7695 USD , reduced 1st collections by 1708 USD  (22\% "crowdout")

Adena and Huck: Anticipated repetition $\rightarrow$ 40\% less "this year" (but also a *persistent* lower don)


Reinstein et al, 2020: First field-experiment to  Ask (or not ask) on multiple separate occasions with a significant delay, vary this delay time; find some crowding out but evidence on interaction with delay time is mixed. Possibly two channels: consistency versus fading of moral license/warm glow.


## Synthesis (emerging)

```{r, out.width='85%', fig.align='center', fig.cap='Papers on substitution; database'}

knitr::include_graphics('picsfigs/subst_meta_cut.png')

```

Proximate asks and clearly presented comparisons $\rightarrow$ expected crowding-out

A particular issue: apparent contrast, **Coherent arbitrariness**, narrow brackets, framing (how people think they ‘should behave’ or how they behave when they are in a deliberative self-reflecting mode. This may characterize some giving decisions but it is probably not the most common.

With naturally-occuring, more time-separated shocks and asks, the results are more mixed, sometimes with much smaller, or no apparent substitution.

So ``how proximate is proximate''? Evidence is still mixed (see above discussion on dual channels) 




