[
["outline.html", "Increasing effective charitable giving: The puzzle, what we know, what we need to know next 1 Outline Extended abstract Presenting the puzzle and challenge: Our ineffective giving Definitions - “Efficiency” versus impact Do people actually care about impact? Does moral utilitarianism matter? Are charities in competition? Is the ineffective giving reducing effective giving? Ask people to give to EA charity ‘instead’? Explaining the puzzle: Barriers to EA giving and potential responses, evidence Barriers: Awareness, consideration, and distance Barriers: Identity and cognitive dissonance Barriers: Signaling and social pressures/social identity Barriers: Aversion/obstacles to doing (and using) evaluations Barriers: Quantitative biases Barriers: Inertia and systemic/institutional Tools for motivating EA giving Conclusion; a research agenda 1.1 Other practical considerations", " Increasing effective charitable giving: The puzzle, what we know, what we need to know next Dr. David Reinstein, Nick Fitz, Ari Kagan, and more 2020-06-04 Abstract This ‘book’ organizes the project and helps others understand it and learn from it 1 Outline Increasing effective charitable giving: The puzzle, what we know, what we need to know next This outline links, and gives a brief description of each section Extended abstract Non-technical abstract Hunger, homelessness, mental and physical illness, environmental degradation: the needs are boundless, but the resources to solve these problems are limited. Even with the best of intentions and impressive generosity (Americans give roughly 2% of their income to charity!), donors often contribute to inefficient charities – ones that spend more but accomplish less than others that may be competing for the same funds. Each dollar given to the most effective charities (like those rated by Givewell.org) benefits greater numbers of people in more significant ways than the least effective ones. However, donors do not always consider “Effective Altruism” (EA) when deciding how much to give and to which organizations. Academics (in Economics, Psychology, Biology, and Philosophy) have applied a range of theories to explain what drives “inefficient altruism.” Evidence comes from a variety of studies, involving surveys, observational work, laboratory experiments, and, where feasible, natural field experiments. These have not been run as part of a systematic project addressing this issue; goals, contexts, and approaches have varied as opportunities presented. Given the disparate findings, we do not have a definitive picture of which factors impact effective giving. Presenting the puzzle and challenge: Our ineffective giving Why should you care about this? Descriptives of giving (US, international) and how ‘ineffective’ it is. Potential global welfare gains to changing ‘where we give’. Lack of previous evidence/synthesis Definitions - “Efficiency” versus impact Charity ‘quality ratings’, Overhead aversion Why (under what models) is this a puzzle? Why (under what models) is this a puzzle? Economics and psych models –&gt; puzzle? Models where people care about the impact of their gift or just ‘amount sacrificed’ (naive warm glow). Does impact map into the ‘good feeling’ from giving, can it do so? Here we also give a general ‘conceptual’ overview of these barriers in the next chapter. We dig into each barrier more carefully in subsequent chapters. Do people actually care about impact? Does moral utilitarianism matter? Are charities in competition? Is the ineffective giving reducing effective giving? Ask people to give to EA charity ‘instead’? Does one ask (or donation) crowd out another… when and how? This is critical to understanding the extent to which gains can be achieved by getting people to ‘switch’ from other charities. To the extent this is the case, factors driving giving to the non-EA charities, especially local obligations (e.g., neighbors pressure you to give to local orgs) themselves represent barriers to EA giving (see below). (???), (???), (???), (???; ???; ???; ???; ???) Explaining the puzzle: Barriers to EA giving and potential responses, evidence Barriers: Awareness, consideration, and distance Whether a cause/charity is something people are aware of, feel is important/salient, and feel close to. Responses?: (Info enhancing) social closeness of recipient Barriers: Identity and cognitive dissonance Barriers: Signaling and social pressures/social identity Barriers: Aversion/obstacles to doing (and using) evaluations Barriers: Quantitative biases Barriers: Inertia and systemic/institutional Tools for motivating EA giving Psych/behavioral tools; applicability to EA charities Briefly highlight those ‘tools’ that give non-EA an advantage, but focus on the actionable–how EA lessen or flip that advantage. Which tools present particular challenges or opportunities for EA? Recipient’s plight as ‘loss’ vs previous state Unconditional gift (Gift exchange) “Percentage donations tied to purchases, especially in online auctions -”, Give more tomorrow Give if you win \"Size of ask; Low-ball, ‘Legitimation of paltry donation’ (LPD/LPC) Solicitor characteristics Visibility (of giver), Visibility Recognition ‘to influence others’, Visibility Recognition tiers, Reveal previous donor/donation (also ‘info’) De-biasing and misperception-correction (???) (???) Innovative proposals Smeets?, Kellner_EA_2017 EA-movement approaches and pitfalls What has EA tried and how has it worked; evaluate approaches in light of the evidence. Is the movement too ‘purist’ (e.g., focusing on only the most effective, proven charities instead of those with broader potential appeal but less evidence)? Conclusion; a research agenda Need for systematic platforms to study this, systematic experimentation and data sharing among effective/international charities. Platforms available, proposals for particular research projects and approaches. Who gives to the truly most effective international charities? Who is most likely to be convinced, and which arguments/presentations work in the SR and LR, and for whom (heterogeneity)? Statistical learning-based analyses Practicable techniques in a range of higher-stakes real-world environments Replication (and verification), pooled evidence, meta-analysis Context-sensitivity, large SE \\(\\rightarrow\\) large samples, statistical learning controls, sharing data Responses to ‘obvious contrasts’ seem to not reflect between-subject responses\" Also see gatesproposal.md (Gates foundation) 1.1 Other practical considerations Notes on potential integration with PriorityWiki/Rethink Charity How have EA orgs been brought together …especiallyat unis Effective thesis project EA hub – add a button here? Facebook group "],
["present-puzzle.html", "2 Presenting the puzzle and challenge: Our ineffective giving 2.1 Motivation and descriptives 2.2 (Lack of) previous synthesis on this 2.3 Definitions - “Efficiency” versus impact 2.4 Why (under which models) is this a puzzle?", " 2 Presenting the puzzle and challenge: Our ineffective giving Overview of research Question/Problem: Why don’t people give in an evidence-based way? When faced with the “girl drowning in the pond” we are willing to sacrifice substantial wealth to save a life. However, most people don’t make large donations to the very poor, in spite of evidence suggesting that lives can be saved for less than $10,000. This is not for lack of generosity. There is a strong case that most donations go to charities that improve well-being far less per-dollar than others.1 As Hoffman et al (2018) state:2 “We donate billions of dollars to charities each year, yet much of our giving is ineffective. Why are we motivated to give, but not motivated to give effectively?” This raises two related questions: 1. “Why don’t we give more to the most effective charities and to those most in need?”, and 2. “Why are we not more efficient with our giving choices?” To address this, we must understand what drives giving choices, and how people react to the presentation of charity-effectiveness information. Note that these two questions are not identical: the first asks about the amounts given to the most needy charities, and the second about the choice of charities conditional on giving. 2.1 Motivation and descriptives Individual donors, governments and firms demonstrate substantial generosity (e.g., UK charity represents 0.5-1% of GDP, US charity around 2% of GDP).3 However, most donations go towards charities that are worthwhile but improve human well-being far less per-£ than basic medical interventions in poor countries, such as antimalarial bednets (see Givewell.org). Even within the same category, more can be achieved for less: e.g., while it costs about USD 40,000 to provide a blind person a guide dog, each USD 100 given for mass-distribution of ivermectin may prevent 10-50 years of river-blindness.4 Social science, biology and philosophy present a range of potential theoretical explanations of how values, preferences, and biases drive this ‘inefficient altruism’. However, evidence (e.g., for ‘availability bias’, or for ‘scope insensitivity’) comes largely from small-scale experiments in domains outside of charitable-giving. It is difficult to distinguish robust, credible findings from one-off results that are vulnerable to hype, p-hacking and publication bias (echoing the ‘replication crisis’ in experimental social science). Given the limited, scattered findings, we do not have a definitive picture of which factors substantially impact ‘effective giving and support for policies that reduce extreme poverty’. (We give a review of papers surveying this evidence below) A plain-language summary of key points, without references (unfold): Charities’ impact differs by an order of magnitude: Some charities are much more effective at saving/improving lives (and achieving other goals such as those involving animals and the environment) than others are. While it is difficult to gain precise estimate on the measures such as “cost of a life saved” there is strong evidence that there are orders of magnitude difference between different categories of charities and different interventions within these categories. **There are some very effective lifesaving charities: Some interventions seem likely to save or vastly improve individual lives at a cost in the range of $2000 - $10,000. When people are asked whether they would be willing to spend this amount or even a vastly larger amount to save a life in other contexts they typically will agree to do so. There are two related and largely unresolved puzzles: Why are people not more generous with the most highly effective causes? and When they give to charity why do they not choose more effective charities? There is some evidence on this but it is far from definitive. We do not expect there to be only a single answer to these questions; there may be a set of beliefs, biases, preferences, and underlying circumstances driving this. We would like to understand which of these are robustly supported by the evidence, and will have a sense of how important each of these in terms of the magnitude of driving and absence of effective giving. There has been only a limited amount of research into this and it has not been systematic, coordinated, nor heavily funded. We seek to understand because we believe that there is potential to change attitudes, beliefs, and actions (primarily charitable giving, but also political and voting behaviour and workplace/career choices). Different charitable appeals, information interventions and approaches may substantially change peoples charity choices. We see potential for changing the “domain” of causes chosen (e.g., international versus US domestic) as well as the effectiveness of the charities chosen within these categories. (However, we have some disagreement over the relative potential for either of these.) Our main ‘policy’ audience includes both effective nonprofit organisations and ‘effective altruists’. The EA movement is highly-motivated, growing, and gaining funding. However, it represents a niche audience: the ‘hyper-analytic but morally-scrupulous’. EA organisations have focused on identifying effective causes and career paths, but have pursued neither extensive outreach nor ‘market research’ on a larger audience (see Charity Science, Gates Foundation/Ideas42). 2.1.1 Descriptives of giving (US, international) and how 'ineffective' it is. Who does give effectively? Potential global welfare gains to changing \"where we give. Who does give effectively? (or put at bottom?) {ea-depict} Fitz/Kagan: Understanding Effective Givers: In this study we attempt to understand who is predisposed towards effective giving. After providing a description of the effective giving movement, we measure support for effective giving and measure a wide range of personality traits and demographics that may predict support for effective giving. Briefly defining the EA movement as an important force “we” (economists, psychologists) need to discuss. 2.2 (Lack of) previous synthesis on this While there have been some relevant prior reviews ((???), introduction to (???), (???))5 the current project uniquely combines focusing on effectiveness, considering ‘choices among charities’ as well as in isolation, incorporating recent work and developments from the ‘EA movement’, a rigorous, sceptical approach to evidence, and advancing a research agenda while building tools that promote robust evidence. Ideas42: “We did not find many field-based, experimental studies on the factors that encourage people to choose thoughtfully among charities or to plan ahead to give.” 2.2.1 Effectiveness-specific Comparison of outlines: unfold Gertler, \"Charitable Fundraising and Smart Giving\" Baron chapter Introduction (with problem/puzzle) Possible Nonutilitarian Heuristics Evaluability (focus on attributes easy to evaluate e.g., &gt; efficiency/overhead) “instead, what is more evaluable than the lives saved per dollar of contribution is the operating cost per dollar” Average vs. Marginal Benefit, Diversification, Prominence, Parochialism Identifiability, Voluntary Versus Tax Experiments Waste, Average Cost Diversification, Unequal Efficiency; Unequal Efficiency, Several Projects Versus One Nationalism Forced Charity Discussion: Utilitarian Models of Altruism, Maximize Total Utility, Limited Self-Sacrifice, Limited Altruism, Moral Education, Implications 2.3 Definitions - “Efficiency” versus impact Consider: The measures used are relevant to how we consider issues such as charity ‘quality ratings’ and ‘overhead aversion.’ It is important to define the concept of talking about. What, precisely, is this effectiveness'' orimpact’’ of a charity we are focusing on? It is not trivial to get this right and there are some delicate and hotly debated questions even within the EA movement. Nonetheless, I sketch the basic idea in the math below. \\(G_j\\): The total donations given to charity \\(j\\) during some interval; i.e., the Cherry’s income. \\(B_j(G_j)\\): A function defining the beneficial outcome achieved by charity \\(j\\) with the total donations \\(G_j\\). Here, we are referring to \\(B_j(G_j)\\) as (the improvement to ) some ultimate outcome: Lives saved (i.e., deaths averted), quality adjusted life years (QALY) added, QALY weighted by age, Disease-adjusted (DALY), future happy lives generated, sentient suffering averted, etc. As noted, there are disagreements over how and whether we should trade off among these outcomes. Issues such as population ethics, andthe importance of sentience and experience — come to the fore. We will ignore these for now. The important distinction here: \\(B(G_j)\\) does not refer to a simple intermediate ‘output’ such as ‘antimalarial nets provided’ nor ‘textbooks purchased’. We are referring to the social outcome of ultimate value; an outcome that could be valued in and of itself. This naturally takes into account both the ‘technical efficiency’ in terms of how many units of output can be produced per dollar, and the rate at which each unit of this output boosts the ultimate outcomes of interest. The ‘production function’ is (perhaps tautologically) the product of two terms: (Total or marginal) impact per dollar = output per dollar \\(\\times\\) impact per output This is obviously an oversimplification. To achieve the beneficial outcome the charity will require many intermediate inputs (or “outputs” as noted above), including ‘management’ and ‘careful targetting of programs’. Some charities may be able to acquire these inputs at better prices than others, and some may also use a more efficient mix of inputs. A donor may care about the ‘impact’ of her own donation; i.e., she may want to know the difference in outcomes that her donation achieves everything else equal. In other words, the difference in the ultimate outcome in a world with versus without her donation. Small donor assumption: For a small donor (perhaps someone who donates less than USD 100,000), we may assume that this “rate of benefit” will be the same for both the first and the last dollar she donates. Thus we consider the marginal impact, as a simplification: \\(B_j^\\prime (G_j)\\) for the marginal donor. I assert that \\(B_j^\\prime(G_j)\\) is the quantity that GiveWell (and perhaps other EA charity raters) are attempting to measure. We know: [CITE evidence here] \\(B_j^\\prime(G_j)\\) is much larger for the most impactful relative to the most popular charities. Increased benefits could be achieved if donations were ‘’reallocated’’ towards more impactful charities. An individual who gains value from her giving through it’s impact alone would naturally donate to only the one charity that has the greatest marginal impact, the charity \\(j\\) with the greatest \\(B_j&#39;(G_j)\\) term. If every donor is doing this, then as an ‘equilibrium’ result every charity receiving positive donations should have the same last-dollar marginal impact. In maths: \\[\\begin{equation} B_k^\\prime(G_k) = B_j^\\prime(G_j)\\forall j,k s.t. G_j&gt;0, G_k&gt;0 \\end{equation}\\] Caveats: This assumes a single impact goal, essentially ‘cause neutrality’. The idea that each donor gives only to a single charity essentially depends on the above ‘Small donor assumption’. Still, allowing that the marginal-benefit-leading-charity may vary within the range of an individuals’ donation simply implies that they should allocate among multiple charities each up to the point that the last dollar given yields the same marginal benefit as the other charities, yielding the above result. We can imagine an equilibrium in which all donors give to multiple charities, with each of these charities being virtually “tied” in their marginal effectiveness. But we do not seem to be doing this. Again: billions are given to charity, and these charities clearly have vastly different marginal impacts, even among those that seem to target very similar outcomes. 2.4 Why (under which models) is this a puzzle? Does the set of facts mentioned above constitute a ``puzzle’’ for our Economics and Psychology models… or are there obvious existing explanations? In Economic terms, are donors mysteriously ‘’leaving money on the table’’ or are they simply optimizing given their their preferences and constraints? What could explain this? Economists love when we can say that something is officially a Puzzle. It is an achievement in itself to be the researcher who first discovered a Puzzle, even if we have no clue how to resolve it. Aside on ‘Warm glow’… consider the contrast between models where people care about the impact of their gift versus models in which they care only about the ‘amount sacrificed’ (naive warm glow). Does impact map into the ‘good feeling’ from giving? Can it do so? 2.4.1 Conceptual breakdown of ‘barriers’ (first presentation) We focus on the ‘barriers’ or ‘hurdles’ to giving effectively among individuals who already engage in some charitable giving and other-regarding acts. Loosely, a donor would need to jump over all of these hurdles and cross each of these barriers in order to be giving effectively. Recall: is there a well-known psychological framework for these sorts of multiple-hurdle choices? We first consider a fairly conceptual breakdown. (In later sections, we will use a less theoretically precise categorization that proved more practically usable.) Later chapters presents the direct and indirect evidence for very specific barriers, with real-world examples, and proposed ‘tools’ for surmounting these. Here the conceptual breakdown proved difficult, as most of the real world cases fell into multiple theoretical categories. Conceptual breakdown of barriers: Base values: (non) utilitarian: people are optimising their own ‘X’, which does not coincide with impact \\(\\rightarrow\\) no puzzle? Judgement/cognition failures: People try but fail to optimize Emotion overrides cognition: Our brain serves two masters, those decisions are not consistent Identity and signalling: Effectiveness in giving clashes with our self-image/self-beliefs, or with how we want to appear to others Systemic factors (and inertia): “It’s society’s fault, man” … social systems leading to pressure and incentives from others to give to local or less-effective causes. Even if impact is a goal these systems take a long time to adjust. 2.4.1.1 Are people utilitarian? The discussion above largely assumes that people are, at least to some extent: Other-regarding/pro-social: her preferences or ger “utility function they are maximizing” incorporates the well-being of others, at least to some extent Moral utilitarians: The value she places on helping others (or on others’ outcomes) is principally increasing in some measure of the amount of good they have done for others, or in others’ welfare. For a given personal sacrifice, she will always prefer to have made more people more well-off than to have made fewer people less well-off. In Economics terms, she strictly prefers and values Pareto-improvements. A mathematical statement of this may be helpful here. Universalist: In considering others’ welfare, she values all others equally regardless of their identity. Universalism: a more precise example: Consider a world with three other people (B,C,D), begin in a Poor state. Consider outcomes such as: B and C are well off and D is poor D is well-off and B and C are poor She would always prefer outcome 1 over outcome 2. She would also rather achieve outcome 1 over outcome 2 with her charity, no matter the identity of persons B, C, and D. Not ‘deontological’: there are no other relevant absolute moral constraints (constraints such as ‘do no harm in your actions, even if others are helped’) To what extent does a ‘moral utilitarian’ (MU) consequentialist ethic govern beliefs and behaviour? To the extent it does, limited effective giving represents a puzzling intention/action gap. However, for non-utilitarians this is no puzzle. If other forces and motivations drive our giving choices, we might not expect these to be aligned with effectiveness. It could be argued that the above is posed too starkly. People may embrace concepts such as utilitarianism, universalism, and cause neutrality, and at the same time be largely driven by other concerns and sympathetic to other moral frameworks. We may agree with statements that “all lives are equal” and “we should strive to do the most good for the largest number” but also support maxims such as “charity begins at home” and “giving is about supporting something you have a personal connection to.” While these statements may, strictly speaking, be contradictory, we shouldn’t expect perfect consistency or constancy. Most people are not asked to rigidly join the deontological or utilitarian camp, and those who have not studied philosophy or social science may never have contemplated these issues directly. Perhaps moral utilitarianism (MU) is relatively unimportant in most people’s charitable choices. Even if this is the case, understanding the ways in which people do pursue their giving goals, and their obstacles and “biases” in doing so may suggest ways of making giving more impactful. For example, many donors may prioritize their local community, leading to their less-effective giving (from a universalist point of view). However, they might be persuaded to expand their definition of their own ‘community’. Some examples of concerns other than MU that might drive giving and charity-choices: Perfectionism/deontological aversion to ‘waste’ Social pressure Signaling virtue to others Emotional empathic reactions to particular images and situations A desire to identify with particular causes or particular groups of individuals, perhaps in opposition to other groups Religious motivations Fairness concerns 2.4.1.2 Judgement/cognition failures; Biases in perceiving impact and in making choices People may (at least to some extent) want to be effective in their donation. However, they may simply not be good at doing this. Quantitative biases may drive departures from effectiveness in general. Anything that causes me to misunderstand effectiveness, to misapprehend the nature of the “production function for good outcomes”, or to misjudge charities will lead me astray from effective giving. if I am making any mistake, I am failing to optimize. Furthermore, some biases may happen to be particularly harmful to those charities and causes that are most effective. We briefly list some of these biases below; we consider these extensively in the section “Barriers: Quantitative biases”. Cognitive biases: Overweighting and underweighting probabilities Misunderstanding marginality Scope-insensitivity Opportunity-cost Neglect Identifiable victims effect Overhead aversion (???), (???), (???), (???), (???), (???), (???) 2.4.1.3 Emotion overrides cognition Presenting analytical/impact information switches off system 1 Charity effectiveness (info/deliberation) Donor’s mood (Impacting) Affect prime Evaluation mode - (Karlan &amp; W, ’07), (Kogut &amp; R, ’05) (Small ea, ’07), (Drouvelis &amp; G, ’16), (Caviola ea, ’14) Avoiding information, motivated reasoning in processing it (???), (???), (???), (???), (???) 2.4.1.4 Identity and signaling Considering effectiveness in giving (and publicizing this concern) may conflict with an individual’s self-perception. It may also harm her reputation, at least relative to emotional or ‘deontological’ helping responses. 2.4.1.5 Barriers: Distance (Physical, Psychological/Emotional, Social) / Less proximate needs are less salient, thus under-funded. (Info enhancing) social closeness of recipient - ? (???), (Sudhir ea, ’16) 2.4.1.6 Barriers: Strong local appeals (‘the ask’), social obligations to give locally (and ‘crowding out’/moral licencing) (Meer, ’11) Does one contribution crowd out another? If so, social pressure, systems enforcing ‘local public goods’ and inertial factors may limit effective (non-local) giving. See, e.g., Ord, T. (2013, March 12). “The moral imperative toward cost-effectiveness in global health. Center for Global Development.” Retrieved from www.cgdev.org/content/publications/detail/142701. Also “Your dollar goes farther oversees”. (2016). Retrieved from http://www.givewell.org/giving101/Your-dollar-goes-further-overseas↩ Moshe Hoffman, Bethany Burum, Dave Rand, and Martin Nowak “Hidden Motives Behind Ineffective Altruism”, unpublished manuscript\"↩ ref↩ citation needed↩ Also, unpublished/non-academic work: ‘Behavior and Charitable Giving’ (Ideas42, 2016), ‘Charitable Fundraising And Smart Giving’ (Gertler, 2015), and ‘The Psychology of Effective Altruism’ (Miller, 2016, slides only).↩ "],
["substitution.html", "3 Are charities in competition? Is the ineffective giving reducing effective giving? 3.1 Previous approaches and evidence 3.2 Synthesis (emerging) 3.3 Random-effects meta-analysis", " 3 Are charities in competition? Is the ineffective giving reducing effective giving? 3.1 Previous approaches and evidence There is a lack of data on donations at the individual-charity level. For identification: Lack of independent observable variation in price, shocks, or appeals. Intertemporal substitution is an issue, and we typically cannot observe ‘lifetime giving.’ Estimation of Expenditure substitution is complicated by issues of extensive vs intensive margins, as well as heterogeneity 3.1.1 Observational work (???) (2011) - fixed effects, bounding arguments With ‘exogenous’ shocks: (???) Donations in state affected by tornado increase 1.7-2 percent in that year and 1.9-2 percent in the 2 years after Can only reject ‘full crowding out’ (Scharf, Smith, and Ottoni-Wilhelm 2017) CAF accounts all donations over substantial period Reject ‘full crowd-out’, tight zero LR crowdout \\(\\rightarrow\\) non-disaster giving pre-poned (!), esp. for disaster/intl donors; “halo effect?” Estimates: +.537 log donations to DEC-13, se .032; -0.008 log donations to ‘other charities’, se 0.017 \\(\\rightarrow\\) Reject ‘full crowd-out’, tight zero LR crowdout Interpretation… consistent with… for (only) people responding to the DEC appeal … the disaster appeal increased the effectiveness with which donating to all charities, including Other charities, produces warm glow utility—a halo effect They argue that their data allows them to reject the transactions cost explanation because they see i. less bunching than usual, ii. shifts in amounts given and not just at the extensive margin and iii. a particular shift from certain categories. Issues: Specific CAF population; disaster-specific; time-series variation issues (6 disasters=lumpy?) 3.1.2 Simultaneous/proximate ‘lab’ experiments** (esp. Reinstein 2006/11; Ozbay-Uler) Figures: Berkeley design, types Vary choice sets/prices, shocks \\(\\rightarrow\\) crowd-out, esp. similar causes Figures: Berkeley line graphs (Reinstein, 2011) \\(\\rightarrow\\) Strong “expenditure substitution” responses to shocks, esp for similar charities; approx 50% crowd-out; 2.59 cross-price-elast) Heterogeneity; mix of ‘fixed purse’, ‘flexible purse/never substitute’] Filiz-Ozbay and Uler, 2018 : Five paired choices, varying ‘rebate rate’ for one only; price-focus - ‘Stealing’ almost always - +0.35 net cross-price elast for ‘substitute’ charities Harwell ea ’15; Schmitz ’18: somewhat related designs, similar results in flavor 3.1.3 Lab/framed experiments with time gaps Schmitz 2019 (ExpEcon) Vance-Mullen component of Reinstein et al 3.1.4 Field/natural experiments Meer 2014, 2017: DonorsChoose.org competition, matching campaigns 2017: Increased funding for project, no significant impact on donations to other projects Meer 2014: “increased competition reduces the likelihood of a project being funded” Donkers et.al. 2017: Extra mailings to existing donors in a week, top-NL charities Extra mailings +1.81 EUR for charity, -0.10 EUR per ‘regular’ mailing for other charity in same week loss of 10% of revenues via competitive effects can’t reject zero-crowding, but wide CI’s Anticipated second asks: (???; ???) Cairns and Slonim: Anticipated `2nd collection’ at Mass raised 7695 USD , reduced 1st collections by 1708 USD (22% “crowdout”) Adena and Huck: Anticipated repetition \\(\\rightarrow\\) 40% less “this year” (but also a persistent lower don) Reinstein et al, 2020: First field-experiment to Ask (or not ask) on multiple separate occasions with a significant delay, vary this delay time; find some crowding out but evidence on interaction with delay time is mixed. Possibly two channels: consistency versus fading of moral license/warm glow. 3.2 Synthesis (emerging) knitr::include_graphics(&#39;picsfigs/subst_meta_cut.png&#39;) Figure 3.1: Papers on substitution; database Proximate asks and clearly presented comparisons \\(\\rightarrow\\) expected crowding-out A particular issue: apparent contrast, Coherent arbitrariness, narrow brackets, framing (how people think they ‘should behave’ or how they behave when they are in a deliberative self-reflecting mode. This may characterize some giving decisions but it is probably not the most common. With naturally-occuring, more time-separated shocks and asks, the results are more mixed, sometimes with much smaller, or no apparent substitution. So ``how proximate is proximate’’? Evidence is still mixed (see above discussion on dual channels) 3.3 Random-effects meta-analysis Build the tables of meta-statistics here Do a Bayesian RE analysis, allowing some variations in universe and assumptions; with and without our own results; interactive (shiny?) to allow personal weightings Explicitly register the PRISM thing, get an exhaustive picture of studies Redo meta-analysis P-curve, robustness to publication bias checks, etc Possibly move it to an appendix or a separate paper List of references "],
["aware-distance.html", "4 Barriers: Awareness, consideration, and distance 4.1 Description and relevance to Effective Giving 4.2 Theoretical and conceptual underpinning 4.3 Distance - Spatial/Physical, Social/Cultural: parochial altruism/ingroup bias, interpersonal and identity e.g., race, gender, age, etc 4.4 Distance: Experiential, Informational, Emotional/Affective 4.5 Distance - Temporal (future problems and people), Hypothetical (probability to happen) 4.6 Availability heuristic and media (also see ‘biases’)", " 4 Barriers: Awareness, consideration, and distance 4.1 Description and relevance to Effective Giving Typically, the most effective (humanitarian) charity will go from wealthy countries in the “North” to poor countries in the “South”. The large, social, cultural geographic distance is an important barrier to giving and a reason why people prefer to give locally. However, technology continues to reduce these barriers (see, e.g., Give Directly and their new web-enabled tools). 4.2 Theoretical and conceptual underpinning Construal theory, psychological distance, moral distance/moral circles 6 4.3 Distance - Spatial/Physical, Social/Cultural: parochial altruism/ingroup bias, interpersonal and identity e.g., race, gender, age, etc 4.4 Distance: Experiential, Informational, Emotional/Affective Ref: small2007_friends small_loewenstein_07_scarecrow 4.5 Distance - Temporal (future problems and people), Hypothetical (probability to happen) 4.6 Availability heuristic and media (also see ‘biases’) Persistent problems are not as noticeable as rare events such as natural and man-made disasters.7 These will then be both inherently less present in donors’ minds, and less reported in the media. Ref: Trope, Yaacov; Liberman, Nira (2010). “Construal-level theory of psychological distance” (PDF). Psychological Review. 117 (2): 440–463. doi:10.1037/a0018963↩ REFs↩ "],
["identity.html", "5 Barriers: Identity and cognitive dissonance 5.1 Self-interest/local public good (?) 5.2 Cognitive dissonance 5.3 (Side note?) Volunteer experience unlocks emotion and giving", " 5 Barriers: Identity and cognitive dissonance 5.1 Self-interest/local public good (?) In the context of ‘team reasoning’ and cooperative equilibria, it may seem selfishly beneficial to give locally/ to a public good that your smaller group gains from. If there is \"“competition”\" ….diminishing empathic returns to giving or moral licensing this may lead to less EG. 5.2 Cognitive dissonance “Accepting EA would imply I was wasting my money/doing it wrong… \\(\\rightarrow\\) they try not to think about effectiveness or are averse to it or just consistency motive” 5.3 (Side note?) Volunteer experience unlocks emotion and giving (Contemplating) Volunteering for a cause may make people care about it more, and be more likely to give to it. It is difficult for people to have volunteering experiences with most EA causes. People tend to volunteer for local and domestic causes, and their sympathy and giving may follow this (perhaps to avoid cognitive dissonance). Alternatively/additionally, the volunteering for the local cause may substitute for EG (via moral licensing or a related channel): ‘I volunteer for the Girl Scouts so I’m doing enough good, but I don’t need to donate to Against Malaria Foundation’ "],
["social.html", "6 Barriers: Signaling and social pressures/social identity 6.1 Signaling concern for effectiveness/impact versus other values", " 6 Barriers: Signaling and social pressures/social identity 6.1 Signaling concern for effectiveness/impact versus other values 6.1.1 Theory and argument Social signaling is seen to be a major driver of human behavior, particularly in the charitable domain.8 Essentially, we may make choices that we would not have otherwise made in order to boost our reputation among our peers, colleagues, etc.. Reputation may be valued for its own sake or instrumentally, as a means to inducing others to act more favorably to us. Game theory (see esp. (???)) offers a precise conception of this signaling as a costly way to demonstrate one’s positive “type” in a context with asndymmetric information. Several authors (can be interpreted to) suggest that valuing ‘’effectiveness in generosity’‘, i.e., moral-utilitarianism, is seen as a negative signal by peers and lowers fitness in the cooperation market, at least in comparison to signaling compared to deontological or ‘sacred values’. The exchange below captures the basic argument… From Robin Hanson and Rob Wiblin exchange on 80000 hours podcast; see Chapter 12 of “The Elephant in the Brain” (Hanson) Hanson: But of course people spend a lot of time directly helping even when they’re relatively well-paid and they could pay other people who earn much lower wages to do a lot more. Wiblin: This is the example of the high-flying lawyer dishing out soup in a soup kitchen. Hanson: … the alternative theory that we suggest is that you are trying to show that you feel empathy. That is you want to show there is an emotional capacity in you such that if you see someone around you in need you will feel like you want to do something about that. And existing charities do tend to successful show that. They show somebody who needs help in a direct way that invokes your emotions and you do help to some degree, you do the thing that people would say would help and that shows people around you that you’re not an uncaring person and it might show them, for example, that if they were in need of help later and they were near you you would see them and you would feel about them too. You want to show people that you will be useful ally. If either of you is in trouble the other will come to their aid. Wiblin: So why is it more important to show the people that you’re the kind of person who if they someone in pain that they’re going to try to help them right then and there than to show that you’re the kind of person who’s smart enough to think about which charities are useful and does their research and actually tries to help people? Because if you don’t care about whether charities are effective or not, my thoughts would just be that you’re not really going to pay attention to whether you’re actually helping your friends or not? Hanson: Right, but at least if I want your help and I’m your friend it will be my job to put myself in your face and to tell you about my problem. And maybe I figure I coul successfully get myself in front of your face and make you pay attention to my problem and help you understand what I think is effective and then you would just do what I say, and that’s maybe what I’m mostly hoping for. And if you were this person who thinks carefully about how to help the best person in the world who needs help, well I’m plausibly not going to be that best person in the world who needs help so I’m not going to win out in that contest so it’s not actually going to be that useful to know you as the sort of person who will help the person in the world who needs the most help. (Everett, Pizarro, and Crockett 2016) argue that deontological ethics signal stable cooperative behavior to others, which enhances fitness in mutualistic partner choice models. The basic argument is “An individual who claims [and believes] that stealing is always morally wrong … seems much less likely to steal from me than an individual who believes that the stealing is sometimes morally acceptable depending on the consequences.” Background and further discussion … in fold The authors’ motivation is to explore why “intuitive moral judgments often”share characteristics with deontological theories while “consequentialist judgments are often the result of slow, deliberative cognitive processes”. Their key theoretical argument cites “mutualistic partner choice models of the evolution of morality”, which… posit a cooperation market such that agents who can be relied upon to act in a mutually beneficial way are more likely to be chosen as cooperation partners, thus increasing their own fitness the typical deontological reason for why specific actions are wrong is that they violate duties to respect persons and honor social obligations-features that are crucial when selecting a social partner. An individual who claims that stealing is always morally wrong and believes themselves morally obligated to act in accordance with this duty seems much less likely to steal from me than an individual who believes that the stealing is sometimes morally acceptable depending on the consequences. Actors who express characteristically deontological judgments may therefore be preferred to those expressing consequentialist judgments because these judgments may be more reliable indicators of stable cooperative behavior. And recent theoretical work has demonstrated that -“cooperating without looking”—that is, without considering the costs and benefits of cooperation—is a subgame perfect equilibrium (Hoffman, Yoeli, &amp; Nowak, 2015). Therefore, expressing characteristically deontological judgments could constitute a behavior that enhances individual fitness in a cooperation market because these judgments are seen as reliable indicators of a specific valued behavior-cooperation. Hoffman et al (2015) present an evolutionary game theoretic analysis of an indefinitely repeated game where Here the analogy to effective versus ineffective giving is not clear… Player 1 can publicly ‘look’ to see the cost of cooperation, Player 1 next chooses to cooperate or defect, and then Player 2 chooses whether to continue repeating the above game, or end the relationship. They provide conditions under which ‘cooperating without looking’ (CWOL) is part of a subgame-perfect Nash equilibrium, and an evolutionarily stable equilibrium can involve a substantial rate of CWOL play. However, the analogy to effective versus ineffective giving is not clear. Perhaps a connection could be made if considering the charity effectiveness tended to provide a motivation to give less, but this is not obviously the case. In general, an ‘excuse not to do something’ is not the same as a ‘choice to be effective’. 6.1.2 Evidence 6.1.3 Evidence that “consequentialist choices lead to negative signals and less-favorable treatment relative to deontological/emotionally intuitive choices” 6.1.3.1 (Everett, Pizarro, and Crockett 2016) Everett, Pizarro, and Crockett (2016) ran a series of experiments on the Mturk platform, involving hypothetical dilemmas paired with low-stakes (or no) Trust games. In each, participants were asked to make and justify their judgement in a moral dillemma such as the famous ‘trolley dillemma.’ In each case, this was a (hypothetical) choice between inaction and taking an action that sacrifices a small number of lives to save a larger number of lives. Would you “push a man off a footbridge to stop an oncoming train from hitting five”? We then had our participants rate the morality and trustworthiness of each agent on a scale (Study 1a), play a hypothetical trust game (TG) with the agents (Study 1b), and, finally, play a TG involving real monetary stakes with the agents (Study Across several studies deontologist agents were preferred in partner choices by participants endorsing the same values; even moral-utilitarians seem to favor peers who express emotional empathy and deontological ethics (ibid., p. 45). However, this difference was not present in the track-switching dilemma, the only dilemma in which a majority favored the consequentialist choice. Incorporate some of the other papers mentioned in the Gdoc here 6.1.3.2 Montealegre et al. (2020) Does Maximizing Good Make People Look Bad? Manuscript Type of evidence: Online experiment (M-turk) with hypothetical choices (attitudes), six pre-registered studies using two different scenarios (N = 1,961) Relation to charitable giving: directly, since … Scenarios (including within and between subjects approaches): participants evaluate a response to survey question about how to select a charity (“If you were to donate, how would you select which charity to donate to?”). Deliberative: I would use evidence to calculate which charity spends its donations most cost effectively, and donate to them. Empathic: I would try to put myself in the shoes of people who are going through difficult situations, and donate to a charity that helped them. John was approached by a charity fundraiser and was asked whether he would be interested in donating to help Rokia, a 7-year-old girl from Mali, Africa who was desperately poor and faced the threat of severe hunger or even starvation. The charity fundraiser showed John a picture of Rokia (also presented to participants) and then asked John whether he would be interested in supporting her. Across conditions, participants were presented with the general scenario and only the potential donor’s actions differed depending on the condition: Deliberation: “John thought that donating to help Rokia might not be the most cost-effective way to use his money and that maybe he should donate to a charity doing something more cost-effective instead. He asked the charity fundraiser about the relevant statistics of the program and since the data suggested this charity was the most cost-effective John donated to the charity.” Empathy: “John was deeply moved by Rokia’s situation and about how terrible her situation must be for her. After hearing about her tragic story and imagining how his donation could help her John donated to the charity.” Robustness checks for: gender, stake size Background mechanism: donors’ failure to prioritize cost-effectiveness can be explained by signaling concerns, since people who favor deontological over consequentialist decisions are preferred as social partners (Everett et al., 2016), Key findings: Across six studies, donors who deliberated were perceived as having worse moral character, were rated as less desirable as social partners, and were judged to be less guided by moral motives. On the other hand, those who deliberated were also seen as more reasonable and competent, and were judged to be more guided by pragmatic motives, Thus, there may be reputational benefits associated with deliberating. However, since deliberators are less preferred as social partners the authors believe the overall effect one reputation is negative. They do not find any differences in trustworthiness. Exhibiting empathy before deliberating reduced most negative reputational effects. People how do not give at all are seen as the worst. Surprisingly, participants judge the empathy donors as more wastful. 6.1.3.3 Considerations Even if we accept the above evidence (that those who make consequentialist active choices in “sacrificial dilemmas” are seen as less trustworthy and less moral) this may not generalize to effective giving. Researching and selecting a more effective charity is closest to the ‘track switching’ scenario in these experiments, in which no substantial difference was observed, and even here it is a stretch. Choosing a more effective charity instead of a more local one (e.g., river blindess prevention in Africa versus local guide Dogs) would be hard to cast seen as taking an active step to harm someone. True, a local blind person may fail to get an additional (fraction of a) dog as a result of this choice. However, there is little sense in which “you funding his dog” would be seen as the status quo absent your intervention. 6.1.4 Indirect evidence (Kahane et al 2018; Jordan et al; Hoffman et al) List of references "],
["eval-aversion.html", "7 Barriers: Aversion/obstacles to doing (and using) evaluations 7.1 General cost-benefit analysis (CBA)-aversion or reluctance 7.2 Market versus social norms 7.3 Cost effectiveness information may turn off System-1 and reduce giving; statistics diminish impact of ‘identifiable victim’", " 7 Barriers: Aversion/obstacles to doing (and using) evaluations Note: this is an ongoing project of David Reinstein with several co-authors, including ongoing field experiments as well as meta-analysis being planned. Much of this project is organised in the dualprocess repo 7.1 General cost-benefit analysis (CBA)-aversion or reluctance This is hard to label: ‘aversion’ may be the wrong word: people may finding it less appropriate/normal/virtuous to do CBA in a charitable context, or it may naturally not occur to them to do it. 7.1.1 Description People may be reluctant9 to consider the cost and benefits of the actions they are funding through their charitable donations (or they find this less appropriate/normal). This contrasts with a much greater willingness to consider these and other domains such as consumption, investment, and public policy. People also seem to avoid accessing/buying/seeing information (particular information that may be likely to feel compelled to give.) 7.1.2 Theoretical/conceptual discussion For this to be considered a bias, the relevant individuals must intrinsically value the usefulness of their charitable activity at least to some extent. I.e., they must be Moral Utilitarians, at least in part, or for some of the time. However, they may consider it very costly or distasteful to actually do this evaluation, or it may clash with other motivations and tendencies. This aversion also must be distinguished from a lack of ability to do CBA in the charity domain; the latter would instead be considered a quantitative bias. The reluctance to engage in this evaluation process may relate to the aforementioned10 “taboo trade-offs”; if these tradeoffs are taboo, considering them may involve great emotional distress. (???) refer to the idea that “believing that charity is a subjective decision licenses individuals to donate in personally gratifying ways.” This perspective plausibly combines partial and conflicted Utililitarian preferences with the presence of moral licensing. As Berman et al note, the belief that CBA is not a natural part of the charitable domain may stem from the lack of direct feedback one gets from donating (in Economics terms, a “credence” good) relative to consumption and investment goods. (they cite: Imas paper?) Several papers11 find that people are reluctant to pay for—or actively seek to avoid— certain information. However, these may reflect motives distinct from CBA, such as a self-serving bias. On the other hand … a majority ranked effectiveness [how highly?] as a crucial criterion to select a charity and reported greater happiness when the impact of their contribution wasis highlighted.(van Iwaarden et al. 2009; Aknin et al., 2013) 7.1.3 Relevance to Effective Giving If determining which charity is effective requires CBA people may avoid doing so. If effective charities force people to consider CBA then people may avoid these charities in order to avoid having to do these evaluations. 7.1.4 Evidence Evidence for “People sometimes actively avoid information about charity effectiveness that would motivate doing a CBA…” (???) run dictator game experiments involving payments to real-life welfare recipients living in 178 public housing in Pittsburgh; each subject is matched with a particular recipient of their potential donation. In their “Choice treatment”, a subject can choose to pay $1 to learn about a recipient’s drug use or disability, information meant to suggest the deservingness of the recipient. “We find that a third of the dictators are willing to pay money to learn more about their recipient. Dictators who acquire information mostly use it to withhold resources from less-preferred types, leading to a drastic decline in aggregate transfers.” But this needs to be interpreted carefully: those who decide not to buy information appear less generous than the average! (???) provide evidence that people will pay costs to avoid being asked and avoid social pressure. However, for this same case if they are asked they then to respond by giving. While “avoiding the ask” is not avoiding cost-benefit analysis, it suggests that people are in fact strategic in avoiding things that may make them feel compelled to donate. Note: This evidence is only tangentially relevant. Evidence for “People rarely seek out effectiveness information and are reluctant to purchase it” In (???), in a final stage of her experiment: Subjects were given the option to spend USD 5 of their total gift to the development charities in order to find out which of the three would receive a matching rate of USD 3 (the other two would receive matching rates of USD 1.50). Altruistic subjects whose donation was at least USD 20 and gave to all three charities, or whose total gift is greater than USD 35 and gave to two charities, would find it profitable to purchase the information. … (84%) met these criteria on gift size and number of charities supported. …only 40% of subjects were willing to give up a small portion of their endowments in order to find out which charity would receive the highest rate; the rest preferred to allocate their gifts without knowing what they would be worth to the charities.\" ...These subjects who chose not to purchase the information forfeited matching funds ranging from 30-150% of the value of their unmatched gifts, with the median donor sacrificing matching funds exactly equal to the value of her unmatched gift, a truly staggering sum. Null attributes this failure to buy information either to subjects who “simply did not care about the potential to substitute into the charity with the highest matching rate”, perhaps driven by some form of simplistic warm glow motive, or to simple misunderstanding or fatigue (in an incentivized elicitation, she found some evidence of incomplete comprehension). To the extent this is not a misunderstanding, it might be seen as evidence of CBA aversion; participants did not want to purchase evidence that would require them to do calculations in this domain. 7.1.4.1 Evidence for “People do not respond ‘efficiently’ to information about costs and benefits” Null (2011) ran a set of experiments at Kiwanis/Rotary clubs and with “professional subjects” (university administrators?) at the Berkeley X-lab; the former strictly involved allocations among charities, in the latter case what was not given away could be kept. For the main reported treatments, participants made a series of decisions under different incentives (mostly on the same page and thus simultaneously?). The “prize” was $100; in each session only one decision from one subject was chosen for actual payment/donations. Many participants who choose to donate positive amounts to multiple charities in earlier (?stages) continue to donate to multiple charities when one charity is given a better match rate; they only “imperfectly substitute” (and some even substitute away from the now “lower-priced” charity). She attributes this to both risk aversion (diminishing utility in to each charity’s actual impact, along with uncertainty about this impact) as well to as a version of “warm glow” with a diminishing marginal benefit in the amount given to each charity.12 However, this could also be attributed to a simple failure to make these cost-benefit calculations (as she also found some evidence suggesting misunderstanding of the nature of these incentives). 7.1.4.2 Evidence for “people accept and value subjectivity in the charitable domain more so than for other choice domains” Berman et al (2018) provide evidence from a series of five survey/vignette experiments; unlike those mentioned above, these (mostly) involve hypothetical choices among multiple causes. All experiments use standard subject pools (behavioral lab subjects or m-turkers) with reasonably large samples. All ask for hypothetical (Likert-scale) responses involving fictional charities, investments, and other scenariae; they mostly rely on between-subject responses, and their statistical analyses report reasonable tests on the relevant comparisons. Their “Study 1: Perceived Subjectivity of Charity” found that, in rating statements such as “it is important that the ______ I choose reflects my personal tastes or values” and “It is more important to rely on objective measures rather than personal feelings when choosing ______ ... they found people agreed more with the subjective/taste approach when assigned a treatment where the blank was”Charity\", relative to those assigned treatments involving medical treatments, investments, and cel phones. (But less than some other things like art, and similar to restaurants in some tests!) Their “Study 2: Personal Feelings Versus Welfare Gains” presented participants with “Mary” and a pairing of fictional domestic (homelessness) and international (micronutrient) charities, presenting effectiveness information on both (clearly favoring the latter). The treatment-- which charity Mary felt an emotional connection to-- had a significant impact on the response to “Which charity should Mary donate to”, in the predicted direction. They were also asked: “Which option does the greatest good for the greatest number of people?”; here responses favored the international charity for both treatments; but even so, when Mary felt connected to local charity, participants favored donating there. Berman et al argue that their results demonstrate the acceptance of the suggestive preferences is somewhat attenuated by the \"role of responsibility\", but it's not clear what this term means or how this could be relevant to voluntary individual giving. In their “Study 3: Charity Versus Investment Choice”, subjects were assigned categories and fictional examples of either charities or investment, and presented domain categories and effectiveness information for each. Fewer participants in the charity treatment (relative to the investment treatment) chose to sort by effectiveness rating, and fewer chose the highest rated option. In Study 4, they find that, in rating research departments for funding, participants pay more attention to charity effectiveness ratings when the are given the “role” of a “president of a local medical research center” rather than a donor. Similarly, in Study 5 participants assess someone who allocates funds to a research department; participants respond to the effectiveness of the department chosen more when rating the decision quality and altruism/selfishness of a “president…” than rating a “donor”. Overall, these suggest that, when considering charitable donations, people tend to favor–or at least to accept–the use of subjective preferences and personal ties, rather than objective information, and they do so more than for more “standard” goods and choices. This is more accepted for “donors” than for people with responsibility for others’ funds. Berman et al argue that their results demonstrate the acceptance of the suggestive preferences is somewhat attenuated by the \"role of responsibility\", but it's not clear what this term means or how this could be relevant to voluntary individual giving. However (as they do note), the effectiveness information still has some (positive) effect on participants’ responses; it is not ignored. Their experiments also do not analyze the avoidance of information or CBA. Methodological strengths and weaknesses: …(E.g., hypothetical nature of choices; some evidence these are not taken seriously; specific context in vignettes allow alternative interpretations…) 7.2 Market versus social norms “People see charity as in the social ‘domain’ not the market one, and thus find it strange to apply CBA to it.” 7.3 Cost effectiveness information may turn off System-1 and reduce giving; statistics diminish impact of ‘identifiable victim’ References: small2007sympathy_s3_s4, small2007sympathy_s1_s2, karlan2017effect, bergh_Reinstein smeets2015giving See also: karlan2017effect, “Parsons, 2007” how observed/manifested?↩ where?↩ ref↩ She also introduces exogenous risks over matching rates, and notes that roughly 2/3 of those that choose to shift only imperfectly are not measured to be \"risk averse\".↩ "],
["quant-biases.html", "8 Barriers: Quantitative biases 8.1 Biases in perceiving impact 8.2 Other biases driving departures from efficiency 8.3 Proportional dominance effect 8.4 Statistical/identifiable victim effect 8.5 Availability heuristic 8.6 Overhead aversion 8.7 Possible: Misunderstanding need (and misunderstanding marginality/tractability/sunk costs?) 8.8 Scope insensitivity/embedding effect/part-whole effect 8.9 Other possibilities: “Risk aversion”, Lack of tangibility, Corruption aversion", " 8 Barriers: Quantitative biases 8.1 Biases in perceiving impact Cognitive biases: Overweighting and underweighting probabilities, misunderstanding marginality, scope-insensitivity, Opportunity-cost Neglect. etc. Identifiable victims effect. small2007sympathy_s3_s4, Gneezy2014, small2007sympathy_s1_s2 kogut2005identified, kogut_2005b, Kinsbergen_tolsma_13, summers_1997, galanter_1962 8.2 Other biases driving departures from efficiency 8.3 Proportional dominance effect AKA ‘drop in the bucket’, ‘psychosocial numbing’, ‘psychophysical numbing’ Proportional dominance effect/drop in bucket/psychosocial numbing/psychophysical numbing 2.7 Quantitative biases 8.3.1 Definition Related Terms include: Drop in the bucket; mechanisms include “futility thinking” (Unger?), psychosocial numbing, quantitative confusion/innumeracy This claim can be summarized as follows: (For a given per-dollar impact on the outcome), people are be less willing to donate towards a cause when the magnitude of the underlying problem is (framed as) larger. Mechanism: Underlying this is the idea that a certain amount of impact (e.g., relieving suffering) is perceived as smaller and thus less valuable when the underlying problem is larger. 8.3.2 Conceptual Discussion Overview of findings from papers, caveats, how the concept works, etc. Provides context for evidence section; Discussion of the relevant mechanisms at play; Discussion of the relevant established theories. Definitional issues and disambiguation This needs to be distinguished from scope insensitivity. Note that if people are being analytical, they must care about scope in order to care about their impact, and thus (mistakenly) react to the perceived lower impact of donating when the needs are much greater. PD arguments may also be used as vehicle for motivated reasoning, and thus not be an important driver in itself: E.g., I don’t want to donate so I focus on my impact being a share of the overwhelming need (which I might opportunistically define broadly) to conclude that helping is futile. Note (unfold)… BG: My thought was that people who do not value saving lives (or are in general unwilling to contribute to it or oppose policies spending money on foreign aid for some other reason, e.g. prejudice) exercise a form of motivated reasoning to justify this (perhaps in a nonstandard way). They choose to reason according to the ‘proportional’ standard in order to conclude that it is not worth mdonating to these causes because ‘the scope of the problem is too large and they will never be completely solved’. I suggest that people apply this reasoning to problems specifically when they do not want to take action to address these problems. (In contrast, in domains where they do want to make a change, they may use a different, more marginal and 'consistent' sort of reasoning.) E.g., (to be stereotypical) imagine a MAGA person who wants to end foreign aid because \"Africa will always have endless problems\" but who wants to impose restrictions on abortion (even knowing millions of abortions will continue to occur) because \"every unborn life matters. To operationalize this, we need to define what the numerator and denominator represent. For the numerator, an (EA) impact-driven individualist donor might consider of her own contribution (per dollar or overall) relative to the size of the need. In contrast, a more collectivist/team-reasoning/communitarian thinker might consider the impact of the total expected donation relative to the size of the need. We also need to better define the denominator; how do individuals lump together different groups/problems to define the overall scale of the need, and how sensitive is this to the fundraisers’ framing? Mechanisms Fetherstonhaugh et al (1997) highlight “Weber’s law”: Humans are sensitive to proportional changes/proportional differences in stimuli (loudness, brightness, etc); thus we are less sensitive to small changes relative to a larger baseline. There is evidence this also holds in assessing losses of life. ... the “subjective value of saving the specified number of lives is greater for a smaller tragedy than for a larger one” . Baron attributes PD to quantity confusion and classifies this as “contamination by an irrelevant factor”; more generally, this could be seen in terms of innumeracy. This may lead to a lower willingness to contribute to a problem when the apparent scale (or “denominator”) of the problem is larger (e.g., more lives at risk), holding constant the benefit per dollar contributed (cost per life saved). The perceived scale of the problem may depend on how it is framed by fundraisers, charities, and the media. However, this may not be completely manipulable: e.g., massive global problems may not be easy to “frame down.” “Loewenstein and Small (2007) suggested that the PDE is driven by increased sympathy towards the victims when one can help a large proportion of the victim reference-group.” -- Erlandsson et al 8.3.3 EG Relevance How this particular barrier proves problematic for effective giving. This effect represents a general departure from appropriate assessment of the marginal benefit (per cost) of a particular charity/intervention. Thus this is a general barrier to accurate assessment of effectiveness ergo a barrier to effective giving. In addition, it might be argued that more effective interventions (e.g., targeting poor Africans versus US poverty) may tend to address problems that are inherently larger in scale and magnitude. These may be intrinsically harder to “frame down”, implying EG will suffer more from this bias. 8.3.4 State of Evidence Key papers: Summarize findings and key takeaways, Short description of methods for relevant studies, Make sure to include both description of evidence and evaluation of evidence Fetherstonhaugh et al 1997 (notes HERE) Methods Range of hypothetical scenariae and evaluations, within-subject manipulations only (with clear contrasts), framed as aid/targeting not charitable donations, standard (mostly Economics) student subject pools. These authors conducted survey experiments on standard (fairly small sample?) student participants. They presented a variety of hypothetical scenariae (e.g., “imagine themselves as a government official of a small, developing country”...), asking for ratings, rankings, etc. Findings Studies 1 and 2 found that an intervention saving a fixed number of lives was judged significantly more beneficial when fewer lives were at risk overall. Study 3 found that respondents wanted the minimum number of lives a medical treatment would have to save to merit a fixed amount of funding to be much greater for a disease with a larger number of potential victims than for a disease with a smaller number. **Evaluation of paper’s evidence:*]{.underline}** Strengths - Reasonably realistic frames, (mostly) consistent results across a variety of frames Limitations - Hypothetical, framed, nonrepresentative, and does not directly address own contributions Within-subject treatments here: (+) allow estimation of heterogeneous responses, (+/-) highlight the difference in denominators/proportions, making them salient; but this might also be expected to be an inhibitor of this (seemingly non-rational) effect, especially for the Economics-trained sample Statistical tests (ANOVA) appear strong and highly significant in most cases, but further investigation warranted (e.g., pre-registration? Evidence of specification fishing and MHT?) Erlansson et al (2015) (Study 4) The PDE-ad was in part based on text from the homepage of a well-known global charity organization focusing on poverty in developing countries. Participants read about Polio and were told that if receiving the expected amount of private donations, it would be possible to vaccinate children so the death rate would decrease by approximately 500 children per year. In the large reference-group version, participants read that 60,000 children in Africa annually die from Polio so the project had a potential rescue proportion of 0.83%. In the small reference-group version, partici pants read that around 500 children in Botswana annually die from Polio so the project had a potential rescue proportion of more than 99%. ...followed by eight questions about participants’ reactions towards the advertisement. The suggested mediators (distress, sympathy, perceived impact and perceived responsibility) were measured with two questions each ...after reading and responding to the three ads, participants were told that thanks to their participation, 10 Swedish Kronor (SEK) $1.50 would be donated to charity. The participants were asked to allocate the money between the three organizations by writing an amount (0–10) after each ad and the sum had to be 10 SEK ...All participants read either one ad from the low end of the effects (statistical victim, large reference-group, out-group victims) plus two ads from the high end of the effects (identified victim, small reference-group, in-group victims) or two ads from the low end plus one ad from the high end. [Results] Participants who read the PDE-ad in the small reference-group version had higher helping intentions (M = 3.77, SD = 1.64) than participants who read the large reference-group version, M = 3.46, SD = 1.57; t(430) = 2.01, p = .045. However, participants who read the small reference-group version did not write that they would donate more money if asked (Mean rank = 213.68) than participants who read the large reference-group version (Mean rank = 218.31; Mann–Whitney U = 22720.50, Z = 0.40, p = .686). Despite this, participants who read the small reference-group version allocated more money to the organization distributing Polio- vaccines (M = 4.30 SEK, SD = 2.85) than the participants who read the large reference-group version, M = 3.50 SEK, SD = 2.87; t(430) = 2.91, p = .004. Although not perfectly consistent between the different outcome variables, the results suggest that we replicated the PDE. Evaluation of evidence (Study 4): Strengths - Realistic charity frame, reasonable implementation of small/large “reference group” frames, outcomes record both intentional/attitudinal and actual (small) donation measures Limitations - A choice among charities only Statistical tests - Brief on tangential papers (non charity) and papers supporting the mechanism Baron, 1997: “Confusion of Relative and Absolute Risk in Valuation” Methods Hypothetical willingness to pay (wtp) questions. Within-subject manipulations only; standard student subject pools, small samples. They do reverse order of presentations for half the participants. They report a lack of significant order effects, but fail to discuss the power of such tests or examine first-presented choices in isolation. S1: Questions about (hypothetical wtp for components of government government health insurance. “[Denominator] people die from this disease each year. Their average age is 60. How much are you willing to pay to cover a treatment that will save the lives of [Numerator] of these people?”… (Numerator=90 or 900; Denominator=100, 1000, or 10,000), all combinations presented to all participants. S2: Set of causes, each gave wtp for a government program for a 5% reduction in that cause of death and for saving 2,600 lives, also rating prevalence and importance. He reports a very high correlation between wtp by these two measures, an “insensitivity to quantity”, and both wtp measures are higher when subjects report a higher prevalence (even controlling for stated importance). Evaluation of paper’s evidence: This evidence appears highly limited. There is some evidence that denominators matter when they (arguably) should not, and participants show confusion between proportions and absolute amounts. The second experiment is highly cognitively demanding and participants have no strong incentive to “get this right.” The first experiment has arguable confounds: e.g., one might question the scientific credibility of the treatment that (claims to) save only a small number of lives out of a very large population. The evidence does not seem to offer much strength over and above the Fetherstonhaugh paper. I also found much of the statistical reporting to be incomplete or unclear, especially for study two. In general, this is, at its best, evidence of quantitative confusion which may go in either direction in any given context. It is also detached from the charity realm, considering the domain of government expenditure and benefits that will accrue to the participant him or herself. For this reason, I listed it is tangential evidence and not charity specific evidence. Jenni and Loewenstein (1997) Provides support for the “reference group effect” (proportional dominance) as an explanation for the identifiable victims bias. (notes HERE) Friedrich et al (2008) PN was investigated by varying the supposed number of brak- ing-related traffic fatalities each year as a within-subjects variable and then obtain- ingjudgments of support for a new antilock brake requirement. Experiment 1 manipulated respondents’ accountability [“…the experimenter will ask you at this time to explain the reasoning behind your decisions and to justify how you arrived at your recommendations”] as a way of exploring whether PN responding is the result of careless or heuristic processing. Extensive work with accountability manipulations has shown them to be effective in debiasing… [other stuff]. … when they expect to have to justify their reason- ing to others, should also be revealing in terms of what they believe constitutes a defensible, normative strategy. [also] a manipulation designed to highlight the salience of the individual lives at risk … [a] description of a preventable, fatal accident with named individuals… , par- ticipants read that the “Federal Transportation Board” estimated annual fatalities due to driver error in the use of conventional braking systems to be approximately 41,000 (“large problem”) or 9,000 (“small problem”). Outcome measures: “support-for-intervention”, 7-point scale “Lives-to-save” “What is the minimum number of these (9,000/41,000) lives at risk … saved each year before you… require consumers &gt; to pay for anti-lock brakes” Treatments started with one size, then presented a “task force’s new estimate” with the reverse. Overall evaluation of evidence Evidence gap and suggestions for future work and approaches 8.3.5 Potential Solutions Framing Frame down denominator (suggestive evidence from Fetherstonhaugh, etc) Report absolute or proportional number of lives that could be saved by an intervention depending on which suggests a smaller denominator (how do you know?) Highlight numerator (impact) (evidence?) (Ari:) “Increase evaluability: putting interventions on same page instead of separate pages” De-biasing (discussed further in Friedrich et al - expand) Consider: “The proportion dominance effect was primarily mediated by perceived impact.” (Erlandsson et al, 2015, OBHDP) “Perceived Utility (not Sympathy) Mediates the Proportion Dominance Effect in Helping Decisions” (Erlandsson et al, 2013) 8.4 Statistical/identifiable victim effect Cite: Hsee13, small2003helping, kogut2011identifiable, small2007sympathy_s3_s4 8.5 Availability heuristic (in probabilities?) People judge the probability of events and the importance of problems by the ease by which they can be brought to mind. This may impact the importance they ascribe to causes and charities. Effective causes may be distant and underreported, for various reasons. Furthermore there may be a set of charities that are for a variety of reasons underreported or unconnected to the lives of the majority of donors; these will be neglected (and thus more effective by dint of a lack of funding). Effective causes may be distant and underreported, for various reasons. Furthermore there may be a set of charities that are for a variety of reasons underreported or unconnected to the lives of the majority of donors; these will be neglected (and thus more effective by dint of a lack of funding). 8.6 Overhead aversion Study finds ‘no correlation’ between overhead and effectiveness– is it convincing? Does working abroad increase overhead? Most relevant tie: doing impact evaluation will itself increase overhead. References: Gneezy2014, Portillo_Stinnb2018, Kinsbergen_tolsma_13, Mayo2009, Meer2017 Chhaochharia_Ghosh_08?, Caviola2014, Qu? 8.7 Possible: Misunderstanding need (and misunderstanding marginality/tractability/sunk costs?) Related terms: misunderstanding marginality, misunderstanding tractability, sunk cost fallacies Misperceiving tractability: donations may respond to number of deaths from a disaster rather than to the scale of the need of survivors (sunk losses) donations may respond to average cost per life saved, rather than marginal cost per life General barrier to accurate assessment of effectiveness ergo a barrier to effective giving. 8.8 Scope insensitivity/embedding effect/part-whole effect “People’s stated valuation or”willingness to pay\" for an outcome seems not to strongly increase in the magnitude of that outcome. For example, when asked in isolation people might say they are willing to pay $50 to save 100 eagles. Other people asked in isolation may say they are willing to pay $50 to save 5000 eagles. Kahneman1992 (Part I: Embedding effect): the expressed willingness of Toronto residents to pay increased taxes to prevent the drop in fish populations in all Ontario lakes was only slightly higher than the willingness to pay to preserve the fish stocks in only a small area of the province.\" When assessing effectiveness in determining which charity to donate to (and how much), a utilitarian should be very sensitive to the scale of the impact (essentially the benefit per cost). If people are scope insensitive they will be bad at making these judgments (particularly when presented in isolation). Ref: Hsee13 8.9 Other possibilities: “Risk aversion”, Lack of tangibility, Corruption aversion See Airtable "],
["inertia.html", "9 Barriers: Inertia and systemic/institutional 9.1 Social norms", " 9 Barriers: Inertia and systemic/institutional 9.1 Social norms Social norms promote giving to traditional non-EA causes and fundraisers, and responding to peer requests. –&gt; crowding out? Norms may also suggest giving to causes like AMF is “weird”. Asks (Own category?) Donation requests increase the propensity to give (Yoruk). There is a conventional wisdom that “most donations occur in response to an ask”. If there are systematic asks for non-EA causes this may crowd out EG. "],
["tools-for-motivating-ea-giving-1.html", "10 Tools for motivating EA giving 10.1 Introduction 10.2 Psych/behavioral tools; applicability to EA charities 10.3 De-biasing and misperception correction 10.4 Innovative proposals 10.5 EA-movement approaches, sucesses and pitfalls 10.6 A listing", " 10 Tools for motivating EA giving 10.1 Introduction What “tools” and approaches may help to increase effective giving? We divide this into three categories: Approaches to overcoming the barriers and biases discussed in previous chapters. Fundraising approaches and innovations that will be particularly suitable for more effective charities, perhaps because these approaches themselves are directly tied to effectiveness. We call these “superpowers” for effective charities. Fundraising strategies that may have historically been underused by affective charities. 10.2 Psych/behavioral tools; applicability to EA charities Do the standard collection of psych/behavioral tools work for EA charities, or can they be made to do so? Does EA have any ‘superpowers’ for any of these? E.g., presenting identifiable victim. Emotional stimuli. Gift exchange, etc. Briefly highlight those ‘tools’ that give non-EA an advantage, but focus on the actionable–how EA lessen or flip that advantage. 2. Which tools present particular challenges or opportunities for EA 10.3 De-biasing and misperception correction 10.4 Innovative proposals 10.5 EA-movement approaches, sucesses and pitfalls What has EA tried and how has it worked; evaluate approaches in light of the evidence. Is the movement too ‘purist’ (e.g., focusing on only the most effective, proven charities instead of those with broader potential appeal but less evidence)? 10.6 A listing Make impact more comparable by allowing joint evaluation (Evaluation mode) Effective charities could present their (e.g., lifesaving) statistics relative to average/popular charities (but be careful about demonizing particular ones) Theory: Evaluability bias Cite: (Kogut &amp; R, ’05), (Caviola ea, ’14) 10.6.1 (Info enhancing) social closeness of recipient Percentage donations tied to purchases, especially in online auctions Psychometrics and targeting people likely to be responsive "],
["conclusion-agenda.html", "11 Conclusion; a research agenda", " 11 Conclusion; a research agenda Need for systematic platforms to study this, systematic experimentation and data sharing among effective/international charities. Platforms available, proposals for particular research projects and approaches. Who gives to the truly most effective international charities? Who is most likely to be convinced, and which arguments/presentations work in the SR and LR, and for whom (heterogeneity)? Statistical learning-based analyses Practicable techniques in a range of higher-stakes real-world environments Replication (and verification), pooled evidence, meta-analysis Context-sensitivity, large SE \\(\\rightarrow\\) large samples, statistical learning controls, sharing data Responses to ‘obvious contrasts’ seem to not reflect between-subject responses\" "],
["bookdown-appendix.html", "12 Appendix: Tech for creating, editing and collaborating on this ‘Bookdown’ web book/project (and starting your own) 12.1 Introduction 12.2 Git and Github 12.3 R and RStudio 12.4 Markdown and Bookdown 12.5 The code and folder structure in this repo, and what it means 12.6 The code in a single “.Rmd” file and how it translates into content 12.7 How to ‘build’ and view the book 12.8 Joining this project 12.9 Airtable and innovationsinfundraising.org 12.10 Useful resources", " 12 Appendix: Tech for creating, editing and collaborating on this ‘Bookdown’ web book/project (and starting your own) This tutorial written by Oska Fentem with David Reinstein 12.1 Introduction This appendix provides a brief introduction to the several types of software and processes used to creating websites such as Increasing Effective Charitable Giving and Researching and writing for Economics students. We aim to encourage others to participate in this collaborative work, and to spin off their own projects. If you would like to provide feedback or ask a question about these projects then using ‘hypothes.is’ is an easy way to do so. The template for my bookdown projects is maintained in my repo here This site (web-book project) is Hosted: Hosted on Github (Github pages) A project managed out of a Git repo stored in Github The content is: A ‘Bookdown’ (in the ‘Gitbook’ style, although we’ve drawn elements from the Tufte style) …which is a hosted collection of HTML (and other) files… …constructed/compiled/built from R-Markdown (.Rmd) files and other support files using the R language This relies heavily on: ‘Markdown syntax’ for basic writing/formatting Latex for mathematics notation Bibtex for references/citations ‘Pandoc’ to convert between different document formats CSS (style sheets) To build this, we chose to use tools and software including: The RStudio environment for working with R code Github desktop to manage pushing/pulling and integrating content (although sometimes we use raw Git) Features of the GitHub website such as ‘projects’ We first give a brief overview of R &amp; RStudio, Git &amp; Github, and R Markdown &amp; Bookdown, linking more extensive further resources/tutorials. 12.2 Git and Github Git is a version control system which enables users to track changes and progress in coding projects or any files in general. It is particularly useful for collaborating on projects as it provides a useful way to show who has altered which files and when. Users are even able to clone a repository (a folder inside of a project which tracks all changes made) and make changes without affecting the original project. Git also provides a very simple way to keep changes to projects up to date across different operating systems such as Windows and Mac. Installation and configuration of Git can be confusing to the newly-initiated user, Happy Git provides a user friendly tutorial on installing Git, which can be downloaded here. Getting a Github account should take about XXX minutes. Here’s a guide to exactly how to do it. Installing Git and the GitHub Desktop should take about XXX minutes. Here’s a guide to exactly how to do it. 12.2.1 Some key things to know about Git and GitHub A brief overview of key functions inside Git (assuming a remote Github repo) including commits, pushes &amp; pulls, forks &amp; branches and pull requests: (unfold) Cloning a Git repository copies an existing Git repository into your local file space. A commit saves the changes made in the current document to the local repository. Specific changes to commit to the remote (online) repo must be specified. This process is made much easier using a program such as Github Desktop rather than the Git code itself (although they do the same thing, and the latter is more flexible). A push, pushes all local commits to the online version of this repository, essentially updating the online version of the files, to the version which is stored locally on your device. A pull, is used to pull the changes made to the online repository, into the local repository. Thus making the local repository up to date with the remote/online repository. Creating a branch allows you to create a separate version of a repository and make changes to this without affecting the master/original repository. A pull request then allows you to pull the changes made in a branch over to the master repository, in order to merge the work. As noted, Github Desktop provides a user interface for a more simple and intuitive way to use Git. There are a variety of other interfaces. Github can also be integrated into RStudio and into many other tools, such as the Atom text editor. Repos that are stored on Github can be accessed via a browser at github.com. The Github website itself provides a wide variety of tools, discussed further below under ‘GitHub web page’, Git and GitHub can be a bit confusing. Here are some things that I wish I had known, that took my a while to figure out (unfold) Git and Github are not the same thing … (explain) A ‘commit’ does not actually change the files in the shared (remote) Github repo; you need to ‘push’ to do that After ‘pulling’ from the remote repo, you may need to merge changes… (explain) You can have several different ‘branches’ of the same Repo existing at the same time. When you switch to a new ‘branch’ the files you see on your computer will instantly and amazingly change to exactly the files in that branch. But don’t worry, the old branch is not lost. … add some more 12.3 R and RStudio R is a free programming language which is mainly used for data analysis and statistics. It can be downloaded here. The popularity of R is growing in Economics Academia, largely due to the growth of Machine Learning techniques in R as well as the flexibility of the language itself. R makes use of packages which are a collection of functions written in order to achieve specific tasks. Whilst R comes pre-installed with a variety of useful packages, it is often useful to install more, which can be done using the install.packages command. If you are familiar with Python, these R packages are roughly comparable to Python’s modules. Installing R should take about XXX minutes. Here’s a guide to exactly how to do it. RStudio is a programming environment and interface which helps facilitate a variety of tasks such as writing scripts using R (as well as other languages), and building/knitting these into various document formats. RStudio ‘Addins’ can also be extremely useful for things like tracking ‘todos’, adding citations, and formatting code. RStudio can also be configured so as to work seamlessly with Git (more on this later). RStudio can be downloaded here Installing and configuring RStudio should take about XXX minutes. Here’s a guide to exactly how to do it. 12.4 Markdown and Bookdown Markdown is a popular set of formats (really a ‘syntax for specifying output’) for generating and authoring documents. The Rmarkdown format (rmarkdown package) is one flavor of Markdown that works with R to enable ‘dynamic documents’ involving text, data-analysis, and other elements. It can then export your work to a variety of outputs such as html, pdf and word documents. As well as this it can also be used to create webpages, such as the one you are currently reading. The power of Markdown files comes from the way that they are able include/embed code as well as data and tables, which is useful for writing reproducible research and creating websites. The Bookdown package was built on the Rmarkdown package, but it adds many features to enable larger and more structured output, particularly ‘web books’ and web sites. As we use it, this these books combine multiple Rmarkdown files, with each such ‘Rmd’ file becoming its own HTML page. Look at the list of headings on the left of this page: each second-level header is it’s own web-page (a distinct html link). “All the content in one scrolled page” is limited to a single first-level header. 12.5 The code and folder structure in this repo, and what it means 12.5.1 Writing_econ_book: Files-folders of interest (taken from readme March 2020) docs: html output put here for web hosting Folder: writing_econ_book bookdown.yml: determines which files are included in the book writing_econ_gfm.Rmd: The main content; body of the book (many chapters) index.Rmd: Setup content and some styling/parameters; determines how the book is built (into which format, etc) header_include.html: Important commands included here including folding boxes references_cut.bib: bibtex references referred to in ‘(???)’ notes tufte_plus.css: Determines layout and styling writing_econ_book.Rproj: ‘project’ … to work on this in R-studio 12.6 The code in a single “.Rmd” file and how it translates into content 12.6.1 Basic (R-)Markdown The Markdown format offers a simple plain-text notation for specifying the elements of documents, reports, web sites, etc. (It is much simpler and easier to read than html, latex, etc.) It is widely used by programmers, on comment boards/forums, and throughout the internet. For example, GitHub.com automatically renders markdown code, particularly in readme.md files. Actually there are several varieties of markdown, but they mainly share key elements. Markdown documents are usually saved as plain text files with the extension .md, e.g., report.md. These allow for an easy way to create a variety of outputs, particularly reports and text-focused web pages. The markdown format is converted into other formats (html, latex, etc.) with a variety of tools, particularly something called Pandoc. What is Pandoc? Pandoc is a tool (a program) for converting from one document format to another. It is incredibly powerful. The great thing about a format like markdown, or r-markdown, is that it is simple to write and peruse, and, with the help of Pandoc, it can convert into many many other useful formats for web pages, documents, presentations, etc. Pandoc is built into other tools including the RMarkdown package (see discussion on Stackexchange here). You can also install and use Pandoc directly in the command line, or try it out (in a limited but still useful way) on the web here For more on Pandoc visit pandoc.org In the R (statistically focused) language there are tools such as knitR that allow R users to produce reports combining text, statistical output, and interactive content. These are generally written in “R-markdown” documents, saved as .Rmd rather than .md files. The R-studio interface, and several “add-ins”, also help facilitate this. This interface is very useful; in fact, it may be convenient to build web books and other content using this even if you are not planning to extensively integrate R code and data. (As in the present book, although I’m hoping to build this in). Using R-markdown and Knitr (and other tools and add-ins like ‘Bookdown’) content from multiple sources can easily be embedded into these documents allowing users to easily display objects such as plots or regression output. 12.6.2 Some simple markdown rules Text can be made italic using single asterisks *italic or bold by using asterisks **bold**. Hashtags/pound signs (#) specify headers and subheaders, e.g., this third-level subsection header was created with the code: ### Some simple markdown rules {#simple-md-rules} Where the bit in the curly braces allows us to link-back with the code [link back text whatever](#simple-md-rules) … rendering as link back text whatever. Other key features are ordered lists and unordered lists: - unordered first entry - unordered second entry - subelement of second entry While basic markdown has a limited set of rules, there are many more formatting and content options for documents produced in (R)-Markdown, far too many to detail here. These may combine markdown code, html code, latex code, and more. The following cheatsheets are very useful for writing (R)-markdown documents: Markdown documents allow for an easy way to write reports. Content from multiple sources can easily be embedded into these documents allowing users to easily display objects such as plots or tables of data. Text can be made italic using single asterisks *italic* and bold by using double asterisks **bold**. There are various text formatting options in Markdown, far too many to detail here… The following cheatsheets are very useful for writing markdown documents: Markdown cheatsheet R Markdown cheatsheet See also (most useful, but highly detailed): R markdown - the definitive guide Code chunks provide an easy way to embed code into your R Markdown files. The code language is not just limited to R either, as other languages can be used. This means that there is a wide variety of content which can be displayed in a chunk. Such as tables of data: ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa Code chunks are defined by wrapping text inside ``` ```. The above example was coded using: ```{r} head(iris) ``` Options can be specified inside of the curly brackets {} More information is provided here 12.6.3 Inline code Inline code is a quick and easy way to put snippets of R code. As an alternative to using code chunks, R code can simply be placed inside of `r `. For example, this can be used as an easy way to insert the value of a variable into a paragraph without inserting a chunk. 12.6.4 Latex/maths R Markdown also can make use of the LaTeX document preparation system, which is popular for writing technical documents with mathematical content. This allows us to publish documents which include equations such as: \\[y = \\beta_0+\\beta_1x_1 +\\beta_2x_2+...+\\beta_kx_k+u\\] Which is written using $$y = \\beta_0+\\beta_1x_1 +\\beta_2x_2+...+\\beta_kx_k+u.$$. Using $$ means that the equation will be centered on the page. Alternatively $ can be used in the same way, without the centering. A very useful guide to maths in R Markdown provides a detailed outline of the various mathematical symbols which can be used. 12.6.5 Custom styles Bookdown allows for users to build their own custom styles in order to change the appearance of documents. To create styles for HTML projects a custom css file is used. For these projects, styles are contained in support/tufte_plus.css. To use a defined style, the user can specify options at the start of a chunk, or using a HTML wrapper as show below for margin notes. More on creating styles here. Below will outline several key styles used throughout these projects: ‘Notes’ Formatted ‘Notes’ have been defined in this work which allow text to be placed in coloured blocks such as this one. To use this note style, {block2, type ='note'} can be specified at the start of the block, or a HTML wrapper can be used. This assigns the .note formatting from the tufte_plus.css file to the chunk. Margin notes Margin notes are used throughout these projects as a way of displaying information in an organised and aesthetically pleasing way. To add a margin note, text is placed inside the following HTML wrapper: The margin notes used in this project are inspired by the Tufte handout style developed by American statistician Edward Tufte. &lt;div class=&quot;marginnote&quot;&gt; Your margin note goes here. &lt;/div&gt; Or margin notes can be added by using chunk options. Folding boxes Folding boxes also provide a useful way to incorporate content without cluttering the page. Similarly to the ‘notes’ the folding boxes are defined in tufte_plus.css and called by specifying {block2, type='fold'} at the start of a chunk, or using a HTML wrapper. 12.6.6 Adding references/citations As with any academic work, it is always important to reference sourced material. Across these projects the following software is used: Setup Pandoc provides a way to generate formatted references as well as a bibliography in R-Markdown. The bibliography file to be sourced is specified within ‘YAML’ content, which guides the processing of these documents. (YAML content is generally enclosed with a three-dash --- break at top and bottom.) I generally specify the bibliography source in the YAML at the top of the .Rmd file, or for Bookdown projects in the the YAML content in index.Rmd. (???) – we should try to explain this yaml stuff a bit better. BibTeX The BibTeX format refers to a stylized file format which is used predomoninantly for lists of references, mainly and originally for working with latex.. BibTeX bibliographies use the .bib extension. For example the bibliography for this project is giving_keywords.bib. For more information on BibTeX see here Zotero Zotero is a free open source reference manager, which enables users to sync their library of references across multiple devices. Similarly to other reference managers, Zotero offers plugins for popular browsers such as Chrome and Safari. This project makes use of a shared reference library in Zotero, contact daaronr AT gmail.com to be added. Download Zotero Better BibTeX for Zotero Better BibTeX for Zotero is a add-on for Zotero. Among other things it allows the Zotero library to be exported from Zotero for use in Markdown. Installation instructions are provided here. Citr package (addin) for RStudio The Citr package provides functions to search Zotero and BibTeX libraries in order to insert references into Markdown files. Citr also features a plugin for RStudio which makes the referencing process even easier. Instructions for download, as well as a demonstration of the Rstudio plugin are provided here. When using the Citr package to add citations to projects such as this one, make sure to have Citr update the correct Bibtex file. The Bibtex file to “Add references to” is the bibliography file specified in the YAML header of index.Rmd. 12.7 How to ‘build’ and view the book One way is within RStudio Be sure Github repo is synced so all files are present Packages need to be installed, but this should (?) be done automatically when you build via the source(here(\"code\", \"baseoptions.R\")) line in index.Rmd knitr is a key package Click ‘Build’, ‘Build all’, or the shortcut key shift-cmd-b … this seems to run the command rmarkdown::render_site(encoding = 'UTF-8') Building may take some time, depending on how much code is present in the Rmd files and what that code does It puts all the Rmd files specified in the _bookdown.yml into a single file, here labeled barriers-to-effective-giving.knit.md (I think), and then turns that into html, also invoking bibtex along the way Depending on your RStudio settings (-Tools, -Project Options, -Build tools, -Preview book after building), it may put up a ‘preview version’ of the site. Sometimes an error will appear such as “some/file not found”, this can typically be bypassed by clicking open in browser. All the ‘new’ output is directed to be put in the ‘docs’ folder, a bunch of html files. You can view those ‘local’ files in any web browser Once you commit and push, the ‘new’ bookdown website should be up on the WWW 12.8 Joining this project Get a Github account, contact daaronr AT gmail.com and tell him your github account ID (or the email you used to join should probably work as well) Remember to ‘accept’ the invitation to the repos (here, the EA_giving_barriers repo; and possibly some other supporting repos as well). You should receive this invitations via email and it should also be in your “notifications” on Github. 12.8.1 Creating a Branch and a ‘pull request’ 12.8.2 GitHub web page content {#} As noted, GitHub is a web page and interface that acts as an external server and storage space for git projects/repos. It works well with this and also incorporate several additional features. You can see it and even interact with much of a repo simply via the GitHub webpage without even installing Git (but I strongly recommend that you do install Git as well as a tool like GitHub Desktop, unless you want to solely rely on command line Git). Web page for a repo In your account when you click on the repo you’ll see something like the screen above. There are many tabs, starting with the code tab. At the top of this, you will see the list of folders and files, with messages describing the latest comments. Once you’ve installed Git you will want to ‘clone this repo’ to have it on your machine and to be able to easily work with it and commit and push and pull changes. You will do this clone either via the web site, GitHub Desktop or another application, or using the command line Note here we also see: 48 ‘commits’ 2 ‘branches’ 2 contributors Below this, some options allowing you to switch branch, manually upload files, clone or download etc. Readme for a repo Below the list of files you should see the “readme” for this repository. This is a file ‘README.md’ stored in the root directory of this repository. If you click on it or look at the file you’ll see it is written in markdown syntax but the GitHub website renders it into a nice format. I typically use this readme to explain what the project is about and describe (and link) the folder structure. Comments/notifications In a variety of places within a repo when you are adding comments or content you can refer to a collaborator who will then receive a “notification” linking this content. (These are also called “callouts” in some systems.) These may come as as emails to that collaborator if they set a setting to get email notifications, but they will definitely appear as a notification, again that bell thing in the upper right hand corner. Seeing recent commits, history and ‘blame’ Showing the most recent commits Above, this shows the most recent commits. Clicking on one of these commits will show you ‘what changed’ and old versus new versions. Showing the most recent commits For example, above we see something like a “split diff” view, with the ‘old version’ (before this commit) on the left and the ‘new version’ on the right. What is new is in green (with a ‘+’), and what is removed is in red highlight (with a “-”). Here we see that … in the file ‘sections/inertia.rmd’ a space has been added after ‘crowding out?’ This is but one way to view and consider changes. Various text editors such as Atom and ViM also offer great tools, as does the Git program itself and the GitHub desktop application. in ‘present_puzzle.Rmd’ an (obsolete) ‘underline’ notation has been replaced with a third level markdown header (three # marks) Commenting within commits, etc., tagging collaborators in this One way to ask questions, comment on changes and let people know about changes you made, is via adding a comment within a commit itself. (Check: can this be tied to an ‘issue’?) Commenting on a part of a commit, notifying a collaborator Above, we see that by clicking on a plus sign that appears just to the right of the the line number when viewing a commit, we can add a comment on that particular part of the commit. We can then flag another collaborator (see ‘(???)’ above … when you type the ‘@’ you get a dropdown of collaborators) who will be notified of this. This mode of commenting and conversation has the advantage of avoiding cluttering up the actual code and text with excess comments. You can also link each comment to an ‘issue’ (issues are discussed below) by adding a hash to the comment and citing the issue number. This comment and link to the place in the code or text for that commit will then show up when you look at that issue. This makes the discussion more organized, at least we hope. Link an issue in a comment The ‘Project’ board and ‘Issues’ the Project is a ‘Kanban board’ for managing tasks, responsibilities and progress these should be entered as ‘issues’, enabling assignments and further discussion within the ‘issues’ pages a github ‘Project’ Kanban for the github ‘Project’ One task/issue in the Kanban Viewing this issue and its discussion 12.9 Airtable and innovationsinfundraising.org This project is closely connected to innovationsinfundraising.org. Much of these projects overlap, and there is a shared ‘database’ stored as an airtable Giving researchers shared We had an earlier … tutorial on using the Airtable and Innovationsinfundraising.org here I add a few more points below, more relevant to the current project: Airtable Airtable is a collaborative web-based software with a variety of displays and organizational structures; it has many features of a relational database, and even more features if one engages their API. It is user-friendly, with a gui resembling a spreadsheet, and easy tutorials, instructions and examples. You can operate it from a browser or a web-driven app. Key features of tables in Airtables (quick views) Each Airtable user can have any number of Bases, and bases can be shared in work groups. Command-K to jump to any other Base “key_papers”; the papers providing the most relevant and strongest evidence for the tool, and “secondary papers”. Key content The “Categories” table provides and explains a number of “schema” we use to characterize both the tools and the “Barriers to effective giving” (discussed later). categories table Key papers are stored and organised in the ‘papers_mass’ table. This is crosslinked in several other tables. Within each paper ‘row’ there is a variety of relevant information and discussion on each paper. key papers The fundingwiki app automatically populates and updates information on the number of times each paper has been cited, using the Crossref database. Tool such as these will enable this to be a perrennial resource, rather than a frozen-in-time evaluation. citations auto update Note: Some but not all of the Airtable content discussed in the rest of this subsection has already been incorporated into the present bookdown. The table “EAlit_sections” outlines the (earlier?) structure of the EA barriers paper, already providing links to information that will be integrated. organizing ealitpaper This table also links directly to the papers_mass table, organizing the papers we are referencing and reviewing in each section. organizing EAlit papers The separate “Barriers to EAG” table is below. This organizes and assembles the discussion and evidence on potential factors and categories of factors that may explain the limited amount of “effective giving”. This represents the largest part of our review paper; we focus on clear definitions of the most relevant psychological (and “behavioral economic”) biases, and carefully asses the available evidence. We focus specifically on evidence in the charitable domain, but we also consider the broader evidence for these biases in other contexts. barriers to EAG Again, this is older work, maybe already incorporated into the Bookdown? For each barrier or bias, we consider why it is may be particularly relevant to effective giving. barriers to EAG, why relevant We further propose and discuss tools addressing these barriers and promoting effective charitable giving. tools remedies 12.10 Useful resources Like most things, when working with code the internet is your best friend. Listed below are several useful resources for learning about the material mentioned above: 12.10.0.1 R Markdown: The definitive guide 12.10.0.2 R for Data Science Authoring Books with R Markdown 12.10.0.3 YaRrr! The Pirate’s Guide to R "],
["references.html", "13 List of references", " 13 List of references "]
]
