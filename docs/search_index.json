[
["index.html", "Increasing effective charitable giving: The puzzle, what we know, what we need to know next Abstract Non-technical abstract", " Increasing effective charitable giving: The puzzle, what we know, what we need to know next Dr. David Reinstein, Nick Fitz, Ari Kagan, Janek Kretschmer, Luke Arundel and more 2020-08-12 Abstract Present or link an extended abstract here. Non-technical abstract Hunger, homelessness, mental and physical illness, environmental degradation: the needs are boundless, but the resources to solve these problems are limited. Even with the best of intentions and impressive generosity (Americans give roughly 2% of their income to charity), donors often contribute to inefficient charities – ones that spend more but accomplish less than others that may be competing for the same funds. Each dollar given to the most effective charities (like those rated by Givewell.org) benefits greater numbers of people in more significant ways than the least effective ones. However, donors do not always consider “Effective Altruism” (EA) when deciding how much to give and to which organizations. Academics (in Economics, Psychology, Biology, and Philosophy) have applied a range of theories to explain what drives “inefficient altruism.” Evidence comes from a variety of studies, involving surveys, observational work, laboratory experiments, and, where feasible, natural field experiments. These have not been run as part of a systematic project addressing this issue; goals, contexts, and approaches have varied as opportunities presented. Given the disparate findings, we do not have a definitive picture of which factors impact effective giving. "],
["outline.html", "1 Introduction and outline 1.1 Overview 1.2 Structure of each ‘barriers’ section 1.3 Airtable organisation; contributing content 1.4 Other practical considerations", " 1 Introduction and outline This outline links, and gives a brief description of each section 1.1 Overview Presenting the puzzle and challenge: Our ineffective giving Why should you care about this? Descriptives of giving (US, international) and how ‘ineffective’ it is. Potential global welfare gains to changing ‘where we give’. Lack of previous evidence/synthesis Motivation and descriptives Definitions - “Efficiency” versus impact Relevant to charity ‘quality ratings’, overhead aversion Why (under what models) is this a puzzle? Economics and psych models \\(\\rightarrow\\) puzzle? Models where people care about the impact of their gift or just ‘amount sacrificed’ (naive warm glow). Does impact map into the ‘good feeling’ from giving, can it do so? Conceptual breakdown of ‘barriers’ (first presentation) Do people actually care about impact? Does moral utilitarianism matter? Are charities in competition? Is the ineffective giving reducing effective giving? Ask people to give to EA charity ‘instead’? Are charitable gifts complements or substitutes; are charities are rivals? Does one donation request ask (or donation itself) crowd out another, and if so when and how much? This is critical to understanding the extent to which gains can be achieved by getting people to ‘switch’ from less to more effective charities. To the extent this crowding-out is the case, factors driving giving to the non-EA charities, especially local obligations (e.g., neighbors’ pressuring you to give to local organisations) themselves represent barriers to EA giving. Explaining the puzzle: Barriers to EA giving and potential responses, evidence Here we also give a general ‘conceptual’ overview of these barriers. We dig into each barrier more carefully in subsequent chapters. Barriers: Awareness, consideration, and distance Whether a cause/charity is something people are aware of, feel is important/salient, and feel close to. Responses?: (Info enhancing) social closeness of recipient Barriers: Identity and cognitive dissonance Barriers: Signaling and social pressures/social identity Barriers: Aversion/obstacles to doing (using) evaluations; effect of analytical information on generosity Barriers: Quantitative biases Barriers: Inertia and systemic/institutional Tools for motivating EA giving Conclusion; a research agenda 1.2 Structure of each ‘barriers’ section In each section we consider: A category of barriers; this is a first-level heading, e.g. ‘Quantitative biases’ is section 8. Here we discuss this category in general, explaining its meaning and plausibility in terms of the underlying theories, models, and generalized observations. Each specific barrier in this category gets a second-level heading, e.g., “Proportional dominance effect” is section 8.3. For each specific barrier we first present (third-level headings) Definition of the barrier Conceptual explanation of the barrier, relating this to theory and generalized observation Relevance to the effective giving (sometimes recapping what was stated above) Next we consider the Evidence, with a third-level header preamble discussing the nature of the evidence Within this, we consider the evidence for each specific empirical claim supporting the case for this barrier’s existence and importance. In considering the evidence for these claims, we generally consider one paper or project at a time (or a specific piece of independent evidence from this paper). However, we are still thinking about the best narrative approach to presenting evidence from multiple papers/projects/analyses. 1.2.1 Consideration of each paper For each paper we focus on key elements, including: Method (lab experiment involving real charitable asks, natural field experiment with charity partner, observational analysis asserting causality via a regression discontinuity approach, etc.) The context and data (the population of donors or lab participants, the charity(s) involved, etc.) The nature of the ‘treatment’ or independent variable (e.g., realistic information presented about impact per dollar) The strength and credibility of the empirical results (considering, e.g., limitations and confounds in the design, experimenter-demand effects, estimates’ statistical strength and power, appropriateness of the statistical analysis, preregistration, signs of specification-fishing and multiple-testing without corrections, replications and citations, etc.) We (should) also link where to find the paper itself as well as the materials and the data collected. For example, within the category Barriers: Aversion/obstacles to doing (using) evaluations; effect of analytical information on generosity … we consider the barrier “General cost-benefit analysis (CBA)-aversion or reluctance”… weighing evidence specific claims such as “People sometimes actively avoid information about charity effectiveness that would motivate doing a CBA…”… coming from research papers/studies such as (Fong and Oberholzer-Gee 2010a). 1.3 Airtable organisation; contributing content These classifications of barriers are organised, outlined, and defined in our Airtable; see the view below. The barriers themselves are organised as well, see the view below: To suggest a new barrier, or a modification of an existing proposed barrier, please fill out the form below and linked here (or contact us otherwise, including via a hypothes.is comment): Did we leave out a paper or a source of evidence? Please fill out the form below or click the link HERE (or contact us otherwise, including via a hypothes.is comment): All contributions will be credited and engaged with. 1.4 Other practical considerations Notes on potential integration with PriorityWiki/Rethink Charity How have EA orgs been brought together …especially at universities? Effective thesis project EA hub Facebook group "],
["present-puzzle.html", "2 Presenting the puzzle and challenge: Our ineffective giving 2.1 Motivation and descriptives 2.2 (Lack of) previous synthesis on this 2.3 Definitions - “Efficiency” versus impact 2.4 Why (under which models) is this a puzzle? 2.5 Conceptual breakdown of ‘barriers’ (first presentation)", " 2 Presenting the puzzle and challenge: Our ineffective giving Overview of research Question/Problem: Why don’t people give in an evidence-based way? When faced with the “girl drowning in the pond” we are willing to sacrifice substantial wealth to save a life. However, most people don’t make large donations to the very poor, in spite of evidence suggesting that lives can be saved for less than 10,000 USD. This is not for lack of generosity. There is a strong case that most donations go to charities that improve well-being far less per-dollar than others. As Hoffman et al (2018) state:1 “We donate billions of dollars to charities each year, yet much of our giving is ineffective. Why are we motivated to give, but not motivated to give effectively?” References supporting this claim are given below. This raises two related questions: 1. “Why don’t we give more to the most effective charities and to those most in need?”, and 2. “Why are we not more efficient with our giving choices?” To address this, we must understand what drives giving choices, and how people react to the presentation of charity-effectiveness information. Note that these two questions are not identical: the first asks about the amounts given to the most needy charities, and the second about the choice of charities conditional on giving. 2.1 Motivation and descriptives Individual donors, governments and firms demonstrate substantial generosity (e.g., UK charity represents 0.5-1% of GDP, US charity around 2% of GDP). (“CAF World Giving Index 2018 | Research into Global Giving Behaviour,” n.d.; “U.S. Charitable Giving Tops $400 Billion for First Time,” n.d.) However, most donations go towards charities that are worthwhile but improve human well-being far less per dollar than basic medical interventions in poor countries, such as antimalarial bednets (see Givewell.org). Even within the same category, more can be achieved for less: e.g. while it costs around USD 50,000 to provide a blind person a guide dog, the equivalent amount could cure 500 people of blindness if it was spent on surgery to prevent blindness from trachoma (Burton and Mabey 2009; Macaskill 2015). Social science, biology and philosophy present a range of potential theoretical explanations of how values, preferences, and biases drive this ‘inefficient altruism’. However, evidence (e.g., for ‘availability bias’, or for ‘scope insensitivity’) comes largely from small-scale experiments in domains outside of charitable-giving. It is difficult to distinguish robust, credible findings from one-off results that are vulnerable to hype, p-hacking and publication bias (echoing the ‘replication crisis’ in experimental social science (Shrout and Rodgers 2018)). Given the limited, scattered findings, we do not have a definitive picture of which factors substantially impact ‘effective giving and support for policies that reduce extreme poverty’. (We give a review of papers surveying this evidence below) A plain-language summary of key points, without references (unfold): Charities’ impact differs by an order of magnitude: Some charities are much more effective at saving/improving lives (and achieving other goals such as those involving animals and the environment) than others are. While it is difficult to gain precise estimate on the measures such as “cost of a life saved” there is strong evidence that there are orders of magnitude difference between different categories of charities and different interventions within these categories. There are some very effective lifesaving charities: Some interventions seem likely to save or vastly improve individual lives at a cost in the range of USD 2000 - USD 10,000. When people are asked whether they would be willing to spend this amount or even a vastly larger amount to save a life in other contexts they typically will agree to do so. There are two related and largely unresolved puzzles: Why are people not more generous with the most highly effective causes? and When they give to charity why do they not choose more effective charities? There is some evidence on this but it is far from definitive. We do not expect there to be only a single answer to these questions; there may be a set of beliefs, biases, preferences, and underlying circumstances driving this. We would like to understand which of these are robustly supported by the evidence, and will have a sense of how important each of these are in terms of the magnitude of driving and absence of effective giving. There has been only a limited amount of research into this and it has not been systematic, coordinated, nor heavily funded. We seek to understand because we believe that there is potential to change attitudes, beliefs, and actions (primarily charitable giving, but also political and voting behaviour and workplace/career choices). Different charitable appeals, information interventions and approaches may substantially change peoples charity choices. We see potential for changing the “domain” of causes chosen (e.g., international versus US domestic) as well as the effectiveness of the charities chosen within these categories. (However, we have some disagreement over the relative potential for either of these.) Our main ‘policy’ audience includes both effective nonprofit organisations and ‘effective altruists’. The EA movement is highly-motivated, growing, and gaining funding. However, it represents a niche audience: the ‘hyper-analytic but morally-scrupulous’. EA organisations have focused on identifying effective causes and career paths, but have pursued neither extensive outreach nor ‘market research’ on a larger audience (see Charity Science, Gates Foundation/Ideas42). 2.1.1 Descriptives of giving (US, international) and how 'ineffective' it is. Who does give effectively? Potential global welfare gains to changing ‘where we give’. Who does give effectively? Fitz/Kagan: Understanding Effective Givers: In this study we attempt to understand who is predisposed towards effective giving. After providing a description of the effective giving movement, we measure support for effective giving and measure a wide range of personality traits and demographics that may predict support for effective giving. We briefly define the EA movement as an important force “we” (economists, psychologists) need to discuss. 2.2 (Lack of) previous synthesis on this While there have been some relevant prior reviews (Loewenstein and Small (2007a), introduction to Berman et al. (2018), Baron and Szymanska (2011)) There has also been some unpublished or non-academic work: ‘Behavior and Charitable Giving’ (Ideas42, 2016), ‘Charitable Fundraising And Smart Giving’ (Gertler, 2015), and ‘The Psychology of Effective Altruism’ (Miller, 2016, slides only). The current project uniquely combines A focus on effectiveness, considering ‘choices among charities’ as well as in isolation, incorporating recent work and developments from the ‘EA movement’, a rigorous, sceptical approach to evidence, and advancing a research agenda while building tools that promote robust evidence. Ideas42: “We did not find many field-based, experimental studies on the factors that encourage people to choose thoughtfully among charities or to plan ahead to give.” 2.2.1 Effectiveness-specific work Baron and Szymanska (2011) - Heuristics and Biases in Charity: Largely conceptual, minimal survey of specific empirical/experimental papers Gertler, Charitable Fundraising and Smart Giving (not peer-reviewed but very useful) Comparison of outlines: unfold Gertler, \"Charitable Fundraising and Smart Giving\" Substantial motivation A broad picture of the evidence on what motivates and can be used to giving in general “Strategies for Effective Charities” (pp 48-59) is most relevant to the current project (Baron and Szymanska 2011) (chapter) Introduction (with problem/puzzle) Possible Nonutilitarian Heuristics Evaluability (focus on attributes easy to evaluate e.g., &gt; efficiency/overhead) “instead, what is more evaluable than the lives saved per dollar of contribution is the operating cost per dollar” Average vs. Marginal Benefit, Diversification, Prominence, Parochialism Identifiability, Voluntary Versus Tax Experiments Waste, Average Cost Diversification, Unequal Efficiency; Unequal Efficiency, Several Projects Versus One Nationalism Forced Charity Discussion: Utilitarian Models of Altruism, Maximize Total Utility, Limited Self-Sacrifice, Limited Altruism, Moral Education, Implications 2.3 Definitions - “Efficiency” versus impact Consider: The measures used are relevant to how we consider issues such as charity ‘quality ratings’ and ‘overhead aversion.’ Reference: Steinberg &amp; Morris, 2010 wrote about marginal vs average effectiveness. It is important to define the concept of talking about. What, precisely, is this ‘effectiveness’ or ‘impact’ of a charity we are focusing on? It is not trivial to get this right and there are some delicate and hotly debated questions even within the EA movement. Nonetheless, I sketch the basic idea in the math below. \\(G_j\\): The total donations given to charity \\(j\\) during some interval; i.e., the charity’s income. \\(B_j(G_j)\\): A function defining the beneficial outcome achieved by charity \\(j\\) with the total donations \\(G_j\\). Here, we are referring to \\(B_j(G_j)\\) as (the improvement to) some ultimate outcome: Lives saved (i.e., deaths averted), quality adjusted life years (QALY) added, QALY weighted by age, Disease-adjusted (DALY), future happy lives generated, sentient suffering averted, etc. As noted, there are disagreements over how and whether we should trade off among these outcomes. Issues such as population ethics, andthe importance of sentience and experience — come to the fore. We will ignore these for now. The important distinction here: \\(B(G_j)\\) does not refer to a simple intermediate ‘output’ such as ‘antimalarial nets provided’ nor ‘textbooks purchased’. We are referring to the social outcome of ultimate value; an outcome that could be valued in and of itself. This naturally takes into account both the ‘technical efficiency’ in terms of how many units of output can be produced per dollar, and the rate at which each unit of this output boosts the ultimate outcomes of interest. The ‘production function’ is (perhaps tautologically) the product of two terms: (Total or marginal) impact per dollar = output per dollar \\(\\times\\) impact per output This is obviously an oversimplification. To achieve the beneficial outcome the charity will require many intermediate inputs (or “outputs” as noted above), including ‘management’ and ‘careful targetting of programs’. Some charities may be able to acquire these inputs at better prices than others, and some may also use a more efficient mix of inputs. A donor may care about the ‘impact’ of her own donation; i.e., she may want to know the difference in outcomes that her donation achieves everything else equal. In other words, the difference in the ultimate outcome in a world with versus without her donation. Small donor assumption: For a small donor (perhaps someone who donates less than USD 100,000), we may assume that this “rate of benefit” will be the same for both the first and the last dollar she donates. Thus we consider the marginal impact, as a simplification: \\(B_j^\\prime (G_j)\\) for the marginal donor. I assert that \\(B_j^\\prime(G_j)\\) is the quantity that GiveWell (and perhaps other EA charity raters) are attempting to measure. We know (evidence cited in fold): There is abundant evidence for this. Some links and references: Ord, T. (2013, March 12). “The moral imperative toward cost-effectiveness in global health. Center for Global Development.” Retrieved from www.cgdev.org/content/publications/detail/142701. Also “Your dollar goes farther overseas”. (2016). Retrieved from http://www.givewell.org/giving101/Your-dollar-goes-further-overseas \\(B_j^\\prime(G_j)\\) is much larger for the most impactful relative to the most popular charities. Increased benefits could be achieved if donations were ‘’reallocated’’ towards more impactful charities. An individual who gains value from her giving through it’s impact alone would naturally donate to only the one charity that has the greatest marginal impact, the charity \\(j\\) with the greatest \\(B_j&#39;(G_j)\\) term. If every donor is doing this, then as an ‘equilibrium’ result, every charity receiving positive donations should have the same last-dollar marginal impact. In maths: \\[\\begin{equation} B_k^\\prime(G_k) = B_j^\\prime(G_j)\\forall j,k s.t. G_j&gt;0, G_k&gt;0 \\end{equation}\\] Caveats: This assumes a single impact goal, essentially ‘cause neutrality’. The idea that each donor gives only to a single charity essentially depends on the above ‘Small donor assumption’. Still, allowing that the marginal-benefit-leading-charity may vary within the range of an individuals’ donation simply implies that they should allocate among multiple charities each up to the point that the last dollar given yields the same marginal benefit as the other charities, yielding the above result. We can imagine an equilibrium in which all donors give to multiple charities, with each of these charities being virtually “tied” in their marginal effectiveness. But we do not seem to be doing this. Again: billions are given to charity, and these charities clearly have vastly different marginal impacts, even among those that seem to target very similar outcomes. 2.4 Why (under which models) is this a puzzle? Does the set of facts mentioned above constitute a “puzzle” for our Economics and Psychology models… or are there obvious existing explanations? In Economic terms, are donors mysteriously ‘’leaving money on the table’’ or are they simply optimizing given their their preferences and constraints? What could explain this? Economists love when we can say that something is officially a Puzzle. It is an achievement in itself to be the researcher who first discovered a Puzzle, even if we have no clue how to resolve it. Aside on ‘Warm glow’… consider the contrast between models where people care about the impact of their gift versus models in which they care only about the ‘amount sacrificed’ (naive warm glow). Does impact map into the ‘good feeling’ from giving? Can it do so? 2.5 Conceptual breakdown of ‘barriers’ (first presentation) We focus on the ‘barriers’ or ‘hurdles’ to giving effectively among individuals who already engage in some charitable giving and other-regarding acts. Loosely, a donor would need to jump over all of these hurdles and cross each of these barriers in order to be giving effectively. Recall: is there a well-known psychological framework for these sorts of multiple-hurdle choices? We first consider a fairly conceptual breakdown. (In later sections, we will use a less theoretically precise categorization that proved more practically usable.) Later chapters presents the direct and indirect evidence for very specific barriers, with real-world examples, and proposed ‘tools’ for surmounting these. Here the conceptual breakdown proved difficult, as most of the real world cases fell into multiple theoretical categories. A conceptual breakdown of barriers: Base values: (non) utilitarian: people are optimising their own ‘X’, which does not coincide with impact \\(\\rightarrow\\) no puzzle? Judgement/cognition failures: People try but fail to optimize Emotion overrides cognition: Our brain serves two masters, those decisions are not consistent Identity and signalling: Effectiveness in giving clashes with our self-image/self-beliefs, or with how we want to appear to others Systemic factors (and inertia): “It’s society’s fault, man” … social systems leading to pressure and incentives from others to give to local or less-effective causes. Even if impact is a goal these systems take a long time to adjust. Are people utilitarian? The discussion above largely assumes that people are, at least to some extent: Other-regarding/pro-social: her preferences or the “utility function she is maximizing” incorporates the well-being of others, at least to some extent Moral utilitarians: The value she places on helping others (or on others’ outcomes) is principally increasing in some measure of the amount of good they have done for others, or in others’ welfare. For a given personal sacrifice, she will always prefer to have made more people more well-off than to have made fewer people less well-off. In Economics terms, she strictly prefers and values Pareto-improvements. A mathematical statement of this may be helpful here. Universalist: In considering others’ welfare, she values all others equally regardless of their identity. Universalism: a more precise example: Consider a world with three other people (B,C,D). Suppose each begin in a poor state. Consider outcomes such as: B and C are well off and D is poor D is well-off and B and C are poor A universalist, as I define it, would always prefer outcome 1 over outcome 2. She would also rather achieve outcome 1 over outcome 2 with her charity, no matter the identity of persons B, C, and D. Not ‘deontological’: there are no other relevant absolute moral constraints (constraints such as ‘do no harm in your actions, even if others are helped’) To what extent does a ‘moral utilitarian’ (MU) consequentialist ethic govern beliefs and behaviour? To the extent it does, limited effective giving represents a puzzling intention/action gap. However, for non-utilitarians this is no puzzle. If other forces and motivations drive our giving choices, we might not expect these to be aligned with effectiveness. It could be argued that the above is posed too starkly. People may embrace concepts such as utilitarianism, universalism, and cause neutrality, and at the same time be largely driven by other concerns and sympathetic to other moral frameworks. We may agree with statements that “all lives are equal” and “we should strive to do the most good for the largest number” but also support maxims such as “charity begins at home” and “giving is about supporting something you have a personal connection to.” While these statements may, strictly speaking, be contradictory, we shouldn’t expect perfect consistency or constancy. Most people are not asked to rigidly join the deontological or utilitarian camp, and those who have not studied philosophy or social science may never have contemplated these issues directly. Perhaps moral utilitarianism (MU) is relatively unimportant in most people’s charitable choices. Even if this is the case, understanding the ways in which people do pursue their giving goals, and their obstacles and “biases” in doing so may suggest ways of making giving more impactful. For example, many donors may prioritize their local community, leading to their less-effective giving (from a universalist point of view). However, they might be persuaded to expand their definition of their own ‘community’. Some examples of concerns other than Moral Utilitarianism that might drive giving and charity-choices: Perfectionism/deontological aversion to ‘waste’ Social pressure Signaling virtue to others Emotional empathic reactions to particular images and situations A desire to identify with particular causes or particular groups of individuals, perhaps in opposition to other groups Religious motivations Fairness concerns Judgement/cognition failures; Biases in perceiving impact and in making choices People may (at least to some extent) want to be effective in their donation. However, they may simply not be good at doing this. Quantitative biases may drive departures from effectiveness in general. Anything that causes me to misunderstand effectiveness, to misapprehend the nature of the “production function for good outcomes”, or to misjudge charities will lead me astray from effective giving. If I am making any mistake, I am failing to optimize. Furthermore, some biases may happen to be particularly harmful to those charities and causes that are most effective. We consider these extensively in the section “Barriers: Quantitative biases”. Cognitive biases include: - Overweighting and underweighting probabilities - Misunderstanding marginality - Scope-insensitivity - Opportunity-cost Neglect - Identifiable victims effect - Overhead aversion Emotion overrides cognition Presenting analytical/impact information switches off system 1 Charity effectiveness (info/deliberation) Donor’s mood (Impacting) Affect prime Evaluation mode See: (Karlan &amp; W, ’07),(Kogut and Ritov 2005b, 2005a), (Small, Loewenstein, and Slovic 2007), (Drouvelis and Grosskopf 2016), (Caviola et al. 2014) Avoiding information, motivated reasoning in processing it See: Andreoni, Rao, and Trachtman (2017), Exley (2016), Exley and Petrie (2018), DellaVigna, List, and Malmendier (2012), Reinstein, Riener, and Kellner (2018) Identity and signaling Considering effectiveness in giving (and publicizing this concern) may conflict with an individual’s self-perception. It may also harm her reputation, at least relative to emotional or ‘deontological’ helping responses. Barriers: Distance (Physical, Psychological/Emotional, Social) Less proximate needs are less salient, thus under-funded. (Info enhancing) social closeness of recipient - Cuddy, Fiske, and Glick (2007), (Sudhir, Roy, and Cherian 2016) Barriers: Strong local appeals (‘the ask’), social obligations to give locally (and ‘crowding out’/moral licencing) (Meer 2011) Does one contribution crowd out another? If so, social pressure, systems enforcing ‘local public goods’ and inertial factors may limit effective (non-local) giving. List of references "],
["substitution.html", "3 Are charities in competition? Is the ineffective giving reducing effective giving? 3.1 Theoretical framework and concerns 3.2 Previous approaches and evidence 3.3 Synthesis (emerging)", " 3 Are charities in competition? Is the ineffective giving reducing effective giving? Are charitable gifts complements or substitutes; are charities rivals? Does one donation request (or donation itself) crowd out another, and if so when and by how much? This is critical to understanding the extent to which gains can be achieved by getting people to ‘switch’ from less to more effective charities. To the extent this crowding-out occurs, factors driving giving to the non-EA charities, especially local obligations (e.g., neighbors pressuring you to give to local organisations) themselves represent barriers to EA giving. 3.1 Theoretical framework and concerns What does this question even mean? In a standard Economics framework we would consider joint optimization over “gifts to an ineffective charity” and “gifts to an effective charity”; one doesn’t “respond” to the other. (or an optimization over ’gifts to the causes these represent’) Prices/ external changes shift each, but we can’t “force you to voluntarily give.” Furthermore, “prices” are unclear in this context (see Economics models of giving) and prices for one cause or charity rarely vary exogenously. If we could shift the ‘meaningful giving’ \\(\\rightarrow\\) we could use theory of Conditional Demand (Pollak 1969) \\(\\rightarrow\\) “expenditure substitution” (Reinstein, n.d.). Still, the sign of the conditional demand effects are straightforward only under very restrictive conditions. What we can measure in a straightforward way (in principle): Does a promotion for a less-effective charity (such as CRUK) cause more or less giving to a more-effective charity (such as Oxfam)? Most of the work discussed below focuses on this sort of estimate. A more difficult question: Is the causality: CRUK promo \\(\\rightarrow\\) give more to CRUK \\(\\rightarrow\\) give less (more) to Oxfam? But can we rule out direct effects of the first promotion? (see (Heckman and Pinto 2015) on “mediators”) This is in fact relevant for a policymaker. She might face a ’shock’ that she knows or expects will lead to donations to charity A to rise by EUR 1,000,000 EUR. She will want to know ‘how much can we expect donations to charity B to fall?’ What underlying causes might lead the effect to go in one direction or the other? The psychological ideas of “self-image management” and “moral-licensing” could also be expressed in terms of a utility function with particularly diminishing returns to total charitable giving; there may be a discount rate on the recency of the donation, as in a perishable good. Expenditure substitution maths This is largely drawn from the appendix of (Reinstein 2011) Assuming that utility is separable in own consumption and charitable gifts, and assuming an additive specific shock (\\(\\alpha\\)), we can express utility as: \\[U=f(x)+V(g_{1},g_{2}-\\alpha )\\] where the functions \\(V\\) and \\(f\\) are functions that represent utility from own-consumption and from charitable giving, repectively. The budget constraint can be written as: \\[x+p_{1}g_{1}+p_{2}g_{2}\\leq Y\\] where \\(Y\\) represents total wealth, \\(p_{1}\\) and \\(p_{2}\\) are the prices of giving to charities one and two (per dollar the charity receives), and I normalize the price of own consumption to one. Under this model, the marginal “indirect effect” of a shock (\\(\\frac{\\partial g_{1}}{\\partial \\alpha })\\) can be expressed simply as a function of the marginal “direct effect” of the shock (\\(\\frac{\\partial g_{2}}{\\partial \\alpha }\\)). Standard comparative statics of the optimal choices (assuming an interior solution and other standard regularity conditions) yields the total derivatives: \\[\\begin{aligned} \\frac{dx}{d\\alpha } &amp;=&amp;\\frac{\\lambda _{\\alpha }}{U_{xx}} \\\\ \\frac{dg_{1}}{d\\alpha } &amp;=&amp;\\frac{\\lambda _{\\alpha }(p_{2}U_{12}-p_{1}U_{22})% }{U_{12}^{2}-U_{11}U_{22}} \\\\ \\frac{dg_{2}}{d\\alpha } &amp;=&amp;1+\\frac{\\lambda _{\\alpha }(p_{2}U_{11}-p_{1}U_{12})}{-U_{12}^{2}+U_{11}U_{22}}\\end{aligned}\\] where \\(\\lambda (\\alpha ,p_{1},p_{2})\\) is the shadow value of the budget constraint, \\(U_{IJ}\\) \\(\\equiv \\frac{\\partial ^{2}U}{\\partial I\\partial J}\\), \\(\\lambda _{\\alpha }\\equiv \\frac{\\partial \\lambda (\\alpha ,p_{1},p_{2})}{% \\partial \\alpha }\\). Hence \\[\\frac{dg_{1}}{d\\alpha }=(\\frac{dg_{2}}{d\\alpha }-1)\\frac{% p_{2}U_{12}-p_{1}U_{22}}{p_{1}U_{12}-p_{2}U_{11}}\\] The sign of the marginal effect on \\(g_{1}\\) (relative to the marginal effect on \\(g_{1}\\)) can be either positive or negative, and will depend on the partial second derivatives of utility and the relative prices. Looking at the discrete effect: \\[g_{1}(\\alpha _{1})-g_{1}(\\alpha _{0})=\\int_{\\alpha _{0}}^{\\alpha _{1}}[(% \\frac{dg_{2}}{d\\alpha }(g_{1,}g_{2})-1)\\frac{% p_{2}U_{12}(g_{1,}g_{2})-p_{1}U_{22}(g_{1,}g_{2})}{% p_{1}U_{12}(g_{1,}g_{2})-p_{2}U_{11}(g_{1,}g_{2})}]d\\alpha \\label{integralgeneral}\\] With quadratic utility (defined in fold), the partial derivatives will be constants, \\(U(x_{0},x_{1},...,x_{n})=x_{0}+\\Sigma _{i=1}^{n}\\alpha _{i}x_{i}-(\\Sigma _{i=1}^{n}\\beta _{i}x_{i}^{2}+2\\Sigma _{i\\neq j}^{n}\\gamma _{ij}x_{i}x_{j})/2\\) … and the discrete indirect effect, as well as the marginal effect, will be a simple linear function of the direct effect: \\[g_{1}(\\alpha )=A+Bg_{2}(\\alpha )\\] where \\(A\\) and \\(B\\) are constants. Quadratic utility is often justified as a second-order approximation to any other utility function. With other utility functions the partial derivatives may vary at different consumption bundles, so the indirect effect may be a nonlinear function of the direct effect, but these should be solvable for a predictable functional form, which for estimation purposes, can be approximated to any desired accuracy by a polynomial function. 3.2 Previous approaches and evidence The material in this section largely overlaps the literature review in Reinstein, Reiner and Vance-McMullen 202 ongoing, in the repository https://github.com/gerhardriener/CharitySubstitutionExperiment/, in the file lit-synth.Rmd These should be integrated with one another. There is a lack of data on donations at the individual-charity level. For identification: Lack of independent observable variation in price, shocks, or appeals. Intertemporal substitution is an issue, and we typically cannot observe ‘lifetime giving.’ Estimation of ‘Expenditure substitution’ (Reinstein, n.d.) is complicated by issues of extensive vs intensive margins, as well as heterogeneity. 3.2.1 Observational work Observational data typically lacks shocks that are clearly specific to giving to one charity. Observational data on charitable giving (e.g., survey data or tax data) offers few variables that can be used to identify ‘specific’ shocks – shocks that alter giving to one charity but have no independent effect on giving to other charities. Most observable variables that are believed to increase giving to one charity will also increase giving to other charities, masking substitution effects. Signing-the-bias approach However, under reasonable assumptions we can sign this bias, and thus estimate a lower bound on substitution. Reinstein (n.d.) using PSID/COPPS data finds some evidence of expenditure substitution, especially for large givers. He makes a “bounding below” argument Issues: charity categorization/misreporting; bounded result only He finds many negative significant correlations between residuals from fixed-effects regressions on donations to categories of charitable causes This especially holds for larger (prior) donors and for certain paired cause categories Under what he argues to be plausible econometric assumptions (essentially, a net positive correlations between the residuals of ‘propensity to donate to each cause’) \\(\\rightarrow\\) negative correlations are strong evidence of expenditure substitution Interpretation: heterogeneous motivations for giving, small vs large givers Observational data paired with ‘exogenous’ shocks (Deryugina and Marx 2015) Donations in a state affected by tornado increase 1.7-2 percent in that year and 1.9-2 percent in the 2 years after. The authors can only reject ‘full crowding out’. (Scharf, Smith, and Ottoni-Wilhelm 2017) These authors observe “CAF accounts”; for this particular group, they observe all donations over a substantial period. \\(\\rightarrow\\) Reject ‘full crowd-out’, tight zero LR crowdout \\(\\rightarrow\\) non-disaster giving pre-poned (!), esp. for disaster/intl donors; “halo effect?” Estimates: +.537 log donations to DEC-13, se .032; -0.008 log donations to ‘other charities’, se 0.017 \\(\\rightarrow\\) Reject ‘full crowd-out’, tight zero LR crowdout Interpretation… consistent with… for (only) people responding to the DEC appeal … the disaster appeal increased the effectiveness with which donating to all charities, including Other charities, produces warm glow utility—a halo effect They argue that their data allows them to reject the transactions cost explanation because they see i. less bunching than usual, ii. shifts in amounts given and not just at the extensive margin and iii. a particular shift from certain categories. Issues: Specific CAF population; disaster-specific; time-series variation issues (6 disasters=lumpy?) 3.2.2 Simultaneous/proximate ‘lab’ experiments (esp. Reinstein 2006/11; (Filiz-Ozbay and Uler 2019)) Figures: Berkeley design, types Vary choice sets/prices, shocks \\(\\rightarrow\\) crowd-out, esp. similar causes Figures: Berkeley line graphs (Reinstein, 2011) \\(\\rightarrow\\) Strong “expenditure substitution” responses to shocks, esp for similar charities; approx 50% crowd-out; 2.59 cross-price-elast) Heterogeneity; mix of ‘fixed purse’, ‘flexible purse/never substitute’] Filiz-Ozbay and Uler (2019) : Five paired choices, varying ‘rebate rate’ for one only; price-focus - ‘Stealing’ almost always - +0.35 net cross-price elast for ‘substitute’ charities Harwell, Candidate, and Eckel (n.d.); Schmitz (n.d.): somewhat related designs, similar results in favor 3.2.3 Lab/framed experiments with time gaps Schmitz (2019) Vance-Mullen component of Reinstein et al 3.2.4 Field/natural experiments Notes from previous paper (unfold) offer some field experimental evidence on the crowding-out effects of direct mail solicitations. %[RESULTS?] investigated the impact of the German church tax on households’ other charitable giving. used a field experiment to examine how donations to different charities respond to changes in relative match rates – however, as the total donation was decided ex-ante, the substitution among charities was constrained to be complete. Finally, an earlier work () examines substitution between giving and volunteering. However, to the best of my knowledge, no work directly addresses the cross-price elasticity (nor the expenditure substitution) between gifts to charitable causes. Meer (2014), Meer (2017): DonorsChoose.org competition, matching campaigns 2017: Increased funding for project, no significant impact on donations to other projects Meer (2014): “increased competition reduces the likelihood of a project being funded” Donkers, Diepen, and Franses (2017): Extra mailings to existing donors in a week, top-NL charities Extra mailings +1.81 EUR for charity, -0.10 EUR per ‘regular’ mailing for other charity in same week loss of 10% of revenues via competitive effects can’t reject zero-crowding, but wide CI’s Anticipated second asks: (Adena and Huck 2019; Cairns and Slonim 2011) Cairns and Slonim (2011): Anticipated `2nd collection’ at Mass raised 7695 USD , reduced 1st collections by 1708 USD (22% “crowdout”) Adena and Huck (2019): Anticipated repetition \\(\\rightarrow\\) 40% less “this year” (but also a persistent lower don) Reinstein et al, 2020: First field-experiment to ask (or not ask) on multiple separate occasions with a significant delay, vary this delay time; find some crowding out but evidence on interaction with delay time is mixed. Possibly two channels: consistency versus fading of moral license/warm glow. 3.3 Synthesis (emerging) knitr::include_graphics(&#39;picsfigs/subst_meta_cut.png&#39;) Figure 3.1: Papers on substitution; database Proximate asks and clearly presented comparisons \\(\\rightarrow\\) expected crowding-out A particular issue: apparent contrast, Coherent arbitrariness, narrow brackets, framing (how people think they ‘should behave’ or how they behave when they are in a deliberative self-reflecting mode. This may characterize some giving decisions but it is probably not the most common. With naturally-occurring, more time-separated shocks and asks, the results are more mixed, sometimes with much smaller, or no apparent substitution. So how proximate is proximate? Evidence is still mixed (see above discussion on dual channels) In Reinstein et al, we are planning a meta-analysis of the above papers List of references "],
["aware-distance.html", "4 Barriers: Awareness, consideration, and distance 4.1 Description and relevance to Effective Giving 4.2 Theoretical and conceptual underpinning 4.3 Distance - Spatial/Physical, Social/Cultural: parochial altruism/ingroup bias, interpersonal and identity e.g., race, gender, age, etc 4.4 Distance: Experiential, Informational, Emotional/Affective 4.5 Availability heuristic and media (also see ‘biases’) 4.6 Reference dependence 4.7 Distance - Temporal (future problems/individuals) and Hypothetical (probability of occurance)", " 4 Barriers: Awareness, consideration, and distance This section was written by David Reinstein and Luke Arundel. 4.1 Description and relevance to Effective Giving Typically, the most effective charities operate in developing countries, with all but one of Give Well’s top charities supporting people in sub-Saharan Africa (“Top Charities,” n.d.). Moreover, people in wealthy developed countries are more likely to be in a position to give a significant amount (Macaskill 2015). However, The large, social, cultural geographic distance between those in developed countries and those in developing countries may be an important barrier to giving and a reason why people prefer to give locally. Loewenstein and Small (2007a) propose a relationship between sympathy and helping behaviour, drawing on experimental findings from Psychology and Economics. This in turn relates to the dual system model (as discussed by Kahneman (2011)). This model distinguishes between System 1, which makes initial judgements (using ‘affective cognition’); these are monitored by a more ‘deliberative cognition’ System 2 (Morewedge and Kahneman 2010).(This model has been subjected to some criticism, Evans and Stanovich (2013) discuss the debate around dual system theories) 4.2 Theoretical and conceptual underpinning Construal theory, psychological distance, moral distance/moral circles Ref: Trope, Yaacov; Liberman, Nira (2010). “Construal-level theory of psychological distance” (PDF). Psychological Review. 117 (2): 440–463. doi:10.1037/a0018963 4.3 Distance - Spatial/Physical, Social/Cultural: parochial altruism/ingroup bias, interpersonal and identity e.g., race, gender, age, etc Consider: What is the evidence that we are less empathetic or less generous to those far from us along these margins? What is the evidence that this is manifested in our actions and choices (political, professional, etc)? What is the evidence that this is manifested in our charitable giving? Parochialism may pose a significant barrier to effective giving. Parochialism, as defined by Baron and Szymanska (2011) is the mental process of making a distinction between in-groups and out-groups, where people feel a greater connection with their own groups and weigh their welfare more heavily. There is some evidence for this in charitable contexts. In a laboratory experiment, Chen and Li (2009) found that when matched with an in-group member, people were significantly more likely to show charitable concern, shown through their allocation of tokens. Sudhir, Roy, and Cherian (2016) suggest that categorizing others as in-group members (along lines such as race, gender and age) increases the sense of responsibility and level of emotion felt, resulting in higher levels of sympathy and consequently a stronger urge to help. They examined this effect by randomizing advertising content in a large scale experiment with charitable mailings in India. When the woman on a flyer advertising the charity in question was from the in-group (in this case a Hindu woman in India, compared to a Christian woman in the out-group), they found a higher rate of donation and greater amounts raised. They suggest that the charity “more than doubles donation dollars by recognizing the identified victim sympathy bias in making its appeals”. 4.4 Distance: Experiential, Informational, Emotional/Affective Ref: small2007_friends small_loewenstein_07_scarecrow 4.5 Availability heuristic and media (also see ‘biases’) Rare events such as natural disasters are particularly vivid and salient, and the availability bias suggests that people will overestimate the probability and value of events if they come to mind more easily (Tversky and Kahneman 1973). For example, people might overestimate the probability of airplane crashes due to their salience. Loewenstein and Small (2007a) argue that vividness is also one of the key determinants of sympathy, and one of the most important demonstrations of this is the identifiable victim effect. Their research suggests that victims who are ‘determined’ received higher levels of aid compared with indeterminate victims, as without identifying them people struggle to empathise, and are as a result less likely to help (Small and Loewenstein 2003). This effect is discussed further under the ‘statistical/identifiable victims’ quantitative bias. Epstein (2006) concluded that natural disasters received a level of donations that was significantly out of proportion to the damage the disasters caused, while other long-term, persistent problems such as AIDS and malaria got much less attention, and consequently much less funding. For example, he discusses the difference in donation rates at the time (2006) between victims of Hurricane Katrina and victims of AIDS, with private donors giving 1,839 dollars per person to those affected by Katrina, and only 10 dollars per person diagnosed with AIDS. He also argued that the huge donations to causes like Hurricane Katrina had the effect of significantly reducing donations to some other charities, although this idea of ‘expenditure substitution’ is hard to measure and is still largely unresolved. See previous section (’Are characteristic in competition) Even when it comes to relief from the government, Eisensee and Stromberg (2007) suggest that the level of U.S. relief for natural disasters depended on whether the disaster had happened while other widely covered events were also occurring. Using data on natural disasters from the Emergency Disaster Database (EM-DAT), and disaster responses from the Office of Foreign Disaster Assistance (OFDA), they explored the relationship between news coverage and relief for natural disasters. To examine whether news had a causal effect on relief, they used two instrumental variables. These variables served the purpose of constructing “meaningful and operational measures of the availability of newsworthy material”. First, they used ‘news pressure’, by measuring the median number of minutes news broadcasts devoted to the top three news stories of the day. Secondly, they used the Olympics, chosen as a large media event that isn’t directly related to politics. They concluded that U.S. disaster relief decisions were dependent on “the availability of other newsworthy material at the time of the disaster”. Their explanation of this effect is that “relief decisions are driven by news coverage of disasters and that this news coverage is crowded out by other newsworthy material”. This potentially poses an issue for effective giving, as the authors suggest that the levels of relief shouldn’t be driven by factors that are not related to the effectiveness of the relief. They use a very interesting methodology; we might describe it a bit more. (Are there similar results for charitable giving?) 4.6 Reference dependence The issue of the arguably disproportionate attention that natural disasters receive has been previously explored. Epstein (2006) disccuses the high levels of support that natural disasters get. He drew on the work of Spence (2006), who reported that there was little relationship between the degree of need and the level of donations. This was illustrated by the private donations (at the time - 2006) of USD 1839 per person impacted by Hurricane Katrina, and USD 10 per person impacted by AIDS. Small (2010) posed potential questions that this might raise: Although the response to dramatic events showcases a great human capacity for caring, the relative neglect of ongoing suffering reveals an equal albeit less attractive capacity for indifference. Can we make sense of this duality? Why do chronic conditions fail to move us even though they do so much harm? Sudhir, Roy, and Cherian (2016) and Small (2010) have both suggested that reference dependence could provide an explanation for this issue, drawing on the work of Kahneman and Tversky (1979). Reference dependence is the notion that people don’t value absolute amounts, but instead view gains and losses relative to a reference point (Kahneman and Tversky 1979; Tversky and Kahneman 1991). Studies from Small (2010) analyze this effect beyond the utility of the individual, evaluating reference dependence in the context of others’ utility. She predicts that because sympathy could be based on change, rather than on a state, then people who have experienced a loss will induce greater levels of sympathy than those who have chronic issues. Small (2010) summarizes the move from analyzing reference dependence for one’s own self, to analyzing reference dependence when viewing the circumstances of others, as follows: Although the reference dependence modeled in prospect theory was conceived to explain the value of outcomes for the self, this research suggests that feelings and behavior with respect to the outcomes of others similarly responds to changes in welfare, not just absolute states. The studies provide insight into how the hardships of others appeal to our emotions. Bearing reference dependence in mind, the government, media and humanitarian agencies can better appeal to sympathy by shifting the focus of attention away from stats of need and instead to losses relative to a reference point. She also suggests that the high levels of sympathy and donations seen with natural disasters like Hurricane Katrina, and the relative lack of sympathy for AIDS and malaria, are consistent with this idea. The first study from Small (2010) examined whether people feel more sympathy for those who have had a negative change, by asking participants to rate their sympathy for people with health conditions that were described as either chronic or recent onset. She found that sympathy was significantly greater in the loss victims than the constant state victims, which she argued was the first evidence that sympathy may be greater in cases that involve a clear loss than for equivalent cases that involve a chronic misfortune. Her second study examined how this idea translated from emotion into actual decision making, using a dictator game. It found that allocators in the dictator game gave more money, and felt greater sympathy, to recipients who had recently lost than to those recipients who stayed constant. This led her to conclude that “prosocial behaviour is not simply a function of others’ states, but additionally responds to whether that state is chronic or changed”. In a study from Sudhir, Roy, and Cherian (2016), where they randomized charitable marketing content (described above), they also found evidence for sympathy being driven by reference dependency. They found that when victims were labelled as currently destitute, having been well-off before, this generated 50% more donors, and average donations per mailing increased by 33%. This is relative to advertisements depicting someone also described as destitute, but with an undescribed past. They concluded that this supported their hypothesis that those in chronic poverty are likely to get less sympathy than those who have suffered a change. These reference dependence effects may only be significant when the target is an identified victim. In another study from Small (2010), she examined whether the affective quality of the victim moderates the reference dependence effect. She found, consistent with her other studies, that identified loss victims elicited more sympathy than identified constant-state victims. However, when this effect was examined with statistical victims, the effect was reversed, with the constant state victims getting more sympathy than the loss victims. Small suggests that this could be because when judgements are less emotion-based, as in the evaluation of statistical victims, people are more likely to account for the duration of the hardship. She evaluated the significance of this result as follows: “This finding lends support to the key theoretical claim that reference-dependent aid judgements are driven by emotion-based thought; when the victim description is unemotional, the effect does not persist” Here we should distinguish individual’s own response to shocks from their sympathetic/empathetic and other-regarding-response to learning about others’ shocks. I would also distinguish reference points a bit more carefully; there are all sorts of effects involving reference points. 4.7 Distance - Temporal (future problems/individuals) and Hypothetical (probability of occurance) This is particularly relevant to causes and charities dealing with the medium-term and long-term future. Overview When considering how we can reduce suffering through effective altruism, immediate problems such as hunger and poverty are clearly visible. However, as well as the sentient beings alive today, altruists may consider challenges that can impact the welfare of future individuals as well. Benjamin Todd outlines this in his article on ‘longtermism’ (worth reading for a more in-depth discussion of the issue) as follows: Since the future is big, there could be far more people in the future than in the present generation. This means that if you want to help people in general, your key concern shouldn’t be to help the present generation, but to ensure that the future goes well in the long-term… This thesis is often confused with the claim that we shouldn’t do anything to help people in the present generation. But the long-term value thesis is about what most matters - what should do about it is a further question. It might turn out that the best way to help those in the future is to improve the lives of people in the present, such as through providing health and education. The difference is that the major reason to help those in the present is to improve the long-term\" This consideration of future people and future problems includes well-known issues such as climate change. It also includes less-discussed) lower-probability or more distant events such as nuclear war, bioterrorism and AI related issues (Macaskill 2015). Individuals such as Ord (2020) and institutions like the Future of Humanity Institute have argued that these problems are important and neglected. However, even motivating ‘giving for current issues’ presents many challenges; encouraging giving for (e.g.) ‘individuals who are yet to be’ born could prove even more difficult. See this podcast and the articles and books linked for a more comprehensive introduction to the long-term future. Discounting future payoffs/assets/welfare Considering how heavily we should weigh the future is a subject that has been raised frequently in the field of Economics (perhaps most notably climate economics in recent times), leading us to the idea (and various conceptions) of ‘discount rates’ (Ackerman 2008). Greaves (2017) outlines how discount rates can work as follows: Suppose we have an opportunity to undertake an investment project, sacrificing k &lt; 1 units of consumption today in order to secure an increase of 1 unit in consumption a time interval t later. Our basic question is: what is the threshold value of k at which the status quo becomes socially preferable to such a sacrifice? The answer to this question is the social discount factor for consumption at time t, R(t). (One also has a private discount factor, corresponding to private as opposed to social preferences; in the remainder of this article, the focus is on the social version.) One generally expects R to decline with time — we are willing to sacrifice more today to gain an increase in one unit of consumption tomorrow than to gain an increase of one unit of consumption next year. The decline, however, may be faster or slower, and for current purposes the rate of the decline is crucial. The choice of discount rate is crucial in the evaluation of projects some of whose important effects are long-term. Analyses that use a higher discount rate will tend to favour the short term: projects requiring sacrifices in the short term for the sake of benefits in the further future will be more likely to fail cost-benefit tests. For further reading on discount rates see Weitzman (1998), Ackerman (2008), Ebert and Prelec (2007), and Farmer and Geanakoplos (2009) An informal discussion from David Reinstein In considering whether there is a bias against helping people in the future we need to establish a baseline: At what rate (if at all) should an effective altruist weigh (far) future lives/pleasure/suffering as less-valuable as current or near-future lives? At what rate should we ‘discount’, if at all? I think it’s actually not clear that we, as a society, should be discounting at all, either for consumption itself, or for some conception of ‘happiness’ or ‘utility’ (where here I’m thinking of ‘utility’ as something that does express well-being, not the very abstract economic concept of ‘the thing that we maximize’). Individuals might discount future “pleasure”: because they might not survive to the future (although this should enter in as a ‘survival discount’ tied to the probability of surviving) because they are impatient (but this is potentially not in their own interest) Individuals may discount future ‘income’ (in currency, inflation-adjusted) or ‘physical consumption’ If we think the ‘future me’ will be wealthier than the present me (consumption smoothing) Or if we think I will be less sensitive to pleasure/pain Businesses/investors may discount future earnings (again, inflation adjusted) If they think that there are other opportunities for ‘returns above inflation’ … because ‘returns to capital exceeds the rental cost of capital’ This should be true for growing societies as well, i.e., where there is real-GDP/capita growth (I’m being a bit loose here) This is not the same as discounting future utility or welfare. There’s no clear reason we should do this. Reasons the distant future may be neglected Beyond the technical analysis of “at what rates people might discount the future”, Schubert (2020) outlines a few reasons why the distant future may receive less attention and action. He argues: Present issues are likely more salient than future issues, and because these issues are more salient, they will be discussed more. Uncertainty is likely an important factor. Even if you are concerned with future well-being, if it is unclear how you can impact the distant future, you may be more likely to focus on other issues. Lack-of-polarisation: “When there is no political conflict, a question might get less discussed, even if it’s seen as morally important”. While uncertainty could pose a problem for encouraging giving for distant future causes in particular, factoring in uncertainty is not necessarily a bias. It may be a reasonable choice, and there is further discussion of uncertainty and how this may link to a form of risk-aversion (see here). The other barriers in this section also link to a potential lack of future-focused giving. For example, when it comes to the availability bias, we suggested that vividness and salience of events may influence how people estimate probabilities. Future events may be hard to picture, particularly more abstract risks like the dangers of artificial intelligence We also discussed the identifiable victim effect. It could be significantly harder to create a story around a single victim if victims affected by that issue do not yet exist. Victims of the distant future may have to be statistical victims only, potentially eliciting less sympathy and consequently less donations. Charities that focus on the distant future may also have issues demonstrating evidence of their impact to donors, which can help to encourage donations ((Karlan and Wood 2017a). However, the influence of demonstrating impact is mixed, as we further discusshere. The impact of people being categorised into in-groups and out-groups could also be considered in analysing potential donations to distant-future causes. In their review of the literature, Sudhir, Roy, and Cherian (2016) suggest social identity works as follows: Social identity has three major components: categorization, identification and comparison. Categorization is the process of putting people, including ourselves, into categories; for example, labelling a person as Chinese, black, female, or a lawyer are all different ways of categorization. Categorization also defines our self-image. Identification is the process by which we associate or identify ourselves with certain groups. We identify with in-groups, and we do not identify with out-groups. Finally, comparison is the process by which we compare in-groups with out-groups, creating a favourable bias toward the in-group. Overall, categorization of others as belonging to an in-group arouses feelings of greater closeness and responsibility and augments emotional response to their misfortune through greater sympathy (Brewer and Gardner (1996), Dovidio et al. (1997)) and willingness to help (Dovidio (1984), Dovidio et al. (1997)). Distant-future generations might be mentally placed in their own category (considered separated from near-future and present generations). This categorical distance could mean that people identify with distant-future generations less. If they are seen as an out-group, this could pose a barrier for giving to distant future generations. Whether those in the future are indeed commonly percieved or treated as an out-group may be an interesting research direction. This is something we need to look into more for this present survey. 4.7.1 Evidence (work in progress) What is the evidence that they are actually doing this (taking into account the ‘uncertainty’ issue (we know less about how to help the far-future). What factors drive this bias or mitigate it? List of references "],
["identity.html", "5 Barriers: Identity and cognitive dissonance 5.1 Self-interest/local public good (?) 5.2 Cognitive dissonance 5.3 (Side note?) Volunteer experience unlocks emotion and giving", " 5 Barriers: Identity and cognitive dissonance 5.1 Self-interest/local public good (?) In the context of ‘team reasoning’ and cooperative equilibria, it may seem selfishly beneficial to give locally/ to a public good that your smaller group gains from. If there is \"“competition”\" ….diminishing empathic returns to giving or moral licensing this may lead to less EG. 5.2 Cognitive dissonance “Accepting EA would imply I was wasting my money/doing it wrong… \\(\\rightarrow\\) they try not to think about effectiveness or are averse to it or just consistency motive” 5.3 (Side note?) Volunteer experience unlocks emotion and giving (Contemplating) Volunteering for a cause may make people care about it more, and be more likely to give to it. It is difficult for people to have volunteering experiences with most EA causes. People tend to volunteer for local and domestic causes, and their sympathy and giving may follow this (perhaps to avoid cognitive dissonance). Alternatively/additionally, the volunteering for the local cause may substitute for EG (via moral licensing or a related channel): ‘I volunteer for the Girl Scouts so I’m doing enough good, but I don’t need to donate to Against Malaria Foundation’ "],
["social.html", "6 Barriers: Signaling and social pressures/social identity 6.1 Signaling concern for effectiveness/impact versus other values", " 6 Barriers: Signaling and social pressures/social identity 6.1 Signaling concern for effectiveness/impact versus other values 6.1.1 Theory and argument Simler and Hanson (2017) argue that social signaling is a major driver of human behavior, particularly in the charitable domain. Essentially, we may make choices that we would not have otherwise made in order to boost our reputation among our peers, colleagues, etc.. Reputation may be valued for its own sake or instrumentally, as a means to inducing others to act more favorably to us. Game theory (see esp. (Spence 1973)) offers a precise conception of this signaling as a costly way to demonstrate one’s positive “type” in a context with asymmetric information. Several authors (can be interpreted to) suggest that valuing ‘’effectiveness in generosity’‘, i.e., moral-utilitarianism, is seen as a negative signal by peers and lowers fitness in the cooperation market, at least in comparison to signaling compared to deontological or ‘sacred values’. The exchange below captures the basic argument… From Robin Hanson and Rob Wiblin exchange on 80000 hours podcast; see Chapter 12 of “The Elephant in the Brain” (Hanson) Hanson: But of course people spend a lot of time directly helping even when they’re relatively well-paid and they could pay other people who earn much lower wages to do a lot more. Wiblin: This is the example of the high-flying lawyer dishing out soup in a soup kitchen. Hanson: … the alternative theory that we suggest is that you are trying to show that you feel empathy. That is you want to show there is an emotional capacity in you such that if you see someone around you in need you will feel like you want to do something about that. And existing charities do tend to successful show that. They show somebody who needs help in a direct way that invokes your emotions and you do help to some degree, you do the thing that people would say would help and that shows people around you that you’re not an uncaring person and it might show them, for example, that if they were in need of help later and they were near you you would see them and you would feel about them too. You want to show people that you will be useful ally. If either of you is in trouble the other will come to their aid. Wiblin: So why is it more important to show the people that you’re the kind of person who if they someone in pain that they’re going to try to help them right then and there than to show that you’re the kind of person who’s smart enough to think about which charities are useful and does their research and actually tries to help people? Because if you don’t care about whether charities are effective or not, my thoughts would just be that you’re not really going to pay attention to whether you’re actually helping your friends or not? Hanson: Right, but at least if I want your help and I’m your friend it will be my job to put myself in your face and to tell you about my problem. And maybe I figure I coul successfully get myself in front of your face and make you pay attention to my problem and help you understand what I think is effective and then you would just do what I say, and that’s maybe what I’m mostly hoping for. And if you were this person who thinks carefully about how to help the best person in the world who needs help, well I’m plausibly not going to be that best person in the world who needs help so I’m not going to win out in that contest so it’s not actually going to be that useful to know you as the sort of person who will help the person in the world who needs the most help. (J. A. Everett, Pizarro, and Crockett 2016) argue that deontological ethics signal stable cooperative behavior to others, which enhances fitness in mutualistic partner choice models. The basic argument is “An individual who claims [and believes] that stealing is always morally wrong … seems much less likely to steal from me than an individual who believes that the stealing is sometimes morally acceptable depending on the consequences.” Background and further discussion … in fold The authors’ motivation is to explore why “intuitive moral judgments often”share characteristics with deontological theories while “consequentialist judgments are often the result of slow, deliberative cognitive processes”. Their key theoretical argument cites “mutualistic partner choice models of the evolution of morality”, which… posit a cooperation market such that agents who can be relied upon to act in a mutually beneficial way are more likely to be chosen as cooperation partners, thus increasing their own fitness the typical deontological reason for why specific actions are wrong is that they violate duties to respect persons and honor social obligations-features that are crucial when selecting a social partner. An individual who claims that stealing is always morally wrong and believes themselves morally obligated to act in accordance with this duty seems much less likely to steal from me than an individual who believes that the stealing is sometimes morally acceptable depending on the consequences. Actors who express characteristically deontological judgments may therefore be preferred to those expressing consequentialist judgments because these judgments may be more reliable indicators of stable cooperative behavior. And recent theoretical work has demonstrated that -“cooperating without looking”—that is, without considering the costs and benefits of cooperation—is a subgame perfect equilibrium (Hoffman, Yoeli, and Nowak 2015). Therefore, expressing characteristically deontological judgments could constitute a behavior that enhances individual fitness in a cooperation market because these judgments are seen as reliable indicators of a specific valued behavior-cooperation. Hoffman, Yoeli, and Nowak (2015) present an evolutionary game theoretic analysis of an indefinitely repeated game where Here the analogy to effective versus ineffective giving is not clear… Player 1 can publicly ‘look’ to see the cost of cooperation, Player 1 next chooses to cooperate or defect, and then Player 2 chooses whether to continue repeating the above game, or end the relationship. They provide conditions under which ‘cooperating without looking’ (CWOL) is part of a subgame-perfect Nash equilibrium, and an evolutionarily stable equilibrium can involve a substantial rate of CWOL play. However, the analogy to effective versus ineffective giving is not clear. Perhaps a connection could be made if considering the charity effectiveness tended to provide a motivation to give less, but this is not obviously the case. In general, an ‘excuse not to do something’ is not the same as a ‘choice to be effective’. 6.1.2 Evidence for this barrier We consider specific empirical claims that could be interpreted as evidence that this is an important barrier. Evidence that “consequentialist choices lead to negative signals and less-favorable treatment relative to deontological/emotionally intuitive choices” (J. A. Everett, Pizarro, and Crockett 2016) J. A. Everett, Pizarro, and Crockett (2016) ran a series of experiments on the Mturk platform, involving hypothetical dilemmas paired with low-stakes (or no) Trust games. In each, participants were asked to make and justify their judgement in a moral dillemma such as the famous ‘trolley dillemma.’ In each case, this was a (hypothetical) choice between inaction and taking an action that sacrifices a small number of lives to save a larger number of lives. Would you “push a man off a footbridge to stop an oncoming train from hitting five”? We then had our participants rate the morality and trustworthiness of each agent on a scale (Study 1a), play a hypothetical trust game (TG) with the agents (Study 1b), and, finally, play a TG involving real monetary stakes with the agents (Study Across several studies deontologist agents were preferred in partner choices by participants endorsing the same values; even moral-utilitarians seem to favor peers who express emotional empathy and deontological ethics (ibid., p. 45). However, this difference was not present in the track-switching dilemma, the only dilemma in which a majority favored the consequentialist choice. Incorporate some of the other papers mentioned in the Gdoc here Montealegre et al. (2020) Does Maximizing Good Make People Look Bad? Manuscript Type of evidence: Online experiment (M-turk) with hypothetical choices (attitudes), six pre-registered studies using two different scenarios (N = 1,961) Relation to charitable giving: directly, since … Scenarios (including within and between subjects approaches): participants evaluate a response to survey question about how to select a charity (“If you were to donate, how would you select which charity to donate to?”). Deliberative: I would use evidence to calculate which charity spends its donations most cost effectively, and donate to them. Empathic: I would try to put myself in the shoes of people who are going through difficult situations, and donate to a charity that helped them. John was approached by a charity fundraiser and was asked whether he would be interested in donating to help Rokia, a 7-year-old girl from Mali, Africa who was desperately poor and faced the threat of severe hunger or even starvation. The charity fundraiser showed John a picture of Rokia (also presented to participants) and then asked John whether he would be interested in supporting her. Across conditions, participants were presented with the general scenario and only the potential donor’s actions differed depending on the condition: Deliberation: “John thought that donating to help Rokia might not be the most cost-effective way to use his money and that maybe he should donate to a charity doing something more cost-effective instead. He asked the charity fundraiser about the relevant statistics of the program and since the data suggested this charity was the most cost-effective John donated to the charity.” Empathy: “John was deeply moved by Rokia’s situation and about how terrible her situation must be for her. After hearing about her tragic story and imagining how his donation could help her John donated to the charity.” Robustness checks for: gender, stake size Background mechanism: donors’ failure to prioritize cost-effectiveness can be explained by signaling concerns, since people who favor deontological over consequentialist decisions are preferred as social partners (J. A. C. Everett, Pizarro, and Crockett 2016) Key findings: Across six studies, donors who deliberated were perceived as having worse moral character, were rated as less desirable as social partners, and were judged to be less guided by moral motives. On the other hand, those who deliberated were also seen as more reasonable and competent, and were judged to be more guided by pragmatic motives. Thus, there may be reputational benefits associated with deliberating. However, since deliberators are less preferred as social partners the authors believe the overall effect one reputation is negative. They do not find any differences in trustworthiness. Exhibiting empathy before deliberating reduced most negative reputational effects. People how do not give at all are seen as the worst. Surprisingly, participants judge the empathy donors as more wasteful. 6.1.2.1 Considerations Even if we accept the above evidence (that those who make consequentialist active choices in “sacrificial dilemmas” are seen as less trustworthy and less moral) this may not generalize to effective giving. Researching and selecting a more effective charity is closest to the ‘track switching’ scenario in these experiments, in which no substantial difference was observed, and even here it is a stretch. Choosing a more effective charity instead of a more local one (e.g., river blindess prevention in Africa versus local guide Dogs) would be hard to cast seen as taking an active step to harm someone. True, a local blind person may fail to get an additional (fraction of a) dog as a result of this choice. However, there is little sense in which “you funding his dog” would be seen as the status quo absent your intervention. 6.1.2.2 Indirect evidence (Kahane et al. (2018); Jordan et al. (2016); Hoffman, Yoeli, and Nowak (2015)) List of references "],
["eval-aversion.html", "7 Barriers: Aversion/obstacles to doing (using) evaluations; effect of analytical information on generosity 7.1 General relevance to effective giving 7.2 General cost-benefit analysis (CBA)-aversion or reluctance 7.3 Information as an ‘excuse’ not to give; allows motivated reasoning 7.4 Exposure to cost effectiveness and impact information (analytical information) may reduce generosity 7.5 Overall ‘net’ responses to charity ratings", " 7 Barriers: Aversion/obstacles to doing (using) evaluations; effect of analytical information on generosity Note: this relates to an ongoing project of David Reinstein with several co-authors, including ongoing field experiments as well as meta-analysis being planned. Much of this project is organised in the dualprocess repo. An earlier set of presentation slides (now pictures are missing – need to recover) is hosted here - press ‘O’ to see the fill multidimensional slide map; the outline slide is here 7.1 General relevance to effective giving For people to choose one product over another on the basis of some characteristic (e.g., safety, taste, or durability), they presumably must be aware of these differences before purchasing. Economists note [ref] the difficulty of investing in producing, marketing and selling high-quality products and services when consumers have difficulty distinguishing these products from inferior ones. This is especially difficult when the quality of a product is not known before purchase (an ‘Experience good’[ref] such as a ticket to a particular stage show), or when it is not known until a long time later, if at all (a ‘credence good’ such as a health remedy or investment advice.) Insert abundant references here to asymmetric information, fly-by-night competition, and experience and creedence goods, product reviews, regulation, advertising as a signal, etc. Considering a charitable donation as a product purchased by the donor, it seems to fall into the latter category[ref to authors making this point]. If donors value their ‘marginal impact on outcomes’ as discussed in our earlier definitions of impact, they may need to do extensive research (or at least know about and visit web sites such as GiveWell and ImpactMatters) to have some estimate of the value-for-money they are getting. Donors may also be uncertain about other benefits they main gain from each donation such as ‘gratitude and long-term sense of fulfillment’. A typical charitable donor, particularly one who donates towards a geographically-distant intervention, will never directly see or experience the consequences of her donation. Thus, for people to systematically choose to donate to the most effective charities, presumably… They must understand and value the idea of effectiveness. They must either: know how effective charities are relative to one another, have reliable information on this presented to them by the charities (or other entities), or they must want to and find it appropriate to seek information on this, and be able to obtain reliable information. (For b or c to have the desired effect…) The act of learning about effectiveness must not substantially decrease their willingness to donate. In this section we consider the evidence for I. People’s aversion/willingness (or sense that it is appropriate/inappropriate) to evaluate effectiveness in a charitable giving context The impact of being presented with (or actively pursuing) effectiveness information (which is naturally analytical information) on generosity and the willingness to donate Effectiveness information may also affect how donors perceive the social signaling value of their donation. We return to this in the signaling and social pressures… section. Further ‘grant-worthy’ motivation (unfold). As noted above, scientific evidence suggesting that organizations’ “cost per outcome” differs substantially, perhaps by a factor of 1000 or more (Jamison, Karlan, and Schechter 2008). This has motivated an increasing focus on charity effectiveness, spearheaded by initiatives from the Rockefeller and Gates foundations. Furthermore, organizations like GiveWell now provide direct ratings on the basis of per-dollar impact (e.g., cost per life saved), and are reaching out to larger audiences. This approach might boost giving, by leveraging donors’ preferences for contributions “to be put to good use”—i.e., for direct interventions. E.g., In Aknin et al. (2013) participants reported greater happiness when the impact of their contribution was highlighted. (van Iwaarden et al. 2009; Aknin et al. 2013). However, while we have rigorous evidence on what works and doesn’t work in anti-poverty and health interventions (acknowledged by the 2019 Economics Nobel Prize), we actually know very little about how potential donors react to this impact information! However, we actually know very little about how potential donors react to this impact information! 7.2 General cost-benefit analysis (CBA)-aversion or reluctance This is hard to label: ‘aversion’ may be the wrong word: people may finding it less appropriate/normal/virtuous to do CBA in a charitable context, or it may naturally not occur to them to do it. 7.2.1 Description People may be reluctant* to consider the cost and benefits of the actions they are funding through their charitable donations (or they find this less appropriate/normal). This contrasts with a much greater willingness to consider these and other domains such as consumption, investment, and public policy. People also seem to avoid accessing/buying/seeing information (particular information that may be likely to feel compelled to give.) How is this reluctance observed/manifested? 7.2.2 Theoretical/conceptual discussion For this to be considered a bias, the relevant individuals must intrinsically value the usefulness of their charitable activity at least to some extent. I.e., they must be Moral Utilitarians, at least in part, or for some of the time. However, they may consider it very costly or distasteful to actually do this evaluation, or it may clash with other motivations and tendencies. This aversion also must be distinguished from a lack of ability to do CBA in the charity domain; the latter would instead be considered a quantitative bias. The reluctance to engage in this evaluation process may relate to the aforementioned “taboo trade-offs”; if these tradeoffs are taboo, considering them may involve great emotional distress. (Berman et al. 2018) refer to the idea that “believing that charity is a subjective decision licenses individuals to donate in personally gratifying ways.” This perspective plausibly combines partial and conflicted Utililitarian preferences with the presence of moral licensing. As Berman et al. (2018) note, the belief that CBA is not a natural part of the charitable domain may stem from the lack of direct feedback one gets from donating (in Economics terms, a “credence” good) relative to consumption and investment goods. (they cite: Imas paper?) Several papers^citation needed^ find that people are reluctant to pay for—or actively seek to avoid— certain information. However, these may reflect motives distinct from CBA, such as a self-serving bias. On the other hand … a majority ranked effectiveness [how highly?] as a crucial criterion to select a charity and reported greater happiness when the impact of their contribution was highlighted. (Aknin et al. 2013; van Iwaarden et al. 2009) Psychological theory behind CBA This CBA discomfort brings together several overlapping theoretical frameworks: Fiske’s Relational Theory (Fiske (1992); also see Aggarwal (2004)), which proposes four basic types of social relationships: communal sharing, authority ranking, equality matching, and market pricing. For more here, see Heyman and Ariely (2004) on social vs economic markets. Taboo Tradeoffs &amp; Protected Values: to the extent that CBA requires making taboo tradeoffs that clash with protected values, people may be reticent to engage in CBA for prosocial purposes. Distorted Altruists as the existing dominant view (contrast) c.f., Loewenstein and Small (2007a); Slovic (2007) -- people care about welfare maximization, but without clear information to make comparisons, they rely on their feelings to guide choice (Loewenstein and Small (2007a); Slovic (2007)). Berman et al. (2018) build on this. We distinguish CBA opposition from the inability to conduct CBA. The former is treated here while the latter involves a series of quantitative biases discussed later. Relevance to Effective Giving (restated in fold) If determining which charity is effective requires CBA people may avoid doing so. If effective charities force people to consider CBA then people may avoid these charities in order to avoid having to do these evaluations. Stated more broadly, effective giving is predicated on conducting CBA for programs and organizations. To the extent that people are uncomfortable with CBA in the charitable domain, they will be uncomfortable with giving effectively. 7.2.3 Evidence surrounding CBA Evidence for claim: “People sometimes actively avoid information about charity effectiveness that would motivate doing a CBA…” (Fong and Oberholzer-Gee 2010a) run dictator game experiments involving payments to real-life welfare recipients living in 178 public housing in Pittsburgh; each subject is matched with a particular recipient of their potential donation. In their “Choice treatment”, a subject can choose to pay $1 to learn about a recipient’s drug use or disability, information meant to suggest the deservingness of the recipient. “We find that a third of the dictators are willing to pay money to learn more about their recipient. Dictators who acquire information mostly use it to withhold resources from less-preferred types, leading to a drastic decline in aggregate transfers.” But this needs to be interpreted carefully: those who decide not to buy information appear less generous than the average! (DellaVigna, List, and Malmendier 2012) provide evidence that people will pay costs to avoid being asked and avoid social pressure. However, for this same case if they are asked they then to respond by giving. While “avoiding the ask” is not avoiding cost-benefit analysis, it suggests that people are in fact strategic in avoiding things that may make them feel compelled to donate. Note: This evidence is only tangentially relevant. Evidence for “People rarely seek out effectiveness information and are reluctant to purchase it” In the final stage of an experiment from Null (2011): Subjects were given the option to spend USD 5 of their total gift to the development charities in order to find out which of the three would receive a matching rate of USD 3 (the other two would receive matching rates of USD 1.50). Altruistic subjects whose donation was at least USD 20 and gave to all three charities, or whose total gift is greater than USD 35 and gave to two charities, would find it profitable to purchase the information. … (84%) met these criteria on gift size and number of charities supported. …only 40% of subjects were willing to give up a small portion of their endowments in order to find out which charity would receive the highest rate; the rest preferred to allocate their gifts without knowing what they would be worth to the charities.\" ...These subjects who chose not to purchase the information forfeited matching funds ranging from 30-150% of the value of their unmatched gifts, with the median donor sacrificing matching funds exactly equal to the value of her unmatched gift, a truly staggering sum. Null attributes this failure to buy information either to subjects who “simply did not care about the potential to substitute into the charity with the highest matching rate”, perhaps driven by some form of simplistic warm glow motive, or to simple misunderstanding or fatigue (in an incentivized elicitation, she found some evidence of incomplete comprehension). To the extent this is not a misunderstanding, it might be seen as evidence of CBA aversion; participants did not want to purchase evidence that would require them to do calculations in this domain. Evidence for “People do not respond ‘efficiently’ to information about costs and benefits” This might be moved into to the next section Null (2011) ran a set of experiments at Kiwanis/Rotary clubs and with “professional subjects” (university administrators?) at the Berkeley X-lab; the former strictly involved allocations among charities, in the latter case what was not given away could be kept. For the main reported treatments, participants made a series of decisions under different incentives (mostly on the same page and thus simultaneously?). The “prize” was $100; in each session only one decision from one subject was chosen for actual payment/donations. Many participants who choose to donate positive amounts to multiple charities in earlier (?stages) continue to donate to multiple charities when one charity is given a better match rate; they only “imperfectly substitute” (and some even substitute away from the now “lower-priced” charity). She attributes this to both risk aversion (diminishing utility in to each charity’s actual impact, along with uncertainty about this impact) as well to as a version of “warm glow” with a diminishing marginal benefit in the amount given to each charity. She also introduces exogenous risks over matching rates, and notes that roughly 2/3 of those that choose to shift only imperfectly are not measured to be “risk averse”. However, this could also be attributed to a simple failure to make these cost-benefit calculations (as she also found some evidence suggesting misunderstanding of the nature of these incentives). Consider also (Metzger and Günther 2019a). Evidence for “people accept and value subjectivity in the charitable domain more so than for other choice domains” (Berman et al. 2018) provide evidence from a series of five survey/vignette experiments; unlike those mentioned above, these (mostly) involve hypothetical choices among multiple causes. All experiments use standard subject pools (behavioral lab subjects or m-turkers) with reasonably large samples. All ask for hypothetical (Likert-scale) responses involving fictional charities, investments, and other scenariae; they mostly rely on between-subject responses, and their statistical analyses report reasonable tests on the relevant comparisons. Their “Study 1: Perceived Subjectivity of Charity” found that, in rating statements such as “it is important that the ______ I choose reflects my personal tastes or values” and “It is more important to rely on objective measures rather than personal feelings when choosing ______ ... they found people agreed more with the subjective/taste approach when assigned a treatment where the blank was”Charity\", relative to those assigned treatments involving medical treatments, investments, and cel phones. (But less than some other things like art, and similar to restaurants in some tests!) Their “Study 2: Personal Feelings Versus Welfare Gains” presented participants with “Mary” and a pairing of fictional domestic (homelessness) and international (micronutrient) charities, presenting effectiveness information on both (clearly favoring the latter). The treatment-- which charity Mary felt an emotional connection to-- had a significant impact on the response to “Which charity should Mary donate to”, in the predicted direction. They were also asked: “Which option does the greatest good for the greatest number of people?”; here responses favored the international charity for both treatments; but even so, when Mary felt connected to local charity, participants favored donating there. Somewhat puzzlingly, Mary's connection to the charity also affected the stated “effectiveness” response! This bears a closer look. In their “Study 3: Charity Versus Investment Choice”, subjects were assigned categories and fictional examples of either charities or investment, and presented domain categories and effectiveness information for each. Fewer participants in the charity treatment (relative to the investment treatment) chose to sort by effectiveness rating, and fewer chose the highest rated option. In Study 4, they find that, in rating research departments for funding, participants pay more attention to charity effectiveness ratings when the are given the “role” of a “president of a local medical research center” rather than a donor. Similarly, in Study 5 participants assess someone who allocates funds to a research department; participants respond to the effectiveness of the department chosen more when rating the decision quality and altruism/selfishness of a “president…” than rating a “donor”. Overall, these suggest that, when considering charitable donations, people tend to favor–or at least to accept–the use of subjective preferences and personal ties, rather than objective information, and they do so more than for more “standard” goods and choices. This is more accepted for “donors” than for people with responsibility for others’ funds. Berman et al argue that their results demonstrate the acceptance of the suggestive preferences is somewhat attenuated by the \"role of responsibility\", but it's not clear what this term means or how this could be relevant to voluntary individual giving. However (as they do note), the effectiveness information still has some (positive) effect on participants’ responses; it is not ignored. Their experiments also do not analyze the avoidance of information or CBA. Methodological strengths and weaknesses: hypothetical nature of choices some evidence suggestng these are not taken seriously specific context in vignettes allow alternative interpretations… 7.3 Information as an ‘excuse’ not to give; allows motivated reasoning Exley (2016) Greater discounting of ‘less-efficient’ charity in charity-charity decision-making than in charity-self d-m Fong and Oberholzer-Gee (2010a) “Dictators [charitable giving] who acquire information mostly use it to withhold resources from less-preferred types, leading to a drastic decline in aggregate transfers” But… Exley issues: Experimenter demand (M-turk focus), not really ‘impact’ information Fong: Selection effects. In their tables, exogenous provision of information seems to increase donations overall. Also … it’s evidence on the deservingness of the recipients, not on impact of a charity itself. (Metzger and Günther 2019a) Lab donations to high/low-performing NGO More purchasing of ‘recipient type’ than ‘impact’ info Mixed &amp; weak evidence on excuse-driven information-seeking Caveats… Opportunity to buy info on ‘recipient type’ increased giving, on ‘admin costs’ decreased giving (marginal significance for both), no effect of ‘aid impact’ but wide CI ‘Free info’ on each of these had insignificant effects (underpowered!) Lots of caveats; e.g., recipient type (artists vs children) may have been seen as a proxy for impact 7.4 Exposure to cost effectiveness and impact information (analytical information) may reduce generosity May turn off System-1 and reduce giving Statistics diminish impact of ‘identifiable victim’ References: Small, Loewenstein, and Slovic (2007), Karlan and Wood (2017a), Bergh and Reinstein (2020), Smeets, Bauer, and Gneezy (2015) See also: Linda, Organizations, and Parsons (2007) A subjective outline of the evidence: The evidence (from the Economics/Behavioral Economics literature) is largely mixed and indeterminate. There has been only a single strong field trial (Karlan and Wood 2017a) in a particular context, which itself reported mixed (null overall, positive for some subgroups, negative for others), and some underpowered results. Laboratory experiments (with real donations) by Small et al find that giving to an identifiable victim is reduced when statistics are also presented and “priming analytic thinking reduced donations to an identifiable victim relative to a feeling-based thinking prime.” Further evidence from lab experiments is mixed and limited, with some studies (Fong and Oberholzer-Gee 2010a) apparently finding that exogenous information about recipient increases donations (although they do not report this). There is some speculation, but again, mixed evidence, that individuals already in a “system 2” (deliberative) frame are more likely to be positively affected by impact information. There is also a distinction to be further explored between “output information” (how the donation is used) and “impact information”; the former is seen to increase generosity in several studies. 7.4.1 Presenting “Effectiveness” and other types of analytical efficiency information 7.4.1.1 Karlan and Wood (2017a) While Karlan and Wood (2017a) did find that those who had previously donated large amounts gave more when they received effectiveness information (and Parsons found similar effects for efficiency and prior donors), the reason for this effect is unclear. For example, large/frequent donors may experience a greater pressure to donate in light of any new positive information. - Bergh and Reinstein (2020) Design and results summary: Add scientific impact text to base script (included a standard qualitative story about an individual beneficiar) &amp; remove emotional text: \\(\\rightarrow\\) little net effect \\(\\rightarrow\\) reduced (increased) giving among small (large) prior donors (not a preregistered hypothesis) Potential confounds, specificity Yale/institution effect (seemed negative) Nature of ‘impact’ information (not entirely quantitative) ex-post splitting two things changed at once (impact in, emotional out) Details of Karlan first wave: SCIENCE vs EMOTION According to studies on our programs in Peru that used rigorous scientific methodologies, women who have received both loans and business education saw their profits grow, even when compared to women who just received loans for their businesses. But the real difference comes when times are slow. The study showed that women in Freedom from Hunger’s Credit with Education program kept their profits strong–ensuring that their families would not suffer, but thrive. &gt; Because of caring people like you, Freedom from Hunger was able to offer Sebastiana a self-help path toward achieving her dream of getting “a little land to farm” and pass down to her children. As Sebastiana’s young son, Aurelio, runs up to hug her, she says, “I do whatever I can for my children.” Linda, Organizations, and Parsons (2007) 2 x 2 mailing appeal for People with Aids Coalition-Houston, Add “Service efforts and accomplishment info”(SEA) Add favorable “FINANCIAL” spending/overhead ratio info FINANCIAL (alone) \\(\\rightarrow\\) 180% increase in odds of donating among prior donors (\\(p&lt;0.05\\)) (Other effects mainly insignificant, underpowered) Unsure if it’s a logit or LPM – confusing writing Not effect-coded; no measure of overall impact of FINANCIAL across both SEA treatments Probably not preregistJjji I’d like to see CI’s knitr::include_graphics(&#39;picsfigs/parsons_fin_treat.png&#39;) Further details from Parsons (unfold, direct quotes from paper) (This is all direct quotations:) Potential donors were sent, via a direct mail campaign, fundraising appeals containing varying amounts of financial and nonfinancial information in order to determine whether individual donors are more likely to contribute when accounting information or voluntary disclosures are provided … A logistic regression provides evidence that some donors who have previously donated use financial accounting information when making a donation decision. The results are inconclusive regarding whether donors use nonfinancial service efforts and accomplishments disclosures to determine whether and how much to give, but participants in the lab experiment judged the nonfinancial disclosures to be useful for making a giving decision Both experiments use a two-by-two design to manipulate the direct provision of (1) financial information (derived from mandatory informational tax filings which are available only if requested by the donor) and (2) voluntary disclosure of nonfinancial accounting information (not otherwise available to the donor). By analyzing actual cash receipts from the fundraising appeal, I find that donors who had previously contributed to the organization are more likely to donate when financial accounting information is directly provided. New prospective donors make larger contributions when either financial information or voluntary, nonfinancial accounting information is included with a basic fundraising appeal, but differences are not statistically significant. The first manipulation is to include financial information drawn from the audited financial statements with the basic fundraising appeal. Summary charts and graphs, instead of full financial statements complete with footnotes, are used to highlight the efficiency measures typically emphasized in previous literature. The financial information indicates that 92.5 percent of the entity’s expenditures were directed to program expenses in the prior year. This figure compares favorably with the 60 percent suggested minimum level recommended by the National Charities Information Bureau The second manipulation is to include a voluntary disclosure of service efforts and accomplishments (SEA) that describes the organization’s past efforts to serve its beneficiaries and gives specific information about the success of its programs (see Appendix C). This information is in narrative form and written in lay terms. 3 It provides both output (quantity of product or service produced) and outcomes (results) information as defined in Hatry et al. (1990). Charity: People with Aids Coalition- Houston 7.4.1.2 Bergh and Reinstein (2020) From Abstract: Across six experiments we examined how images of identified victims interact with information about charity efficiency (money toward program) and effectiveness (program outcome). We further examined if the images primarily get people to donate (yes/no), while efficiency/effectiveness might provide a tuning mechanism for how much to give. Results showed that images influenced the propensity to donate and induced participants donate their full bonuses, indicating heuristic effects. Efficiency and effectiveness information had no effects on donations. Need to delve into this further: tight null effects or underpowered studies? Consider confidence intervals of effects reported, as in tables below. These need some clarification and improved formatting. (Note that in the above, all binary variables are ‘effect coded’) Considering ‘Don share’ (the share of the endowment contributed), as well as the linear probability model, we see that the pooled effect of the effectiveness information is fairly tightly bounded around zero. Even at the 95% lower bound, the effect is no more than an 11% reduction in the share donated (.04/0.35), and a 10% reduction in incidence (.06/.62). Study 6 had the most straightforward ‘impact information’ as per our definitions. Above we see estimated of odds ratios, relative to the control group, of the incidence of donating to RB (Carter Center: the river-blindness charity) and GD (Guide Dogs for the blind). Confidence intervals reveal a lack of power. However, there is suggestive evidence (p=0.09 and p=0.16, respectively) that the image lead people to be less-likely to donate to GD and more likely to donate to RB. This may have been driven by the African appearance of the blind girl depicted. The wide confidence intervals of the odds ratios suggests that Study 6 had limited statstical power. 7.4.1.3 (Caviola, Schubert, and Nemirow 2020) Series of hypothetical experiments, mainly on M-Turk Abstract: … Across six tasks (Studies 1a, 1b), we found support for both explanations. Among lay donors, we observed multiple misconceptions—regarding disaster relief, overhead costs, donation splitting, and the relative effectiveness of local and foreign charities—that reduced thee ffectiveness of their giving. Similarly, we found that they were unfamiliar with the most effective charities (Studies 2a, 2b). Debunking these misconceptions and informing people about effectiveness boosted effective donations; however, a portion of lay donors continued to give ineffectively to satisfy their personal preferences. By contrast, a sample of self-identified effective altruists gave effectively across all tasks. 7.4.1.4 (Mulesky 2020) Setup Participants “recruited through Positly, an online study recruiter that solicits high quality participants from Amazon’s M-Turk” Series of experiments giving participants a hypothetical choice: “you have the opportunity to donate 100 USD to i. [described charity] or ii. Some other international health charity.” They needed to hypothetically allocate the 100USD completely between these two. Study 1 treatments: No Impact information Null Impact information (\"study found that Human Rights International did not have the desired impact, suggesting that reform is needed to increase effectiveness’.) Realistic impact information … “results of the study suggest … [HHI} saves the life of one person for each 2000 USD spent” Unrealistic impact information “… for each 150 USD spent” Study 2: Similar to Study 1, but for preventing HIV infections The third study revolves around the addition of overhead information, in with what might be seen as a fairly negative presentation. I do not discuss it here Results considered Stated finding: &gt; Charities are only rewarded for revealing information about their impact when the results are unrealistic and unattainable. In fact, the mean donations were ordered: Unrealistic (Impact information) \\(&gt;\\) Realistic \\(&gt;\\) No(ne) \\(&gt;\\) Null. While the difference between Realistic and None was not significant by the standard tests, the confidence interval does not rule out an affect of up to almost 15 percentage points. 7.4.2 Evidence: Analytical information \\(\\times\\) emotional information and ‘identifiable victim’ (Kogut and Ritov 2011; Loewenstein and Small 2007a; Small, Loewenstein, and Slovic 2007) (Drouvelis and Grosskopf 2016), (Caviola et al. 2014) (Small, Loewenstein, and Slovic 2007), studies 3-4 Study 3: individuals who faced an identifiable victim donated more than those who faced victim statistics, p &lt; .01, and also donated more than those who faced an identifiable victim in conjunction with statistics, p &lt; .05. (They interpret the statistics as possibly ‘debiasing’ the IVE) Study 4: “Priming analytic thinking [math problems] reduced donations to an identifiable victim relative to a feeling-based thinking prime [\"impression questionnaire\"]. Yet, the primes had no distinct effect on donations to statistical victims, which is symptomatic of the difficulty in generating feelings for these victims.” Considerations Basic design has key strengths: Double-blind, real donations, distractors, careful use of language. Primes: Note, the latter non-effect appears tightly bounded; but this could simply be driven by nonlinearity. If people gave little to statistical victims, there is less room for this to decrease further. A classic problem when considering interactions. Ideas42 Summary: Researchers gave study participants the opportunity to donate $0-5 to famine relief efforts at Save the Children (n = 159). One group received letters that included a picture and brief description of a little girl. A second group received letters describing factual information about food security, and a third group received letters with both the little girl’s profile and factual information. The photo and description prompted an emotion-based response, raising more than twice as much money as the factual solicitation. Including factual information with the girl’s profile reduced this effect, with no significant difference in giving between those who received both pieces and those who received factual information only Bergh and Reinstein, 2020, SPSS 7.5 Overall ‘net’ responses to charity ratings There is a small body of evidence on how charity quality ratings (which are not typically ‘impact’ ratings as we have defined it) affect, or at least correlate with a charity’s fundraising success. The effect of these ratings presumably relates both to individual’s willingness to seek out and process this information (as in our discussion of CBA), and to the impact of this information on an individual’s generosity (as in our discussion of . If individual’s strongly avoided seeing this information and ignored being exposed to this information 7.5.1 Evidence on responses to charity ratings One characterization, from Bergh and Reinstein (2020) Some work further suggests that changes in charity ratings lead to changes in charity revenues (e.g., Gordon, Knock, and Neely (2009); Yörük (2016)), but it is unclear if this is driven by efficiency evaluations per se. For instance, people might respond to the number of stars given to a charity without deeply considering what these stars represent. Yörük (2016). “Charity ratings” Journal of Economics &amp; Management Strategy, 25(1), 195-219. Relevance: Reasonably strong causal evidence that in general, charity ratings may boost a charity’s fundraising, at least for some types of charities. However, this is based on Charity Navigator ratings, which do not generally agree with our measures of impact. Type of evidence: Observational, claiming causality through a regression discontinuity framework Charity Navigator stars are based on a continuous score across categories Identification via RD: Impact of crossing a ‘star’ threshold on amounts raised Background mechanisms and related evidence: the role of consumer reviews and independent ratings in for-profit sectors, e.g. Luca(2011): one star increase in online rating leads to a 5 to 9 percent increase in revenue, Jin and Sorensen (2006): health plan ratings have a significant impact on individuals’ health plan choices, Reinstein and Snyder (2005): positive expert reviews have a significant effect on the box office revenue of movies. Key findings: For relatively smaller and unknown charities one star increase in ratings is (causally) associated with a 19.5 percent increase in the amount of charitable contributions received See also Vesterlund (2003) Chhaochharia, Ghosh, and others (2008), Landry et al. (2010), Brown, Meer, and Williams (2016) Gordon, Knock, and Neely (2009) 7.5.1.1 Notes There is also evidence that people may dramatically underestimate the cost of saving lives. DR: I am considering whether this should be seen as a relevant barrier. It is important to note in trying to measure the impact of effectiveness information. Evidence comes from Caviola et al 2019 and Greenberg et al 2017 List of references "],
["quant-biases.html", "8 Barriers: Quantitative biases 8.1 Biases in perceiving impact 8.2 Other biases driving departures from efficiency 8.3 Proportional dominance effect 8.4 Statistical/identifiable victim effect 8.5 Availability heuristic 8.6 Diversification heuristic 8.7 Overhead aversion 8.8 Possible: Misunderstanding need (and misunderstanding marginality/tractability/sunk costs?) 8.9 Scope insensitivity/embedding effect/part-whole effect 8.10 Other quantitative biases 8.11 Other possibilities: “Risk aversion”, Lack of tangibility, Corruption aversion", " 8 Barriers: Quantitative biases Recapping the discussion from the Conceptual breakdown of ‘barriers’. Even if people want to be effective givers, they may simply be bad at this, because they have quantitative limitations and biases. Anything that causes me to misunderstand effectiveness, to misapprehend the nature of the “production function for good outcomes”, or to misjudge charities will lead me astray from effective giving. Furthermore, some biases may happen to be particularly harmful to those charities and causes that are most effective. 8.1 Biases in perceiving impact Cognitive biases: Overweighting and underweighting probabilities, misunderstanding marginality, scope-insensitivity, Opportunity-cost Neglect. etc. Identifiable victims effect. Some key references: Small, Loewenstein, and Slovic (2007), Gneezy, Keenan, and Gneezy (2014), Kogut and Ritov (2005a), Kogut and Ritov (2005b), Kinsbergen and Tolsma (2013), Kinsbergen and Tolsma (2013), Summers et al. (1994), Press (2018) 8.2 Other biases driving departures from efficiency 8.3 Proportional dominance effect AKA ‘drop in the bucket’, ‘psychosocial numbing’, ‘psychophysical numbing’ Proportional dominance effect/drop in bucket/psychosocial numbing/psychophysical numbing 8.3.1 Definition Related Terms include: Drop in the bucket; mechanisms include “futility thinking” (Unger?), psychosocial numbing, quantitative confusion/innumeracy This claim can be summarized as follows: (For a given per-dollar impact on the outcome), people are be less willing to donate towards a cause when the magnitude of the underlying problem is (framed as) larger. Mechanism: Underlying this is the idea that a certain amount of impact (e.g., relieving suffering) is perceived as smaller and thus less valuable when the underlying problem is larger. 8.3.2 Conceptual Discussion Overview of findings from papers, caveats, how the concept works, etc. Provides context for evidence section; Discussion of the relevant mechanisms at play; Discussion of the relevant established theories. Definitional issues and disambiguation This needs to be distinguished from scope insensitivity. Note that if people are being analytical, they must care about scope in order to care about their impact, and thus (mistakenly) react to the perceived lower impact of donating when the needs are much greater. PD arguments may also be used as vehicle for motivated reasoning, and thus not be an important driver in itself: E.g., I don’t want to donate so I focus on my impact being a share of the overwhelming need (which I might opportunistically define broadly) to conclude that helping is futile. Note (unfold)… BG: My thought was that people who do not value saving lives (or are in general unwilling to contribute to it or oppose policies spending money on foreign aid for some other reason, e.g. prejudice) exercise a form of motivated reasoning to justify this (perhaps in a nonstandard way). They choose to reason according to the ‘proportional’ standard in order to conclude that it is not worth mdonating to these causes because ‘the scope of the problem is too large and they will never be completely solved’. I suggest that people apply this reasoning to problems specifically when they do not want to take action to address these problems. (In contrast, in domains where they do want to make a change, they may use a different, more marginal and 'consistent' sort of reasoning.) E.g., (to be stereotypical) imagine a MAGA person who wants to end foreign aid because \"Africa will always have endless problems\" but who wants to impose restrictions on abortion (even knowing millions of abortions will continue to occur) because \"every unborn life matters. To operationalize this, we need to define what the numerator and denominator represent. For the numerator, an (EA) impact-driven individualist donor might consider of her own contribution (per dollar or overall) relative to the size of the need. In contrast, a more collectivist/team-reasoning/communitarian thinker might consider the impact of the total expected donation relative to the size of the need. We also need to better define the denominator; how do individuals lump together different groups/problems to define the overall scale of the need, and how sensitive is this to the fundraisers’ framing? Mechanisms Fetherstonhaugh et al. (1997) highlight “Weber’s law”: Humans are sensitive to proportional changes/proportional differences in stimuli (loudness, brightness, etc); thus we are less sensitive to small changes relative to a larger baseline. There is evidence this also holds in assessing losses of life. ... the “subjective value of saving the specified number of lives is greater for a smaller tragedy than for a larger one” . Baron (1997) attributes PD to quantity confusion and classifies this as “contamination by an irrelevant factor”; more generally, this could be seen in terms of innumeracy. This may lead to a lower willingness to contribute to a problem when the apparent scale (or “denominator”) of the problem is larger (e.g., more lives at risk), holding constant the benefit per dollar contributed (cost per life saved). The perceived scale of the problem may depend on how it is framed by fundraisers, charities, and the media. However, this may not be completely manipulable: e.g., massive global problems may not be easy to “frame down.” “Loewenstein and Small (2007a) suggested that the PDE is driven by increased sympathy towards the victims when one can help a large proportion of the victim reference-group.” -- Erlandsson et al. (n.d.) 8.3.3 EG Relevance How this particular barrier proves problematic for effective giving. This effect represents a general departure from appropriate assessment of the marginal benefit (per cost) of a particular charity/intervention. Thus, this is a general barrier to accurate assessment of effectiveness ergo a barrier to effective giving. In addition, it might be argued that more effective interventions (e.g., targeting poor Africans versus US poverty) may tend to address problems that are inherently larger in scale and magnitude. These may be intrinsically harder to “frame down”, implying EG will suffer more from this bias. 8.3.4 State of Evidence Key papers: Summarize findings and key takeaways, Short description of methods for relevant studies, Make sure to include both description of evidence and evaluation of evidence Fetherstonhaugh et al. (1997) (notes HERE) Methods Range of hypothetical scenariae and evaluations, within-subject manipulations only (with clear contrasts), framed as aid/targeting not charitable donations, standard (mostly Economics) student subject pools. These authors conducted survey experiments on standard (fairly small sample?) student participants. They presented a variety of hypothetical scenariae (e.g., “imagine themselves as a government official of a small, developing country”...), asking for ratings, rankings, etc. Findings Studies 1 and 2 found that an intervention saving a fixed number of lives was judged significantly more beneficial when fewer lives were at risk overall. Study 3 found that respondents wanted the minimum number of lives a medical treatment would have to save to merit a fixed amount of funding to be much greater for a disease with a larger number of potential victims than for a disease with a smaller number. Evaluation of paper’s evidence: Strengths: Reasonably realistic frames, (mostly) consistent results across a variety of frames Limitations: Hypothetical, framed, nonrepresentative, and does not directly address own contributions Within-subject treatments here: Benefit: allow estimation of heterogeneous responses, Mixed pro and con: highlight the difference in denominators/proportions, making them salient; but this might also be expected to be an inhibitor of this (seemingly non-rational) effect, especially for the Economics-trained sample Statistical tests (ANOVA) appear strong and highly significant in most cases, but further investigation warranted (e.g., pre-registration? Evidence of specification fishing and MHT?) Erlandsson, Björklund, and Bäckström (2015) (Study 4) The PDE-ad was in part based on text from the homepage of a well-known global charity organization focusing on poverty in developing countries. Participants read about Polio and were told that if receiving the expected amount of private donations, it would be possible to vaccinate children so the death rate would decrease by approximately 500 children per year. In the large reference-group version, participants read that 60,000 children in Africa annually die from Polio so the project had a potential rescue proportion of 0.83%. In the small reference-group version, partici pants read that around 500 children in Botswana annually die from Polio so the project had a potential rescue proportion of more than 99%. ...followed by eight questions about participants’ reactions towards the advertisement. The suggested mediators (distress, sympathy, perceived impact and perceived responsibility) were measured with two questions each ...after reading and responding to the three ads, participants were told that thanks to their participation, 10 Swedish Kronor (SEK) (1.50 USD) would be donated to charity. The participants were asked to allocate the money between the three organizations by writing an amount (0–10) after each ad and the sum had to be 10 SEK ...All participants read either one ad from the low end of the effects (statistical victim, large reference-group, out-group victims) plus two ads from the high end of the effects (identified victim, small reference-group, in-group victims) or two ads from the low end plus one ad from the high end. [Results] Participants who read the PDE-ad in the small reference-group version had higher helping intentions (M = 3.77, SD = 1.64) than participants who read the large reference-group version, M = 3.46, SD = 1.57; t(430) = 2.01, p = .045. However, participants who read the small reference-group version did not write that they would donate more money if asked (Mean rank = 213.68) than participants who read the large reference-group version (Mean rank = 218.31; Mann–Whitney U = 22720.50, Z = 0.40, p = .686). Despite this, participants who read the small reference-group version allocated more money to the organization distributing Polio- vaccines (M = 4.30 SEK, SD = 2.85) than the participants who read the large reference-group version, M = 3.50 SEK, SD = 2.87; t(430) = 2.91, p = .004. Although not perfectly consistent between the different outcome variables, the results suggest that we replicated the PDE. Evaluation of evidence (Study 4): Strengths - Realistic charity frame, reasonable implementation of small/large “reference group” frames, outcomes record both intentional/attitudinal and actual (small) donation measures Limitations - A choice among charities only Statistical tests - Brief on tangential papers (non charity) and papers supporting the mechanism Baron (1997): “Confusion of Relative and Absolute Risk in Valuation” Methods Hypothetical willingness to pay (wtp) questions. Within-subject manipulations only; standard student subject pools, small samples. They do reverse order of presentations for half the participants. They report a lack of significant order effects, but fail to discuss the power of such tests or examine first-presented choices in isolation. S1: Questions about (hypothetical wtp for components of government government health insurance. “[Denominator] people die from this disease each year. Their average age is 60. How much are you willing to pay to cover a treatment that will save the lives of [Numerator] of these people?”… (Numerator=90 or 900; Denominator=100, 1000, or 10,000), all combinations presented to all participants. S2: Set of causes, each gave wtp for a government program for a 5% reduction in that cause of death and for saving 2,600 lives, also rating prevalence and importance. He reports a very high correlation between wtp by these two measures, an “insensitivity to quantity”, and both wtp measures are higher when subjects report a higher prevalence (even controlling for stated importance). Evaluation of paper’s evidence: This evidence appears highly limited. There is some evidence that denominators matter when they (arguably) should not, and participants show confusion between proportions and absolute amounts. The second experiment is highly cognitively demanding and participants have no strong incentive to “get this right.” The first experiment has arguable confounds: e.g., one might question the scientific credibility of the treatment that (claims to) save only a small number of lives out of a very large population. The evidence does not seem to offer much strength over and above the Fetherstonhaugh paper. I also found much of the statistical reporting to be incomplete or unclear, especially for study two. In general, this is, at its best, evidence of quantitative confusion which may go in either direction in any given context. It is also detached from the charity realm, considering the domain of government expenditure and benefits that will accrue to the participant him or herself. For this reason, I listed it is tangential evidence and not charity specific evidence. Jenni and Loewenstein (1997) Provides support for the “reference group effect” (proportional dominance) as an explanation for the identifiable victims bias. (notes HERE) Friedrich et al. (1999) PN was investigated by varying the supposed number of brak- ing-related traffic fatalities each year as a within-subjects variable and then obtain- ingjudgments of support for a new antilock brake requirement. Experiment 1 manipulated respondents’ accountability [“…the experimenter will ask you at this time to explain the reasoning behind your decisions and to justify how you arrived at your recommendations”] as a way of exploring whether PN responding is the result of careless or heuristic processing. Extensive work with accountability manipulations has shown them to be effective in debiasing… [other stuff]. … when they expect to have to justify their reason- ing to others, should also be revealing in terms of what they believe constitutes a defensible, normative strategy. [also] a manipulation designed to highlight the salience of the individual lives at risk … [a] description of a preventable, fatal accident with named individuals… , par- ticipants read that the “Federal Transportation Board” estimated annual fatalities due to driver error in the use of conventional braking systems to be approximately 41,000 (“large problem”) or 9,000 (“small problem”). Outcome measures: “support-for-intervention”, 7-point scale “Lives-to-save” “What is the minimum number of these (9,000/41,000) lives at risk … saved each year before you… require consumers &gt; to pay for anti-lock brakes” Treatments started with one size, then presented a “task force’s new estimate” with the reverse. Overall evaluation of evidence Evidence gap and suggestions for future work and approaches 8.3.5 Potential Solutions Framing Frame down denominator (suggestive evidence from Fetherstonhaugh, etc) Report absolute or proportional number of lives that could be saved by an intervention depending on which suggests a smaller denominator (how do you know?) Highlight numerator (impact) (evidence?) (Ari:) “Increase evaluability: putting interventions on same page instead of separate pages” De-biasing (discussed further in Friedrich et al. (1999) - expand) Consider: “The proportion dominance effect was primarily mediated by perceived impact.” (Erlandsson, Björklund, and Bäckström (2015), OBHDP) “Perceived Utility (not Sympathy) Mediates the Proportion Dominance Effect in Helping Decisions” (Erlandsson, Björklund, and Bäckström 2014) 8.4 Statistical/identifiable victim effect Cite: Hsee13, small2003helping, kogut2011identifiable, small2007sympathy_s3_s4 8.4.1 Definition The identifiable victim effect (IVE) is credited as being first developed by Schelling (1968), who argue “there is a distinction between an individual and a statistical life”. People may react differently towards victims when these victims are identified rather than anonymous (Small and Loewenstein 2003). As a result, resources may be more likely to be devoted to causes where individual victims are more prominent and identifiable (rather than cases where we only see large, unidentified groups) (Small 2010). Slovic (2007) also discussed this effect, in a paper that derives its title from a Mother Teresa quote that reflects the key idea: “If I look at the mass I will never act. If I look at the one I will”. 8.4.2 Relevance to effective giving Baron and Szymanska (2011) discuss how the IVE could pose a problem for effective altruism, suggesting two reasons that this could be considered a bias from the utilitarian perspective. Firstly, they suggest that when altruism is increased for identified victims, this could result in less altruism for those who are not identified,\\(^{(?)}\\) Why? Through which channel. The latter group may include those most in need of help (such as large groups of people who are severely deprived). Kogut and Ritov (2011) similarly argued that the IVE could yield less efficiency given that it is improbable that the benefits to society will be maximized when more resources are given to victims who are identified than those who aren’t. (This essentially restates our general efficiency argument above, in section 8). Baron and Szymanska (2011) offer a counter-argument: Perhaps, though, the emotion changes the benefit/cost threshold for altruism, meaning that people are willing to incur a greater personal cost of helping, even when the amount of benefit to others does not change. This shift in the benefit/cost threshold might possibly even increase overall altruism. This could be interpreted as ‘Those internal factors that cause a bias towards identified victims also lead to greater regard for others and thus more giving (’donation bundle Y’), even if it is less efficient. In net this could potential yield a greater good.’ OR “Presenting and depicting identified victims leads to … potential yielding a greater good” In either case, we can still see the IVE as leading to inefficient giving. From the point of view of the individual before he/she has been ‘triggered by identifiability’, ‘donation bundle Y’ is excessive as well as inefficient (the same benefit could be achieved at less expense or more good at the same expense). Ex-post, after she has been ‘triggered’ to be more generous, we can still see that more social good could have been done given her expenditure. Baron and Szymanska (2011) also argue that the IVE could be viewed as a framing effect: the choices the donors make are influenced by how the information is presented, holding reality constant. This is about presentation: all victims could be identified, with names, ethnicities and ages. This leads Baron and Szymanska (2011) to suggest that “the identifiability effect may fail a simpler test of rationality”.^\\(^{(??)}\\) What test?^ 8.4.3 Evidence One of the potential reasons that identified victims could elicit greater generosity is that their stories can involve more sympathy-inducing information (see Jenni and Loewenstein (1997) and Loewenstein and Small (2007a) for more on the causes of the identifiable victim effect and more on sympathy biases). However, while sympathy-inducing information can contribute to the impact of the identifiable victim effect, some evidence suggests that it is not the sole factor driving this. Small and Loewenstein (2003) designed studies to separate the effect of the identification of a victim from the effect of information being provided about a victim. They outlined this distinction as follows: Although it has been claimed that people care about identifiable more than statistical victims, demonstrating this “identifiable victim effect” has proven difficult because identification usually provides information about a victim, and people may respond to the information rather than to identification per se. We show that a very weak form of identifiability - determining the victim without providing any personalizing information - increases caring. In one of their studies, they used a version of the dictator game. In dictator games, the first player, known as the ‘allocator’ is given an endowment. They then make a unilateral decision on how they should split this endowment. The second player, known as the ‘recipient’, has to accept this split. For more on dictator games see Kahneman, Knetsch, and Thaler (1986) and Camerer and Thaler (1995). There were two conditions in the slightly altered dictator game devised by Small and Loewenstein (2003). In the ‘determined’ condition, allocators were given a number to link them with the recipient before they made their decision, while in the ‘undetermined’ condition they were linked after the decision. Their hypothesis, that an allocator would give more money to recipients in the determined condition, was supported. Subjects gave significantly more to those victims who had been determined before the allocation. The mean donation for an undetermined victim was USD 2.12, compared to USD 3.42 for determined victims. The second study from Small and Loewenstein (2003) was a field experiment with the following methodology: … potential donors were presented with a letter requesting money to buy materials for a house that was to be built for a needy family through the Habit for Humanity organization. The letter described several families on the waiting list to move into homes. Identifiability was manipulated by informing respondents that the family either “has been selected” or “will be selected” from the list. In neither condition were respondents told which family had been or would be selected; the only difference between conditions was in whether the decision had already been made As in their first study, they found evidence supporting their hypothesis that contributions would be larger when the recipients had already been determined. Mean, median and mode donations were all larger in the determined condition, with a mean of USD 2.93 given in the determined family condition, and a mean of USD 2.33 given in the undetermined family condition. This study could arguably provide stronger support for the identifiable victim effect impacting altruism, as Small and Loewenstein (2003) suggest: By moving out of the laboratory, we eliminated potential artifacts such as the concern that students might have felt of being “found out” by their peers or other non-empathatic motives. By collecting money for a real charity to help people truly in need, we illustrate the real world implications of this effect. Both of these studies from Small and Loewenstein (2003) suggest that identifying a victim, even without providing additional information, can potentially increase giving. Results from Charness and Gneezy (2008) similarly offer support for the identifiable victim effect from dictator games. In their dictator game, they found that when the family name of the recipient was revealed, the allocator gave a significantly larger portion of their endowment. Allocators who were told the family name gave 50 percent more than those who weren’t. Kogut and Ritov (2005a) also studied the IVE with the following design for participants: They were randomly assigned to one of eight conditions. Two factors were varied between subjects in a 2 x 4 factorial design: the singularity of the victim (single vs. a group of eight individuals) and the identifying information (unidentified; age only; age &amp; name; age, name, &amp; picture) Participants were given the same story, describing either a sick child, or a group of eight sick children. They were then asked if they would donate, and if so, how much they would donate. Their first finding was that “the effect of identification may be largely restricted to single victims”, as the impact of being identified was significantly less for the group of eight children than for the single child. Secondly, they found that “the identification of the single victim is more effective the more vivid the representation”, with willingness to donate at its highest when the victims were identified by age, name, and picture. I’d like to check the robustness of this ‘interaction’ effect; such effects can be confounded with non-linearity. See discussion here, section 1.3.7 Sudhir, Roy, and Cherian (2016) also found support for the IVE. In their study, they randomized advertising content in a large-scale experiment with charitable mailings across India. In the individual condition, they described an individual along with her photograph, and in the group condition they described the victims as a group of four women and used a photo collage. They found that in the individual condition, the average donation rate was 0.24% compared to 0.09% for the group condition. They also found that as well as the identifiable victim effect contributing to more donors giving, it also increased the level of giving among those that did give. Linked to the identifiable victim effect is the notion that people are sensitive to the proportion of lives saved, rather than absolute lives (as discussed in more detail above) (Baron 1997; Fetherstonhaugh et al. 1997; Small, Loewenstein, and Slovic 2007). Loewenstein and Small (2007a) suggest that if the proportion of lives saved is higher, then the lives could be more identifiable, resulting in more sympathy. They clain that, for example, “Ten lives out of a group of 100 is a high proportion and thus more sympathy inducing than 10 lives out of 1,000,000”. Loewenstein and Small (2007a) also argue that the IVE represents one extreme on a continuum. If a single victim is identified, this victim becomes part of one’s own reference group; thus one might experience higher levels of sympathy. At the opposite end of the continuum we find the ‘drop-in-the-bucket’ effect, where “there are so many victims in the reference group that the individual victims are hidden among the masses”. 8.5 Availability heuristic 8.5.1 Definition and relevance The availability heuristic suggests that people judge the frequency of classes, or the probability of events, by the ease with which they come to mind (Tversky and Kahneman 1973). I.e., people may treat an event a as more likely than an event b, if a comes to mind more easily than b (Angner 2012). As a result of people using the availability heuristic, they may underestimate the prevalence of–and place less value on–problems such as extreme poverty. These problems may be less salient than issues people in developed countries regularly encounter. For example, many of us have personal experiences with cancer. As well as potentially inducing more sympathy (see here for more on sympathy biases), this could lead us to that people place disproportionately high value on curing cancer relative to, e.g., preventing malaria. Tversky and Kahneman (1973) discussed how personal experience can influence judgments of probability in their original paper on the availability heuristic: Perhaps the most obvious demonstration of availability in real life is the impact of the fortuitous availability of incidents of scenarios. Many readers must have experienced the temporary rise in the subjective probability of an accident after seeing a car overturned by the side of the road… Continued preoccupation with an outcome may increase its availability, and hence its perceived likelihood. Kahneman (2011) also looks at studies from Slovic, Fischhoff, and Lichtenstein (1981b), Slovic, Fischhoff, and Lichtenstein (1981a), and Lichtenstein et al. (1978), summarising: Strokes cause almost twice as many deaths as all accidents combined, but 80% of respondents judged accidental deaths to be more likely Tornadoes were seen as more frequent killers than asthma, although the latter cause 20 times more deaths Death by disease is 18 times more likely as accidental death, but the two were judged about equally likely Kahneman (2011) concludes: The lesson is clear: estimates of death are warped by media coverage. The coverage itself is biased toward novelty and poignancy. The media do not just shape what the public is interested in, but are also shaped by it The availability heuristic could translate to more effective charities being neglected. For example, in the UK, cancer is a very prominent charitable cause, and Cancer Research UK is one of the UK’s most popular charities. This is in spite of the fact, per-dollar, Cancer Research is appears significantly less effective than several anti-malaria charities Macaskill (2015). E.g., the Against Malaria Foundation is ranked highly by GiveWell, but receives relatively little attention, and is not among the most popular charities in the UK. Macaskill (2015) has also discussed how we should compare malaria and cancer as issues (unfold): Macaskill: Every year cancer kills 8.2 million people and is responsible for 7.6 percent of all deaths and ill health worldwide (measured in terms of QALYs lost). USD 217 billion per year is spent on cancer treatment. Malaria is responsible for 3.3 percent of QALYs lost worldwide. In terms of its health impacts, cancer is about twice as bad as malaria, so if medical spending were in proportion to the scale of the problem, we would expect malaria treatment to receive about USD 100 billion per year. In reality only USD 1.6 billion per year is spent on malaria treatment: about sixty times less than we would expect. Cancer treatment receives so much more funding than malaria treatment because malaria is such a cheap problem to solve that rich countries no longer suffer from it. (It was eliminated in the US in 1951.) The fact that cancer treatment receives so much more funding than malaria treatment means that, on the margin, each of us can provide a far greater benefit for other people by funding the most effective malaria treatments in the developing world than we can by funding the most effective cancer treatments in the developed world. Most people in developed countries like the US and the UK will have an experience with cancer over their lifetime, either personally or through a loved one. It is estimated that roughly 38% of men and women will be diagnosed with cancer at some point over their lifetime. In contrast, while malaria it receives some international coverage, was eliminated in the US in the 1950s. If cancer is more visible, it could be more salient,leading people to overestimate its importance through their use of the availability heuristic. Note that none of the ‘barriers’ we mention are mutually exclusive. There may be many other factors driving the popularity of cancer research charities. 8.5.2 Connection to other biases This ‘availability’ bias is distinct from the idea that are more likely to donate to cancer research out of self-interest (i.e. thinking that it may help them personally); the latter is discussed in section 5.1. Availability has some links to other biases we consider. Salience contributes to probability estimations, and events that come to mind more easily can be judged as more likely. Thus, this could be a mechanism behind other biases, such as the identifiable victim effect and the lack of attention given to distant future causes. Angner (2012) discusses the link between the availability heuristic and vivid stories (with vividness discussed as a potential contributor to both the IVE and distant future issues): The availability heuristic sheds light on the power of storytelling. As every writer knows, stories are often far more compelling than scientific data. If you doubt that, just ask a wolf. Wolves pose a trivial danger to humans: the number of verifiable, fatal attacks by wolves on humans is exceedingly low. And yet, fear of wolves runs deep. Part of the explanation is certainly that there are so many stories about big, bad wolves eating, e.g., little girls’ grandmothers. As a result of these stories, the idea of wolves attacking humans is highly salient, which means that people treat it as likely – even though the data establish it is not. Far more dangerous organisms, such as the Salmonella bacterium that kills some 400 people each year in the US alone, do not figure in the public imagination in the same way and consequently are not as feared as they probably should be. The power of storytelling can be harnessed to communicate risk communication very effectively, but it can also do immense harm. A single story about an illegal immigrant committing a heinous crime can generate strong anti-immigration sentiments in spite of evidence of the beneficial welfare effects of immigration. 8.5.3 Evidence (to do) 8.6 Diversification heuristic Baron and Szymanska (2011) suggest that, in many contexts, diversification can often be beneficial. For example, when it comes to experiences, diversification can mean variety, helping to reduce the likelihood of adaption and things being repeated. This comes from the idea of diminishing marginal utility, and Read and Loewenstein (1995) explain the classical model of variety seeking as follows: According to the classical model, variety seeking arises from object-specific satiation or the diminishing rate of marginal return to consumption [of an individual good]. According to this view, the optimal bundle of goods contains variety because the benefit from an additional unit of a specific good (i.e., its marginal return) decreases as a function of the number of units of that good one already possesses. David Reinstein: The classical economics model does not assert a diminishing rate of marginal return to consumption as a general universal property. It is recognized that this may not hold over all goods for all quantities and all individuals. However, this (as well as the more rigorous concepts of ‘convex’ preferences or ‘quasi-concave’ upper-contour sets) are Convenient for the maths/proofs, allowing continuous responses to prices, etc. Intuitively (and perhaps empirically) justified in many contexts. A reasonable way of explaining why individuals do not ‘spend their money on a single good’. Diversification can particularly have value in investing, where it can reduce the exposure to risk (variance) for a given expected return (or increase the expected return for a given expected variance of the return. (See ‘diversification’, ‘asset pricing’ and the CAPM model, in standard textbooks.) However, people may continue to diversify even in domains where this no longer makes sense, as they use diversification heuristics. The causes of diversification heuristics more broadly are discussed in detail by Read and Loewenstein (1995). A study by Benartzi and Thaler (2007) is also useful for examining the evidence of diversification heuristics more widely, particularly for establishing what they refer to as the “\\(1/n\\) rule”. The \\(1/n\\) rule was inspired by the tendency for people to sometimes split allocations evenly across their options: Nobel laureate Harry Markowitz, one of the founders of modern portfolio theory, confessed: “I should have computed the historic covariances of the asset classes and drawn an efficient frontier. Instead, . . . I split my contributions fifty–fifty between bonds and equities” (Zweig 1998). Markowitz was not alone. During the period when TIAA-CREF had only two options—TIAA invests in fixed income securities and CREF invests in equities—more than half the participants had selected a fifty–fifty split. Markowitz’s strategy can be viewed as naive diversification: when faced with “n” options, divide assets evenly across the options. We have dubbed this heuristic the “1/n rule.” The study from Benartzi and Thaler (2007) was focused on heuristics and biases in retirement savings, Implications and causes of diversification heuristics in charitable giving For the rest of this section, we will focus on the implications and causes of diversification heuristics as they relates to charitable giving specifically, but the above studies are valuable for further examining the underlying causes behind diversification heuristics in general. One study that offers some evidence for people diversifying when this is no longer effective comes from a study examining how people chose to distribute screening tests for colon cancer, by Ubel et al. (1996), who used the following method: We asked prospective jurors, medical ethicists, and experts in medical decision making to choose between two screening tests for a population at low risk for colon cancer. One test was more cost effective than the other but because of budget constraints was too expensive to be given to everyone in the population. With the use of the more effective test for only half the population, 1100 lives could be saved at the same cost as that of saving 1000 lives with the use of the less effective test for the entire population. They found that 56 percent of the prospective jurors, 53 percent of the medical ethicists, and 41 percent of the experts chose the less effective test. The authors report that most defended this choice on the basis of valuing equity, leading Ubel et al. (1996) to conclude that “People place greater emphasis on equity than is reflected by cost-effectiveness analysis”. While this study is not on charitable giving directly, it may have implications in understanding how people may view trade-offs in equity and efficiency, particularly where real human lives are at stake. Fox, Ratner, and Lieb (2005) also expanded on a problem linked to diversification, which they refer to as partition dependence. This builds on the finding that people can often split allocations evenly across options (Benartzi and Thaler 2007). They discuss the distinction between the two ideas: If a decision maker subjectively partitions the option set in different ways on different occasions, then choices and allocations will vary systematically with these partitions. We refer to this phenomenon as partition dependence. To illustrate, suppose that a philanthropist intent on donating to an array of children’s charities is presented with a set of organizations that are grouped by whether they are domestic or international. She may decide to diversify fully across these two categories by allocating half of her donation to domestic charities and half to international charities. However, suppose instead that she is presented with the same set of organizations, grouped into local charities, national charities, and international charities. In this case, the philanthropist may allocate two thirds to domestic charities (one third to local, one third to national) and one third to international charities. Note that partition dependence differs from diversification heuristics such as the “1/n rule,” documented by Benartzi and Thaler (2007), in which people spread their retirement savings evenly across the n investment instruments that were offered (e.g., stock fund, bond fund.) The 1/n rule refers to the tendency to spread savings evenly among investment options with little regard to the particular investments that are offered; partition dependence refers to the tendency to make different allocations among the same set of options as a function of the way those options are subjectively grouped. In one of their studies to examine partition dependence, Fox, Ratner, and Lieb (2005) recruited participants and told them that the researchers would donate $2 on behalf of each participant to United Way charities (a charity which includes funds that benefit both international projects and local communities). The participants could choose how to allocate the funds, and were told the following: In particular, you can allocate the United Way donation into international funds (which the United Way would then allocate to more specific funds abroad) and/or Durham County funds (including programs benefiting seniors, programs nurturing our young children, programs promoting health and wellness, and programs strengthening our families). The study had two conditions in order to examine the potential impacts of partition dependence, non-hierarchical and hierarchical: Participants in the nonhierarchical partition condition (n = 15) were then asked to indicate their proposed allocation to international funds and each of four Durham County funds, with the order identical to that listed in the preceding paragraph. Respondents were asked to indicate percentages and were reminded to make sure that their allocation summed to 100%. Participants in the hierarchical partition condition (n = 16) were told, “Below we will ask you to first allocate geographically, then to more specific funds.” Next they were asked to indicate how much of the money they would donate to (superordinate categories of) international funds versus Durham County funds and were reminded to make sure that their allocation summed to 100%. Finally, these participants were asked to indicate how they would allocate their Durham County donation among each of the four possibilities. Their results suggested that there was evidence for partition dependence in participants: The mean donation to the international fund was 55% in the hierarchical condition (n = 16) but only 21% in the nonhierarchical condition (n = 15), t(29) = 3.73, p = .0004, one-tailed. In fact, median donations were 50% in the hierarchical condition and 20% in the nonhierarchical condition—the precise proportions one would expect if participants applied pure partition-dependent diversification without adjustment. If people do use diversification heuristics in charitable domains, as these studies from Ubel et al. (1996) and Fox, Ratner, and Lieb (2005) suggest, this could have significant implications for the extent to which people give effectively. While diversifying could have some value, and may make some sense if people are uncertain about the outcomes of their giving, Baron and Szymanska (2011) outline ‘why the usual arguments for diversification are less likely to apply for charitable giving’: The marginal benefit per dollar (recall the difference between the average vs. marginal benefit) of some support is usually much higher than the marginal benefit of support in addition to some other previous support. In the context of charitable donations, however, a single donor does not have much influence over the total level of the charity’s income (unless the donor is a major philanthropist). Thus, the usual arguments that favour diversification in investments do not necessarily apply to donations by typical donors. For charities, the focus should be on maximizing the expected increase in the economic welfare per dollar of every contribution… In reality, however, more often than not, each contributor has only a tiny effect on the total funding required by a charitable organization, so the argument based on the principle of declining marginal utility is unlikely to apply. We should, therefore, identify a charity with the highest expected benefit per dollar, and make our entire contribution to that one charity. In other words, a donor may err by thinking and acting as if she were the only donor to the charities that she supports. If she were, then it would make sense to diversify because of the principle of declining marginal utility just described. In reality, however, more often than not, each contributor has only a tiny effect on the total funding required by a charitable organization, so the argument based on the principle of declining marginal utility is unlikely to apply. We should, therefore, identify a charity with the highest expected benefit per dollar, and make our entire contribution to that one charity. DR: There are some perspectives under which a certain amount diversification in charitable giving, motivated by a form of risk-aversion, may be optimising, at least for an individual with particular other-regarding preferences. For example, suppose: … an individual donor values the impact that she actually has in terms of realized outcomes (rather than valuing her ‘expected value impact’), and … she gains diminishing returns to this impact (making her, in a sense ‘risk-averse’) This would imply that, if she is maximising her expected utility (a standard assumption in Economics): she would strictly prefer to have (e.g.) a 100% chance of saving one life over a 50% chance of saving two lives, and she would strictly prefer to have a 10% chance of saving one life over a 5% chance of saving two lives, and she might strictly prefer to have a 10% chance of saving 100 lives over a 5% chance of saving 201 lives. Consider the probabilities that each dollar donated to a charity (leads to an intervention that) saves a life (or achieves a particular outcome). Suppose these outcomes (the lives saved) are not perfectly correlated across charities. In such a case, this an individual would find it optimal to diversify her giving across equally-impactful charities, and potentially even to include some ‘slightly less impactful’ charities in her ‘giving bundle.’ Evidence for diversification heuristic in charitable giving (to do) 8.7 Overhead aversion Related Terms Similar terms: Overhead bias Possible mechanisms: waste aversion, perfectionism; evaluability bias (for this versus other metrics); excuse-driven/motivated reasoning Distinct but related: corruption aversion Description Potential donors may have a negative feeling towards a charity’s costs that are considered “overhead” rather than “direct spending on program activities.” This may make them reluctant to donate to charities that express a high “overhead ratio” and/or when they believe their donation will go to “pay for overhead”, and to favor instead charities that report low “overhead ratios”. Discussion: There are some clear flaws in this logic (thus we may call it “overhead bias”): many things considered overhead are fixed or sunk costs which will not be changed by the amounts donated; thus, at the margin the donation may not actually go towards this overhead. Marginal overhead is also possible. Suppose, e.g., the cost of an additional year of school tuition fees for a child are £200, but this requires an additional administrative cost of £50 to vet the student and her family, pay money transfer fees, fill out additional forms, etc. A donation of £200 earmarked for “tuition only” would require an additional £50 of these costs, which might be labled “overhead”. However, as this example suggests, many such “overhead” expenses are necessary parts of the mission, an increase its effectiveness (e.g., training employees, auditing, evaluating and targeting programs). On the other hand, we cannot rule out that in some cases high overhead might be a signal of inefficient practices. Where organizations have bloated annual operating expenses it might be more efficient for them to close down in the medium term and for that money to be used for leaner charities. (Several theoretical papers (ref: Steinberg 1986 and later work) discuss whether or not the overhead ratios are a sign of efficiency.) 8.7.1 Overview of Evidence Survey and observational evidence suggests that donors focus on potentially misleading measures of overhead. Gneezy, Keenan, and Gneezy (2014) present a credible piece of field-experimental evidence suggesting that having a “lead donor” and framing this as “covering overhead” may increase donations. Metzger and Günther (2019b) lab participants donate (marginally) significantly less when presented with (the option to buy) information about a NGO’s administrative costs (perhaps because such costs were made salient). Caviola et al. (2014) (hypothetical?) experiments suggest that evaluability may drive the focus on overhead rather than effectiveness. Portillo and Stinn (2018) lab participants favored overhead-free charities and preferred fundraising-related to salary-related overhead. Kinsbergen and Tolsma (2013) representative (Dutch) survey participants “have a strong aversion regarding overhead costs, [but]... seem to value the capacities of paid staff members and are, to a certain extent, willing to pay a price for these.” 8.7.2 Relevance to effective giving How this particular barrier proves problematic for effective giving? Studies finds ‘no correlation’ between overhead and effectiveness-- are these convincing? Check claims made in “BBB Wise Giving Alliance”; Caviola et al., 2014; Gregory &amp; Howard, 2009; Karlan, 2014; Pallotta, 2008; Sellers, 2018 As noted above, overhead is an important input to the charity’s production function, enabing it to be effective. A biases against overhead therefore distort’s the donor choice of charity away from effectiveness. The other side of this coin: in an efficient market firms provide the services consumers demand. If consumers have a preference for firms that use a lower share of some input, this will “distort” the production process away from this input, making it seem artificially costly [ref: Reinstein and Song, others]. Similarly, if donors punish charities for excessive overhead, charities will use “too little” of inputs deemed to be overhead. Note that doing impact evaluation will itself increase overhead. I.e., aversion to overhead will lead people to be biased against evidence-based charities that evaluate their own programs. While the above concerns do not necessarily tilt against charities targeting overeas or lower-profile causes, it nonetheless represents a departure from efficiency in choice/provision of charitable services. Furthermore, there is a reasonable case [todo: get evidence] that working in poor countries, countries that are further from the charity’s headquarters, and countries more distant from legal, financial, and other services will lead to a greater overhead ratio. This may be accentuated if the basic service (e.g., food, housing, or education) is cheaper in poor countries. E.g., sending a poor child in Chicago to a summer enrichment program might cost £4000 in fees and £500 to administer the scholarship, roughly 11% “overhead share” . Sending a poor Ghanaian child for a year might cost £300 plus £100 in administration, a 25% share. State of Evidence; key papers Methodological issues Observational (correlational) studies: Overhead varies across charities in non-random ways; may be correlated to unobservable characteristics. There may also be reverse causality – fundraising expenses both increase reported overhead and (presumably) drive donations. Meer (2017) identified plausibly exogenous variation; but this pertained to actual incremental costs/prices, rather than the “overhead” costs at issue Field experiments can vary presentation or framing of overhead but not (typically) a charity’ actual administration processes (thus “overhead”) Lab experiments can vary the actual price of giving but this doesn’t represent the real-world “overhead” issue; others In contrast, Metzger and Günther (2019b) varied the charity the subjects could donate to, but imposed a strong framing of the administrative costs as a marginal price). Survey and hypothetical vignette evidence (usual issues) Gneezy, Uri, Elizabeth A. Keenan, and Ayelet Gneezy. “Avoiding overhead aversion in charity.” Science 346.6209 (2014): 632-635.| Gneezy, Keenan, and Gneezy (2014) ran a large-scale (N=40,000 [check]) mail solicitation on behalf of an organization seeking to fund as many US educational projects (each costing $20,000 US) as possible. Recipients were asked to give 20/50/100 USD. They found that framing a lead donation as “covering[ing] all the overhead costs associated with raising the needed donations” lead to a significantly greater share donating and amount raised than either the control condition (no lead donation?) or a seed (“has given this campaign seed money”) or matching frame (“will match every dollar given… up to a total of $10,000”). Results Share donating: Overhead (8.5%) \\(&gt;\\) *** \\(\\geq\\) Match \\(&gt;\\) Control (3.4%) Amount raised: Overhead ($2.31) &gt; ** Seed, Match &gt; *** Control ($0.80) Note that while the framing differed, the actual treatment of the seed money in each case was the same; unless the charity could change the way it administered its programs between treatment, there is no clear way to experimentally vary the actual overhead. This amounts to a clear piece of evidence that in such contexts framing overhead as being “covered” in this way may increase donations. However, it doesn’t reveal donors’ reaction to the reported measure of overhead itself. The effect may come from the particular salience of the way the lead donor’s (particularly selfless) act is portrayed, or it may be specific to overhead \"associated with raising … donations\" rather than administrative overhead, salaries, etc. The same authors ran a lab experiment where they were able to vary the share of the subjects’ donation that actually went to the charity, labeling the difference (donation - amount passed) as “overhead”, and in a second treatment arm, whether this “overhead” was covered by a third party. The results were similar to the field experiment [CHECK, go into more detail]. However, this transparent “donation reduction” has little in common with the real-world costs usually depicted as “overhead”. In this lab experiment, a donor who cares about her marginal impact should consider the pass-through rate or “price”; this is not “overhead illusion”. Other standard critiques of lab experiments in this domain apply here. Portillo, Javier E.; Stinn, Joseph, (2018). “Overhead Aversion: Do Some Types Of Overhead Matter More Than Others?”. Journal Of Behavioral And Experimental Economics, 72, , 40--50. Portillo and Stinn (2018) Lab experiment If an overhead-free donation is readily available, then the average donor in our experiment (70–80% of subjects) prefers that charity to receive the donation. However, if donations are not overhead-free, most (approximately two-thirds of subjects) prefer the donation go toward fundraising efforts instead of salary-related expenditures. Kinsbergen, Sara; Tolsma, Jochem, (2013) Kinsbergen and Tolsma (2013) Hypothetical survey (vignettes, scenarios) \"We constructed 960 scenarios in which a fictive international development organisation was described. … A large representative sample of the Dutch population (N = 2,758) received six randomly allocated scenarios and had to decide if, and if so, how much they would donate to the depicted (fictive) organisation…. Although donors have a strong aversion regarding overhead costs, we find that donors seem to value the capacities of paid staff members and are, to a certain extent, willing to pay a price for these. Meer, Jonathan, 2017 Meer (2017) “Effects of the price of charitable giving: Evidence from an online crowdfunding platform” DonorsChoose platform involves plausibly exogenous variation in the providing (the same) goods to teachers across projects (varying sales taxes, fullfillment, payment processing fees, etc).[^3] Fees are ‘explicit and salient’. Robust analysis (e.g., teacher fixed-effects) to address a potential &gt; endogeneity concern (saavy teachers economize on fees) An increased price of giving results in a lower likelihood of a &gt; project being funded. We also calculate the price elasticity of &gt; giving, finding estimates between −0.8 and −2. However, this does not typify the overhead we are considering. Here, we see variation in the donot’s actual costs of providing outputs; as in Gneezy, Keenan, and Gneezy (2014) lab experiments, this is not “illusion”. While donor responses to e.g., greater fixed costs of maintaining an office in Malawi, or greater costs of identifying legitimately poor families might be similar, we do not know.\\(^+\\) “…variation in the payment processing, optional support, and fulfillment fees described above; along with sales taxes and shipping fees charged by vendors. … the optional support fee changed twice over the course of our data and the payment processing fee changed once. The fulfillment fee, a fixed amount, changed three times in the time covered by the data. In addition, this fee affects the efficiency price of different-sized projects differently. The changes affected only newly posted projects; therefore, for nearly half a year after each change was implemented, active projects that might be otherwise identical had different fee levels.” Furthermore, DonorsChoose doesn’t have clearly separate variation in effectiveness of the outputs which we could compare to the differential prices of providing particular outputs (fees, etc.), to potentially detect oversensitivity to the former. 8.7.2.1 Solutions (add section) “Seed donor covering overhead” Simultaneous comparisons and evaluation of impact and overhead where &gt; relevant Caviola et al. (2014) De-biasing? Other papers to look into and incorporate (unfold) Borgloh, S., Dannenberg, A., Aretz, B., 2013. Small is beautiful - experimental evidence of donors’ preferences for charities. Econ. Lett. 120 (2), 242–244. (Borgloh, Dannenberg, and Aretz 2013) Hope Consulting Survey: “a recent survey found that only 35 percent of donors do any research before giving (Hope Consulting, 2012), this is a valid concern – though among those who did research, the most commonly sought information was some type of overhead ratio, and two-thirds were seeking some sort of information related to efficiency.”-Meer “Making an impact? The relevance of information on aid effectiveness for charitable giving. A laboratory experiment” Metzger L Günther, Journal of Development Economics (2019) 136 (Metzger and Günther 2019c) \"We thus clarified that a decrease in administrative costs from 40% to 10% is equivalent to a 50% increase in net transfers to the recipient, in an attempt to make the administration costs group as comparable to the aid impact group as possible.\" -- this oversimplified framing may be driving their results. “A. a relatively small share of people makes a well-informed donation decision. B. the demand for information about aid impact is lowest, and it is highest for information about the recipient type. C. impact info didn't affect average donation, while information about the exact recipient type and administrative costs led to a significant change in donation levels.” “In the recipient type group, informed participants donated significantly more than uninformed participants because they”rewarded\" the preferred recipient with higher-than- average transfers. In the administration costs group, informed participants donated significantly less than uninformed participants because they used the information to “punish” NGOs with high administration costs.\" “only 28% of the participants in the bought ANY information (impact, who benefits overhead). Within that, highest demand for beneficiary, lowest for impact. Impact info no effect on giving. Knowing who benefits info increased giving. Overhead info decreased giving.” Caviola, L., Faulmüller, N., Everett, J. A., Savulescu, J., &amp; Kahane, G. (2014). The evaluability bias in charitable giving: Saving administration costs or saving lives?. Judgment and decision making, 9(4), 303. (Caviola et al. 2014) “When presented with a single charity, people are willing to donate more to a charity with low overhead ratio, regardless of cost-effectiveness. When presented with two charities simultaneously, they base their donation behavior on cost-effectiveness” Bowman, W., 2006. Should donors care about overhead costs? Do they care? Nonprofit Volunt. Sect. Q. 35 (June (2)), 288–310. (Bowman 2006) Meer… Are overhead costs a good guide for charitable giving? Trussel, J. M., &amp; Parsons, L. M. (2007). Financial reporting factors affecting donations to charitable organizations. Advances in Accounting, 23, 263-285. (Trussel and Parsons 2007) Tinkelman, D. (1998). Differences in sensitivity of financial statement users to joint cost allocations: The case of nonprofit organizations. Journal of Accounting, Auditing &amp; Finance, 13(4), 377-393. (Tinkelman 1998) Parsons, L. M. (2007). The impact of financial information and voluntary disclosures on contributions to not-for-profit organizations. Behavioral research in accounting, 19(1), 179-196. (Linda, Organizations, and Parsons 2007) Yörük, B.K. (2013). Charity ratings [this literature is not specifically on ‘overhead’; I should check how Charity Navigator factors this in] (Yörük 2016) Frumkin, P., &amp; Kim, M. T. (2001). Strategic positioning and the financing of nonprofit organizations: Is efficiency rewarded in the contributions marketplace?. Public administration review, 61(3), 266-275. (Frumkin and Kim 2001) van Iwaarden, J., Van Der Wiele, T., Williams, R., &amp; Moxham, C. (2009). Charities: how important is performance to donors?. International Journal of Quality &amp; Reliability Management, 26(1), 5-22. (van Iwaarden et al. 2009) Study finds ‘no correlation’ between overhead and effectiveness– is it convincing? Does working abroad increase overhead? Most relevant tie: doing impact evaluation will itself increase overhead. References: Gneezy, Keenan, and Gneezy (2014), Portillo and Stinn (2018), Kinsbergen and Tolsma (2013), Mayo and Tinsley (2009), Meer (2017), Chhaochharia, Ghosh, and others (2008), and Caviola et al. (2014) 8.8 Possible: Misunderstanding need (and misunderstanding marginality/tractability/sunk costs?) Related terms: misunderstanding marginality, misunderstanding tractability, sunk cost fallacies Misperceiving tractability: donations may respond to number of deaths from a disaster rather than to the scale of the need of survivors (sunk losses) donations may respond to average cost per life saved, rather than marginal cost per life General barrier to accurate assessment of effectiveness ergo a barrier to effective giving. 8.9 Scope insensitivity/embedding effect/part-whole effect “People’s stated valuation or”willingness to pay\" for an outcome seems not to strongly increase in the magnitude of that outcome. For example, when asked in isolation people might say they are willing to pay 50 USD to save 100 eagles. Other people asked in isolation may say they are willing to pay 50 USD to save 5000 eagles. Kahneman1992 (Part I: Embedding effect): the expressed willingness of Toronto residents to pay increased taxes to prevent the drop in fish populations in all Ontario lakes was only slightly higher than the willingness to pay to preserve the fish stocks in only a small area of the province.\" When assessing effectiveness in determining which charity to donate to (and how much), a utilitarian should be very sensitive to the scale of the impact (essentially the benefit per cost). If people are scope insensitive they will be bad at making these judgments (particularly when presented in isolation). Ref: Hsee et al. (2013) 8.10 Other quantitative biases 8.10.1 “Excessive Risk aversion or loss aversion” 8.10.2 Bias towards tangibility (perhaps not ‘quantitative’?) 8.10.3 Corruption aversion (perhaps not ‘quantitative’?) 8.11 Other possibilities: “Risk aversion”, Lack of tangibility, Corruption aversion See Airtable List of references "],
["inertia.html", "9 Barriers: Inertia and systemic/institutional 9.1 Social norms 9.2 Consider: inertia and obstacles to charities collecting, evaluating, and sharing impact information", " 9 Barriers: Inertia and systemic/institutional 9.1 Social norms Social norms promote giving to traditional non-EA causes and fundraisers, and responding to peer requests. –&gt; crowding out? Norms may also suggest giving to causes like AMF is “weird”. Asks (Own category?) Donation requests increase the propensity to give (Yörük 2009). There is a conventional wisdom that “most donations occur in response to an ask”. If there are systematic asks for non-EA causes this may crowd out EG. 9.2 Consider: inertia and obstacles to charities collecting, evaluating, and sharing impact information List of references "],
["tools-for-motivating-ea-giving.html", "10 Tools for motivating EA giving 10.1 Introduction 10.2 Psych/behavioral tools; applicability to EA charities 10.3 De-biasing and misperception correction 10.4 Innovative proposals 10.5 EA-movement approaches, sucesses and pitfalls 10.6 A listing", " 10 Tools for motivating EA giving 10.1 Introduction What “tools” and approaches may help to increase effective giving? We divide this into three categories: Approaches to overcoming the barriers and biases discussed in previous chapters. Fundraising approaches and innovations that will be particularly suitable for more effective charities, perhaps because these approaches themselves are directly tied to effectiveness. We call these “superpowers” for effective charities. Fundraising strategies that may have historically been underused by affective charities. 10.2 Psych/behavioral tools; applicability to EA charities Do the standard collection of psych/behavioral tools work for EA charities, or can they be made to do so? Does EA have any ‘superpowers’ for any of these? E.g., presenting identifiable victim. Emotional stimuli. Gift exchange, etc. Briefly highlight those ‘tools’ that give non-EA an advantage, but focus on the actionable–how EA lessen or flip that advantage. 2. Which tools present particular challenges or opportunities for EA 10.3 De-biasing and misperception correction 10.4 Innovative proposals 10.5 EA-movement approaches, sucesses and pitfalls What has EA tried and how has it worked; evaluate approaches in light of the evidence. Is the movement too ‘purist’ (e.g., focusing on only the most effective, proven charities instead of those with broader potential appeal but less evidence)? 10.6 A listing Make impact more comparable by allowing joint evaluation (Evaluation mode) Effective charities could present their (e.g., lifesaving) statistics relative to average/popular charities (but be careful about demonizing particular ones) Theory: Evaluability bias Cite: (Caviola et al. 2014; Kogut and Ritov 2005b, 2005a) 10.6.1 (Info enhancing) social closeness of recipient Percentage donations tied to purchases, especially in online auctions Psychometrics and targeting people likely to be responsive List of references "],
["conclusion-agenda.html", "11 Conclusion; a research agenda 11.1 A program and key principles for future research and action 11.2 Key practical questions 11.3 Policy issues 11.4 Why will this be helpful and who will use it and how? 11.5 Research infrastructure and methodology 11.6 Targeting 11.7 Working with charities and organisations", " 11 Conclusion; a research agenda 11.1 A program and key principles for future research and action This content comes in part from an open-ended letter of interest submitted to the Gates foundation. Our research program aims to provide practical methods to increasing the level and impact of effective, impactful private giving. We are building a database of evidence on “what works”, with a particular focus on the questions below. We will assess, evaluate, and present this information in several ways, including an interactive database, a wiki, and a meta-analysis and survey paper. Each of these will be carefully linked and integrated. For example, the analysis and discussion in the survey paper will be mirrored on the wiki, providing a platform for discussion and continuous updating. Each element of the surveyed evidence will be provided as a database entry, cross-referencing relevant papers, theories, use-cases, and available raw data. The meta-analysis will be presented in the database and Wiki, as well as in an web app (e.g., R Shiny Rstudio), to permit users to consider alternate statistical assumptions and focus on separate domains, as relevant to their own use-case. All of this will be provided in multiple formats (without confusing overlap), allowing users to choose a more technical, or a more descriptive presentation. 11.2 Key practical questions Who is giving to effective charities, and can we predict who is likely to be convinced to do so? (When/how) is asking people to re-target their giving towards more effective charities going to be effective? Is ‘substitution’/competition an issue? (Overcoming important practical and psychological barriers…) How to presenting effectiveness information in an effective way, without switching-off emotional motivations to give? Will de-biasing lead to effective giving? How can we avoid self-interested motivated reasoning? How can we reduce the empathic distance to international recipients and make the geographically-distant feel local? How can we best apply standard emotional and behavioral approaches (fundraising tools like ‘gift exchange’) to effective charities; what are the particular strengths and limitations of these charities in applying these? How can we incorporate psychological and social rewards for donors without overly sacrificing mission efficiency? What is the tradeoff between promoting the purest, best-evidenced charities (e.g., GiveWell’s list) and increasing the overall donation amounts? How to best target High-Net-Worth individuals to give effectively; does this require distinct approaches? 11.3 Policy issues Will these same tools help motivate support for foreign aid and other pro-poor policies? What is the interaction between private giving and (support for) government policies, and how can we boost the net effect? ##A program and key principles for future research Building platforms to observe relevant giving behavior, and systematic experimentation to observe impact of approaches in many contexts Open science framework: Research integrity, collaboration and data-sharing, enabling re-analysis and meta-analysis Robust and validated evidence: Pre-registration and pre-analysis plans, experimentation and independent replication across a range of relevant environment and frames Present research for users in an effective way, using modern information systems. Not mainly for “old-school” academic journals; living, continually-validated and re-assesed research rather than frozen pdf’s. Open access in a web framework. Collaboration with and across relevant charities and fundraisers (e.g., the International Fundraising Leadership Forum) Organized open communication and sharing informal trials via wiki tools Replication (and verification), pooled evidence, meta-analysis Context-sensitivity, large SE \\(\\rightarrow\\) large samples, statistical learning controls, sharing data Responses to ‘obvious contrasts’ seem to not reflect between-subject responses\" 11.4 Why will this be helpful and who will use it and how? Effective charities, fundraisers for these charities, and groups of these organizations will use this directly. As noted above, the results will be presented in interactive accessible ways, including more and less technical presentations, and allowing users to select a tailored analysis. We will aim to provide personal support and communication to qualified effective charities. Researchers interested in this area (both “effective charitable giving” directly, and as an input into understanding human behavior). Our project will encourage and foster future work… Providing an accessible ‘evidence baseline’, a shared database of raw and meta-data, and collaborative tools to facilitate further analysis Building an interactive community, providing ways to disseminate results to users and see a clear practical impact. Further on, we aim to build a low-overhead, straightforward application process and network to evaluate and disperse grants to fund promising research; all funded projects will be required to follow the principles of open, robust, and collaborative research alluded to above Government policymakers: in enabling and enhancing effective private giving, and providing public programs that are compatible with this Foundations (Gates, etc), in targeting and communicating interventions, considering interactions and feedback on the wider society of givers. Advocates and activists for globally sympathetic and pro-poor policies; this research is likely to unlock both factors that encourage effective giving, and factors that drive cross-cultural sympathy, empathy, and action 11.5 Research infrastructure and methodology Also see gatesproposal.md (Gates foundation) 11.6 Targeting Who gives to the truly most effective international charities? Who is most likely to be convinced, and which arguments/presentations work in the SR and LR, and for whom (heterogeneity)? Statistical learning-based analyses Practicable techniques in a range of higher-stakes real-world environments 11.7 Working with charities and organisations "],
["bookdown-appendix.html", "12 Appendix: Tech for creating, editing and collaborating on this ‘Bookdown’ web book/project (and starting your own) 12.1 Introduction 12.2 Git and Github 12.3 R and RStudio 12.4 Markdown and Bookdown 12.5 The code and folder structure in this repo, and what it means 12.6 Adding the main content… the code in a single “.Rmd” file 12.7 How to ‘build’ and view the book 12.8 Joining this project 12.9 Airtable and innovationsinfundraising.org 12.10 Useful resources", " 12 Appendix: Tech for creating, editing and collaborating on this ‘Bookdown’ web book/project (and starting your own) This tutorial written by Oska Fentem with David Reinstein 12.1 Introduction This appendix provides a brief introduction to the several types of software and processes used to creating websites such as Increasing Effective Charitable Giving and Researching and writing for Economics students. We aim to encourage others to participate in this collaborative work, and to spin off their own projects. If you would like to provide feedback or ask a question about these projects then using ‘hypothes.is’ is an easy way to do so. You can also contribute content through the Airtable forms (see above). The template for my bookdown projects is maintained in my repo here This site (web-book project) is Hosted: Hosted on Github (Github pages) A project managed out of a Git repo stored in Github The content is: A ‘Bookdown’ (in the ‘Gitbook’ style, although we’ve drawn elements from the Tufte style) …which is a hosted collection of HTML (and other) files… …constructed/compiled/built from R-Markdown (.Rmd) files and other support files using the R language This relies heavily on: ‘Markdown syntax’ for basic writing/formatting Latex for mathematics notation Bibtex for references/citations ‘Pandoc’ to convert between different document formats CSS (style sheets) To build this, we chose to use tools and software including: The RStudio environment for working with R code Github desktop to manage pushing/pulling and integrating content (although sometimes we use raw Git) Features of the GitHub website such as ‘projects’ We first give a brief overview of R &amp; RStudio, Git &amp; Github, and R Markdown &amp; Bookdown, linking more extensive further resources/tutorials. 12.2 Git and Github Git is a version control system which enables users to track changes and progress in coding projects or any files in general. It is particularly useful for collaborating on projects as it provides a useful way to show who has altered which files and when. Users are even able to clone a repository (a folder inside of a project which tracks all changes made) and make changes without affecting the original project. Git also provides a very simple way to keep changes to projects up to date across different operating systems such as Windows and Mac. Installation and configuration of Git can be confusing to the newly-initiated user, Happy Git provides a user friendly tutorial on installing Git, which can be downloaded here. Getting a Github account should take about XXX minutes. Here’s a guide to exactly how to do it. Installing Git and the GitHub Desktop should take about XXX minutes. Here’s a guide to exactly how to do it. 12.2.1 Some key things to know about Git and GitHub A brief overview of key functions inside Git (assuming a remote Github repo) including commits, pushes &amp; pulls, forks &amp; branches and pull requests: (unfold) Cloning a Git repository copies an existing Git repository into your local file space. A commit saves the changes made in the current document to the local repository. Specific changes to commit to the remote (online) repo must be specified. This process is made much easier using a program such as Github Desktop rather than the Git code itself (although they do the same thing, and the latter is more flexible). A push, pushes all local commits to the online version of this repository, essentially updating the online version of the files, to the version which is stored locally on your device. A pull, is used to pull the changes made to the online repository, into the local repository. Thus making the local repository up to date with the remote/online repository. Creating a branch allows you to create a separate version of a repository and make changes to this without affecting the master/original repository. A pull request then allows you to pull the changes made in a branch over to the master repository, in order to merge the work. As noted, Github Desktop provides a user interface for a more simple and intuitive way to use Git. There are a variety of other interfaces. Github can also be integrated into RStudio and into many other tools, such as the Atom text editor. Repos that are stored on Github can be accessed via a browser at github.com. The Github website itself provides a wide variety of tools, discussed further below under ‘GitHub web page’, Git and GitHub can be a bit confusing. Here are some things that I wish I had known, that took my a while to figure out (unfold) Git and Github are not the same thing … (explain) A ‘commit’ does not actually change the files in the shared (remote) Github repo; you need to ‘push’ to do that After ‘pulling’ from the remote repo, you may need to merge changes… (explain) You can have several different ‘branches’ of the same Repo existing at the same time. When you switch to a new ‘branch’ the files you see on your computer will instantly and amazingly change to exactly the files in that branch. But don’t worry, the old branch is not lost. … add some more 12.3 R and RStudio R is a free programming language which is mainly used for data analysis and statistics. It can be downloaded here. The popularity of R is growing in Economics Academia, largely due to the growth of Machine Learning techniques in R as well as the flexibility of the language itself. R makes use of packages which are a collection of functions written in order to achieve specific tasks. Whilst R comes pre-installed with a variety of useful packages, it is often useful to install more, which can be done using the install.packages command. If you are familiar with Python, these R packages are roughly comparable to Python’s modules. Installing R should take about XXX minutes. Here’s a guide to exactly how to do it. RStudio is a programming environment and interface which helps facilitate a variety of tasks such as writing scripts using R (as well as other languages), and building/knitting these into various document formats. RStudio ‘Addins’ can also be extremely useful for things like tracking ‘todos’, adding citations, and formatting code. RStudio can also be configured so as to work seamlessly with Git (more on this later). RStudio can be downloaded here Installing and configuring RStudio should take about XXX minutes. Here’s a guide to exactly how to do it. 12.4 Markdown and Bookdown Markdown is a popular set of formats (really a ‘syntax for specifying output’) for generating and authoring documents. The Rmarkdown format (rmarkdown package) is one flavor of Markdown that works with R to enable ‘dynamic documents’ involving text, data-analysis, and other elements. It can then export your work to a variety of outputs such as html, pdf and word documents. As well as this it can also be used to create webpages, such as the one you are currently reading. The power of Markdown files comes from the way that they are able include/embed code as well as data and tables, which is useful for writing reproducible research and creating websites. The Bookdown package was built on the Rmarkdown package, but it adds many features to enable larger and more structured output, particularly ‘web books’ and web sites. As we use it, this these books combine multiple Rmarkdown files, with each such ‘Rmd’ file becoming its own HTML page. Look at the list of headings on the left of this page: each second-level header is it’s own web-page (a distinct html link). “All the content in one scrolled page” is limited to a single first-level header. stackedit.io can help you practice your markdown, or work on it in a nearly-WYSIWYG environment. To work on the files in a github archive directly in stackedit.io: Make sure you are a member of the archive Go to https://stackedit.io/app# Click the “#” in the upper right corner Click ‘synchronise’ and add your github account Click ‘open from github’ Fill in the url for the github repo, e.g., https://github.com/daaronr/ea_giving_barriers/, and the (folder and) file you want to edit, such as README.MD) (Not sure if rmd works; gotta check) It should then come out with two panels. Left panel=code, right panel=output in a nice format, auto-updating. You can open one, close the other, etc., and there are lots of tips/tools. Hitting ‘synchronise’ should push your changes to the Github repo (but doublecheck this is working) 12.5 The code and folder structure in this repo, and what it means 12.5.1 Writing_econ_book: Files-folders of interest (taken from readme March 2020) docs: html output put here for web hosting Folder: writing_econ_book bookdown.yml: determines which files are included in the book writing_econ_gfm.Rmd: The main content; body of the book (many chapters) index.Rmd: Setup content and some styling/parameters; determines how the book is built (into which format, etc) header_include.html: Important commands included here including folding boxes references_cut.bib: bibtex references referred to in ‘@ref’ notes tufte_plus.css: Determines layout and styling writing_econ_book.Rproj: ‘project’ … to work on this in R-studio 12.6 Adding the main content… the code in a single “.Rmd” file …and how it translates into content Video guides In the video: intro to rmd and bookdown - template HERE I introduce the basics of the Bookdown setup and folder structure, using the bookdown template repo files as an example. I further discuss the elements of the .Rmd (and associated) files, and how they translate into html output in the video: rmarkdown content from template HERE A final video that focuses a bit more on adding citations is HERE – this latter video has a very large file size, sorry. My apologies: In these videos my dumb head is blocking an important part of the screen share. It may help you to have the original files up to see the missing bits. I hope to redo these when I have a chance. Note: The key files and settings for my bookdown projects are maintained in my repo here, along with a minimal example. This is (or should be) synchronised with all the other repos. A tip: ‘find in files’ ‘Find in files’ is a nice tool when working in Rstudio for a project combining many files. In menu bar, select: - Edit - Find in files… Or use the (built in?) shortcut (in Mac) &lt;Shift&gt;-&lt;cmd&gt;-f 12.6.1 Basic (R-)Markdown The Markdown format offers a simple plain-text notation for specifying the elements of documents, reports, web sites, etc. (It is much simpler and easier to read than html, latex, etc.) It is widely used by programmers, on comment boards/forums, and throughout the internet. For example, GitHub.com automatically renders markdown code, particularly in readme.md files. Actually there are several varieties of markdown, but they mainly share key elements. Markdown documents are usually saved as plain text files with the extension .md, e.g., report.md. These allow for an easy way to create a variety of outputs, particularly reports and text-focused web pages. The markdown format is converted into other formats (html, latex, etc.) with a variety of tools, particularly something called Pandoc. What is Pandoc? Pandoc is a tool (a program) for converting from one document format to another. It is incredibly powerful. The great thing about a format like markdown, or r-markdown, is that it is simple to write and peruse, and, with the help of Pandoc, it can convert into many many other useful formats for web pages, documents, presentations, etc. Pandoc is built into other tools including the RMarkdown package (see discussion on Stackexchange here). You can also install and use Pandoc directly in the command line, or try it out (in a limited but still useful way) on the web here For more on Pandoc visit pandoc.org In the R (statistically focused) language there are tools such as knitR that allow R users to produce reports combining text, statistical output, and interactive content. These are generally written in “R-markdown” documents, saved as .Rmd rather than .md files. The R-studio interface, and several “add-ins”, also help facilitate this. This interface is very useful; in fact, it may be convenient to build web books and other content using this even if you are not planning to extensively integrate R code and data. (As in the present book, although I’m hoping to build this in). Using R-markdown and Knitr (and other tools and add-ins like ‘Bookdown’) content from multiple sources can easily be embedded into these documents allowing users to easily display objects such as plots or regression output. 12.6.2 Some simple markdown rules Text can be made italic using single asterisks *italic or bold by using asterisks **bold**. Hashtags/pound signs (#) specify headers and subheaders, e.g., this third-level subsection header was created with the code: ### Some simple markdown rules {#simple-md-rules} Where the bit in the curly braces allows us to link-back with the code [link back text whatever](#simple-md-rules) … rendering as link back text whatever. Other key features are ordered lists and unordered lists: - unordered first entry - unordered second entry - subelement of second entry While basic markdown has a limited set of rules, there are many more formatting and content options for documents produced in (R)-Markdown, far too many to detail here. These may combine markdown code, html code, latex code, and more. The following cheatsheets are very useful for writing (R)-markdown documents: Markdown documents allow for an easy way to write reports. Content from multiple sources can easily be embedded into these documents allowing users to easily display objects such as plots or tables of data. Text can be made italic using single asterisks *italic* and bold by using double asterisks **bold**. There are various text formatting options in Markdown, far too many to detail here… The following cheatsheets are very useful for writing markdown documents: Markdown cheatsheet R Markdown cheatsheet See also (most useful, but highly detailed): R markdown - the definitive guide Code chunks provide an easy way to embed code into your R Markdown files. The code language is not just limited to R either, as other languages can be used. This means that there is a wide variety of content which can be displayed in a chunk. Such as tables of data: Table 12.1: Sepal.LengthSepal.WidthPetal.LengthPetal.WidthSpecies 5.13.51.40.2setosa 4.93&nbsp;&nbsp;1.40.2setosa 4.73.21.30.2setosa 4.63.11.50.2setosa 5&nbsp;&nbsp;3.61.40.2setosa 5.43.91.70.4setosa Code chunks are defined by wrapping text inside ``` ```. The above example was coded using: ```{r} head(iris) ``` Options can be specified inside of the curly brackets {} More information is provided here 12.6.3 Inline code Inline code is a quick and easy way to put snippets of R code. As an alternative to using code chunks, R code can simply be placed inside of `r `. For example, this can be used as an easy way to insert the value of a variable into a paragraph without inserting a chunk. 12.6.4 Latex/maths R Markdown also can make use of the LaTeX document preparation system, which is popular for writing technical documents with mathematical content. This allows us to publish documents which include equations such as: \\[y = \\beta_0+\\beta_1x_1 +\\beta_2x_2+...+\\beta_kx_k+u\\] Which is written using $$y = \\beta_0+\\beta_1x_1 +\\beta_2x_2+...+\\beta_kx_k+u.$$. Using $$ means that the equation will be centered on the page. Alternatively $ can be used in the same way, without the centering. A very useful guide to maths in R Markdown provides a detailed outline of the various mathematical symbols which can be used. 12.6.5 Custom styles Bookdown allows for users to build their own custom styles in order to change the appearance of documents. To create styles for HTML projects a custom css file is used. For these projects, styles are contained in support/tufte_plus.css. To use a defined style, the user can specify options at the start of a chunk, or using a HTML wrapper as show below for margin notes. More on creating styles here. Below will outline several key styles used throughout these projects: ‘Notes’ Formatted ‘Notes’ have been defined in this work which allow text to be placed in coloured blocks such as this one. To use this note style, {block2, type ='note'} can be specified at the start of the block, or a HTML wrapper can be used. This assigns the .note formatting from the tufte_plus.css file to the chunk. Margin notes Margin notes are used throughout these projects as a way of displaying information in an organised and aesthetically pleasing way. To add a margin note, text is placed inside the following HTML wrapper: The margin notes used in this project are inspired by the Tufte handout style developed by American statistician Edward Tufte. &lt;div class=&quot;marginnote&quot;&gt; Your margin note goes here. &lt;/div&gt; Or margin notes can be added by using chunk options. Folding boxes Folding boxes also provide a useful way to incorporate content without cluttering the page. Similarly to the ‘notes’ the folding boxes are defined in tufte_plus.css and called by specifying {block2, type='fold'} at the start of a chunk, or using a HTML wrapper. 12.6.6 Adding references/citations As with any academic work, it is always important to reference sourced material. Across these projects the following software is used: Setup Pandoc provides a way to generate formatted references as well as a bibliography in R-Markdown. The bibliography file to be sourced is specified within ‘YAML’ content, which guides the processing of these documents. (YAML content is generally enclosed with a three-dash --- break at top and bottom.) I generally specify the bibliography source in the YAML at the top of the .Rmd file, or for Bookdown projects in the the YAML content in index.Rmd. BibTeX The BibTeX format refers to a stylized file format which is used predomoninantly for lists of references, mainly and originally for working with latex.. BibTeX bibliographies use the .bib extension. For example the bibliography for this project is giving_keywords.bib. For more information on BibTeX see here Zotero Zotero is a free open source reference manager, which enables users to sync their library of references across multiple devices. Similarly to other reference managers, Zotero offers plugins for popular browsers such as Chrome and Safari. This project makes use of a shared reference library in Zotero, contact daaronr AT gmail.com to be added. Download Zotero Better BibTeX for Zotero Better BibTeX for Zotero is a add-on for Zotero. Among other things it allows the Zotero library to be exported from Zotero for use in Markdown. Installation instructions are provided here. Citr package (addin) for RStudio The Citr package provides functions to search Zotero and BibTeX libraries in order to insert references into Markdown files. Citr also features a plugin for RStudio which makes the referencing process even easier. Instructions for download, as well as a demonstration of the Rstudio plugin are provided here. When using the Citr package to add citations to projects such as this one, make sure to have Citr update the correct Bibtex file. Citr Settings for Ea_giving_barriers The Bibtex file to “Add references to” is the bibliography file specified in the YAML header of index.Rmd. 12.6.7 Specific system for adding references in this project Method 1 (recommended): Rstudio citr plugin linked to Zotero Install Zotero software, Rstudio, and citr package (an ‘Add-in’). Make sure all are running. Join the Zotero reinstein_research_and_impact_collabs group Make sure the group library is syncronised with your Zotero R-Studio ‘Addins (see bar at top)’, (Citr) ‘insert citation’, settings (brings up the screen shown above) Make sure ‘add references to’ specifies the “…ea_giving_barriers/support/reinstein_bibtex.bib” folder. Make sure Zotero ‘reinstein_research_and_impact_collabs’ library is loaded Try to add the citation/reference. Note that [@reference] gives a different format than @reference (see below test). If the reference is not present, add it to the Zotero library (there are various methods, from Google Scholar etc) and synchronise your library, and try it again. If you are not sure what the reference is, consult the Airtable, use context, and consult other survey papers. If you are still not sure ask on Github. Method 2: Dropbox-syncronised Zotero to bibtex (I’ll explain this later) Adding a shortcut key for ‘insert citations’ in R-Studio You may be able to save time in adding citations (via the CitR add-in in R-Studio) if you use a shortcut key. Select (menu bar): Tools Addins Browse addins Click in box “keyboard shortcuts” Click the addin “Insert Citations” under ‘shortcuts’, and enter a keyboard shortcut of your choice. 12.6.8 A test of adding references Test a reference from reinstein_bibtex.bib: Fong and Oberholzer-Gee (2010a) no brackets (Fong and Oberholzer-Gee 2010a) with brackets using an “ID”\" only: (Fong and Oberholzer-Gee 2010a) 12.7 How to ‘build’ and view the book One way is within RStudio Be sure Github repo is synced so all files are present Packages need to be installed, but this should (?) be done automatically when you build via the source(here(\"code\", \"baseoptions.R\")) line in index.Rmd knitr is a key package Click ‘Build’, ‘Build all’, or the shortcut key shift-cmd-b … this seems to run the command rmarkdown::render_site(encoding = 'UTF-8') Building may take some time, depending on how much code is present in the Rmd files and what that code does It puts all the Rmd files specified in the _bookdown.yml into a single file, here labeled barriers-to-effective-giving.knit.md (I think), and then turns that into html, also invoking bibtex along the way Depending on your RStudio settings (-Tools, -Project Options, -Build tools, -Preview book after building), it may put up a ‘preview version’ of the site. Sometimes an error will appear such as “some/file not found”, this can typically be bypassed by clicking open in browser. All the ‘new’ output is directed to be put in the ‘docs’ folder, a bunch of html files. You can view those ‘local’ files in any web browser Once you commit and push, the ‘new’ bookdown website should be up on the WWW 12.8 Joining this project Get a Github account, contact daaronr AT gmail.com and tell him your github account ID (or the email you used to join should probably work as well) Remember to ‘accept’ the invitation to the repos (here, the EA_giving_barriers repo; and possibly some other supporting repos as well). You should receive this invitations via email and it should also be in your “notifications” on Github. 12.8.1 Creating a Branch and a ‘pull request’ 12.8.2 GitHub web page content {#} As noted, GitHub is a web page and interface that acts as an external server and storage space for git projects/repos. It works well with this and also incorporate several additional features. You can see it and even interact with much of a repo simply via the GitHub webpage without even installing Git (but I strongly recommend that you do install Git as well as a tool like GitHub Desktop, unless you want to solely rely on command line Git). Web page for a repo knitr::include_graphics(&#39;picsfigs/ea_barriers_github_repo_startpage.png&#39;) Figure 12.1: EA barriers repo github starting page In your account when you click on the repo you’ll see something like the screen above. There are many tabs, starting with the code tab. At the top of this, you will see the list of folders and files, with messages describing the latest comments. Once you’ve installed Git you will want to ‘clone this repo’ to have it on your machine and to be able to easily work with it and commit and push and pull changes. You will do this clone either via the web site, GitHub Desktop or another application, or using the command line Note here we also see: 48 ‘commits’ 2 ‘branches’ 2 contributors Below this, some options allowing you to switch branch, manually upload files, clone or download etc. Readme for a repo Below the list of files you should see the “readme” for this repository. This is a file ‘README.md’ stored in the root directory of this repository. If you click on it or look at the file you’ll see it is written in markdown syntax but the GitHub website renders it into a nice format. I typically use this readme to explain what the project is about and describe (and link) the folder structure. Comments/notifications In a variety of places within a repo when you are adding comments or content you can refer to a collaborator who will then receive a “notification” linking this content. (These are also called “callouts” in some systems.) These may come as as emails to that collaborator if they set a setting to get email notifications, but they will definitely appear as a notification, again that bell thing in the upper right hand corner. Seeing recent commits, history and ‘blame’ Showing the most recent commits Above, this shows the most recent commits. Clicking on one of these commits will show you ‘what changed’ and old versus new versions. Showing the most recent commits For example, above we see something like a “split diff” view, with the ‘old version’ (before this commit) on the left and the ‘new version’ on the right. What is new is in green (with a ‘+’), and what is removed is in red highlight (with a “-”). Here we see that … in the file ‘sections/inertia.rmd’ a space has been added after ‘crowding out?’ This is but one way to view and consider changes. Various text editors such as Atom and ViM also offer great tools, as does the Git program itself and the GitHub desktop application. in ‘present_puzzle.Rmd’ an (obsolete) ‘underline’ notation has been replaced with a third level markdown header (three # marks) Commenting within commits, etc., tagging collaborators in this One way to ask questions, comment on changes and let people know about changes you made, is via adding a comment within a commit itself. (Check: can this be tied to an ‘issue’?) Commenting on a part of a commit, notifying a collaborator Above, we see that by clicking on a plus sign that appears just to the right of the the line number when viewing a commit, we can add a comment on that particular part of the commit. We can then flag another collaborator (see ‘@daaronr’ above … when you type the ‘@’ you get a dropdown of collaborators) who will be notified of this. This mode of commenting and conversation has the advantage of avoiding cluttering up the actual code and text with excess comments. You can also link each comment to an ‘issue’ (issues are discussed below) by adding a hash to the comment and citing the issue number. This comment and link to the place in the code or text for that commit will then show up when you look at that issue. This makes the discussion more organized, at least we hope. Link an issue in a comment The ‘Project’ board and ‘Issues’ I discuss these features in a video guide here starting at about 11:46. Note that the ‘project board’ and ‘issues’ are just tools on the Github web site for discussing and managing the project; these are not files or data, it’s a built-in tool. the Project is a ‘Kanban board’ for managing tasks, responsibilities and progress these should be entered as ‘issues’, enabling assignments and further discussion within the ‘issues’ pages a github ‘Project’ Kanban for the github ‘Project’ One task/issue in the Kanban Viewing this issue and its discussion 12.9 Airtable and innovationsinfundraising.org This project is closely connected to innovationsinfundraising.org. Much of these projects overlap, and there is a shared ‘database’ stored as an airtable Giving researchers shared We had an earlier … tutorial on using the Airtable and Innovationsinfundraising.org here I add a few more points below, more relevant to the current project: Airtable Airtable is a collaborative web-based software with a variety of displays and organizational structures; it has many features of a relational database, and even more features if one engages their API. It is user-friendly, with a gui resembling a spreadsheet, and easy tutorials, instructions and examples. You can operate it from a browser or a web-driven app. Key features of tables in Airtables (quick views) Each Airtable user can have any number of Bases, and bases can be shared in work groups. Command-K to jump to any other Base “key_papers”; the papers providing the most relevant and strongest evidence for the tool, and “secondary papers”. Key content The “Categories” table provides and explains a number of “schema” we use to characterize both the tools and the “Barriers to effective giving” (discussed later). categories table Key papers are stored and organised in the ‘papers_mass’ table. This is crosslinked in several other tables. Within each paper ‘row’ there is a variety of relevant information and discussion on each paper. key papers The fundingwiki app automatically populates and updates information on the number of times each paper has been cited, using the Crossref database. Tool such as these will enable this to be a perrennial resource, rather than a frozen-in-time evaluation. citations auto update Note: Some but not all of the Airtable content discussed in the rest of this subsection has already been incorporated into the present bookdown. The table “EAlit_sections” outlines the (earlier?) structure of the EA barriers paper, already providing links to information that will be integrated. organizing ealitpaper This table also links directly to the papers_mass table, organizing the papers we are referencing and reviewing in each section. organizing EAlit papers The separate “Barriers to EAG” table is below. This organizes and assembles the discussion and evidence on potential factors and categories of factors that may explain the limited amount of “effective giving”. This represents the largest part of our review paper; we focus on clear definitions of the most relevant psychological (and “behavioral economic”) biases, and carefully asses the available evidence. We focus specifically on evidence in the charitable domain, but we also consider the broader evidence for these biases in other contexts. barriers to EAG Again, this is older work, maybe already incorporated into the Bookdown? For each barrier or bias, we consider why it is may be particularly relevant to effective giving. barriers to EAG, why relevant We further propose and discuss tools addressing these barriers and promoting effective charitable giving. tools remedies 12.10 Useful resources Like most things, when working with code the internet is your best friend. Listed below are several useful resources for learning about the material mentioned above: 12.10.0.1 R Markdown: The definitive guide 12.10.0.2 R for Data Science Authoring Books with R Markdown 12.10.0.3 YaRrr! The Pirate’s Guide to R List of references "],
["references.html", "13 List of references", " 13 List of references Ackerman, Frank. 2008. “Climate Economics in Four Easy Pieces.” Development 51 (3): 325–31. Adena, Maja, and Steffen Huck. 2019. “Giving Once, Giving Twice: A Two-Period Field Experiment on Intertemporal Crowding in Charitable Giving.” Journal of Public Economics 172. https://doi.org/10.1016/j.jpubeco.2019.01.002. Aggarwal, Pankaj. 2004. “The Effects of Brand Relationship Norms on Consumer Attitudes and Behavior.” Journal of Consumer Research 31 (1): 87–101. Aknin, Lara B, Elizabeth W Dunn, Ashley V Whillans, Adam M Grant, and Michael I Norton. 2013. “Making a Difference Matters: Impact Unlocks the Emotional Benefits of Prosocial Spending.” Journal of Economic Behavior &amp; Organization. https://doi.org/10.1016/j.jebo.2013.01.008. Andreoni, James, Justin M Rao, and Hannah Trachtman. 2017. “Avoiding the Ask: A Field Experiment on Altruism, Empathy, and Charitable Giving.” Journal of Political Economy 125 (3): 625–53. Angner, Erik. 2012. A Course in Behavioral Economics. Macmillan International Higher Education. Baron, Jonathan. 1997. “Confusion of Relative and Absolute Risk in Valuation.” Journal of Risk and Uncertainty 14 (3): 301–9. https://doi.org/10.1023/A:1007796310463. Baron, Jonathan, and Ewa Szymanska. 2011. “Heuristics and Biases in Charity.” Benartzi, Shlomo, and Richard H Thaler. 2007. “Heuristics and Biases in Retirement Savings Behavior.” The Journal of Economic Perspectives, 81–104. Bergh, Robin, and David Reinstein. 2020. “Empathic and Numerate Giving: The Joint Effects of Victim Images and Charity Evaluations.” Social Psychological and Personality Science, 1948550619893968. Berman, Jonathan Z., Alixandra Barasch, Emma E. Levine, and Deborah A. Small. 2018. “Impediments to Effective Altruism: The Role of Subjective Preferences in Charitable Giving.” Psychological Science, 095679761774764. https://doi.org/10.1177/0956797617747648. Borgloh, Sarah, Astrid Dannenberg, and Bodo Aretz. 2013. “Small Is BeautifulExperimental Evidence of Donors’ Preferences for Charities.” Economics Letters 120 (2): 242–44. Bowman, Woods. 2006. “Should Donors Care About Overhead Costs? Do They Care?” Nonprofit and Voluntary Sector Quarterly 35 (2): 288–310. Brewer, Marilynn B, and Wendi Gardner. 1996. “Who Is This\" We\"? Levels of Collective Identity and Self Representations.” Journal of Personality and Social Psychology 71 (1): 83. Brown, A L, J Meer, and J F Williams. 2016. “Social Distance and Quality Ratings in Charity Choice.” Journal of Behavioral and Experimental. Burton, Matthew J, and David CW Mabey. 2009. “The Global Burden of Trachoma: A Review.” PLoS Neglected Tropical Diseases 3 (10): e460. “CAF World Giving Index 2018 | Research into Global Giving Behaviour.” n.d. https://www.cafonline.org/about-us/publications/2018-publications/caf-world-giving-index-2018. Cairns, Jason, and Robert Slonim. 2011. “Substitution Effects Across Charitable Donations.” Economics Letters 111 (2): 173–75. https://doi.org/10.1016/j.econlet.2011.01.028. Camerer, Colin F, and Richard H Thaler. 1995. “Anomalies: Ultimatums, Dictators and Manners.” Journal of Economic Perspectives 9 (2): 209–19. Caviola, Lucius, Nadira Faulmüller, Jim. A C Everett, and Julian Savulescu. 2014. “The Evaluability Bias in Charitable Giving: Saving Administration Costs or Saving Lives?” Judgment and Decision Making 9 (4): 303–15. https://doi.org/None. Caviola, Lucius, Stefan Schubert, and Jason Nemirow. 2020. “The Many Obstacles to Effective Giving.” Judgment and Decision Making 15 (2): 159. Charness, G, and U Gneezy. 2008. “What’s in a Name? Anonymity and Social Distance in Dictator and Ultimatum Games.” Journal of Economic Behavior and Organization. https://doi.org/10.1016/j.jebo.2008.03.001. Chen, Yan, and Sherry Xin Li. 2009. “Group Identity and Social Preferences.” American Economic Review 99 (1): 431–57. https://doi.org/10.1257/aer.99.1.431. Chhaochharia, Vidhi, Suman Ghosh, and others. 2008. “Do Charity Ratings Matter.” Unpublished Manuscript, Florida Atlantic University. Cuddy, Amy JC, Susan T Fiske, and Peter Glick. 2007. “The BIAS Map: Behaviors from Intergroup Affect and Stereotypes.” Journal of Personality and Social Psychology 92 (4): 631. DellaVigna, Stefano, John A List, and Ulrike Malmendier. 2012. “Testing for Altruism and Social Pressure in Charitable Giving.” The Quarterly Journal of Economics 127 (1): 1–56. Deryugina, Tatyana, and Benjamin Marx. 2015. “Do Causes Crowd Each Other Out ? Evidence from Tornado Strikes,” no. December: 1–19. Donkers, Bas, Merel Van Diepen, and Philip Hans Franses. 2017. “Journal of Behavioral and Experimental Economics Do Charities Get More When They Ask More Often ? Evidence from a Unique Field Experiment 73” 66: 58–65. https://doi.org/10.1016/j.socec.2016.05.006. Dovidio, John F. 1984. “Helping Behavior and Altruism: An Empirical and Conceptual Overview.” In Advances in Experimental Social Psychology, 17:361–427. Elsevier. Dovidio, John F, Kerry Kawakami, Craig Johnson, Brenda Johnson, and Adaiah Howard. 1997. “On the Nature of Prejudice: Automatic and Controlled Processes.” Journal of Experimental Social Psychology 33 (5): 510–40. Drouvelis, Michalis, and Brit Grosskopf. 2016. “The Effects of Induced Emotions on Pro-Social Behaviour.” Journal of Public Economics 134: 1–8. Ebert, Jane EJ, and Drazen Prelec. 2007. “The Fragility of Time: Time-Insensitivity and Valuation of the Near and Far Future.” Management Science 53 (9): 1423–38. Eisensee, T, and D Stromberg. 2007. “News Floods, News Droughts, and US Disaster Relief.” Quarterly Journal of Economics 122 (2): 693–728. https://doi.org/10.1162/qjec.122.2.693. Epstein, Keith. 2006. “Crisis Mentality (SSIR).” https://ssir.org/articles/entry/crisis_mentality. Erlandsson, Arvid, Fredrik Björklund, and Martin Bäckström. 2014. “Perceived Utility (Not Sympathy) Mediates the Proportion Dominance Effect in Helping Decisions.” Journal of Behavioral Decision Making 27 (1): 37–47. ———. 2015. “Emotional Reactions, Perceived Impact and Perceived Responsibility Mediate the Identifiable Victim Effect, Proportion Dominance Effect and in-Group Effect Respectively.” Organizational Behavior and Human Decision Processes 127: 1–14. https://doi.org/10.1016/j.obhdp.2014.11.003. Erlandsson, A, D Västfjäll, O Sundfelt, P Slovic - Journal of Economic, and undefined 2016. n.d. “Argument-Inconsistency in Charity Appeals: Statistical Information About the Scope of the Problem Decrease Helping Toward a Single Identified Victim but Not Helping.” Elsevier. Evans, Jonathan St BT, and Keith E Stanovich. 2013. “Dual-Process Theories of Higher Cognition: Advancing the Debate.” Perspectives on Psychological Science 8 (3): 223–41. Everett, Jim A. C., David A. Pizarro, and M. J. Crockett. 2016. “Inference of Trustworthiness from Intuitive Moral Judgments.” Journal of Experimental Psychology: General 145 (6): 772–87. https://doi.org/10.1037/xge0000165. Everett, Jim AC, David A. Pizarro, and Molly J. Crockett. 2016. “Inference of Trustworthiness from Intuitive Moral Judgments.” Journal of Experimental Psychology: General 145 (6): 772. Exley, Christine L. 2016. “Excusing Selfishness in Charitable Giving: The Role of Risk.” Review of Economic Studies. https://doi.org/10.1093/restud/rdv051. Exley, Christine L, and Ragan Petrie. 2018. “The Impact of a Surprise Donation Ask.” Journal of Public Economics. https://doi.org/10.1016/j.jpubeco.2017.12.015. Farmer, J Doyne, and John Geanakoplos. 2009. “Hyperbolic Discounting Is Rational: Valuing the Far Future with Uncertain Discount Rates.” Fetherstonhaugh, David, Paul Slovic, Stephen Johnson, and James Friedrich. 1997. “Insensitivity to the Value of Human Life: A Study of Psychophysical Numbing.” Journal of Risk and Uncertainty 14 (3): 283–300. https://doi.org/10.1023/A:1007744326393. Filiz-Ozbay, Emel, and Neslihan Uler. 2019. “Demand for Giving to Multiple Charities: An Experimental Study.” Journal of the European Economic Association 17 (3): 725–53. https://doi.org/10.1093/jeea/jvy011. Fiske, Alan P. 1992. “The Four Elementary Forms of Sociality: Framework for a Unified Theory of Social Relations.” Psychological Review 99 (4): 689. Fong, Christina, and Felix Oberholzer-Gee. 2010a. “Truth in Giving: Experimental Evidence on the Welfare Effects of Informed Giving to the Poor.” Journal of Public Economics. ———. 2010a. “Truth in Giving: Experimental Evidence on the Welfare Effects of Informed Giving to the Poor.” Journal of Public Economics. ———. 2010a. “Truth in Giving: Experimental Evidence on the Welfare Effects of Informed Giving to the Poor.” Journal of Public Economics. Fox, Craig R, Rebecca K Ratner, and Daniel S Lieb. 2005. “How Subjective Grouping of Options Influences Choice and Allocation: Diversification Bias and the Phenomenon of Partition Dependence.” Journal of Experimental Psychology: General 134 (4): 538. Friedrich, James, Paul Barnes, Kathryn Chapin, Ian Dawson, Valerie Garst, and David Kerr. 1999. “Psychophysical Numbing: When Lives Are Valued Less as the Lives at Risk Increase.” Journal of Consumer Psychology 8 (3): 277–99. https://doi.org/10.1207/s15327663jcp0803_05. Frumkin, Peter, and Mark T Kim. 2001. “Strategic Positioning and the Financing of Nonprofit Organizations: Is Efficiency Rewarded in the Contributions Marketplace?” Public Administration Review 61 (3): 266–75. Gneezy, Uri, Elizabeth A. Keenan, and Ayelet Gneezy. 2014. “Avoiding Overhead Aversion in Charity.” Science. https://doi.org/10.1126/science.1253932. Gordon, Teresa P, Cathryn L Knock, and Daniel G Neely. 2009. “The Role of Rating Agencies in the Market for Charitable Contributions: An Empirical Test.” Journal of Accounting and Public Policy 28 (6): 469–84. https://doi.org/10.1016/j.jaccpubpol.2009.08.001. Greaves, Hilary. 2017. “Discounting for Public Policy: A Survey.” Economics &amp; Philosophy 33 (3): 391–439. Harwell, Haley, Ph D Candidate, and Catherine Eckel. n.d. “Did the Ice Bucket Challenge Drain the Philanthropic Reservoir ?: Evidence from a Real-Donation Lab Experiment Version as of November 19 , 2015 DRAFT : DO NOT QUOTE WITHOUT AUTHORS ’ PERMISSION,” 1–37. Heckman, James J, and Rodrigo Pinto. 2015. “Econometric Mediation Analyses: Identifying the Sources of Treatment Effects from Experimentally Estimated Production Technologies with Unmeasured and Mismeasured Inputs.” Econometric Reviews 34 (September 2016): 6–31. https://doi.org/10.1080/07474938.2014.944466. Heyman, James, and Dan Ariely. 2004. “Effort for Payment: A Tale of Two Markets.” Psychological Science 15 (11): 787–93. Hoffman, Moshe, Erez Yoeli, and Martin A. Nowak. 2015. “Cooperate Without Looking: Why We Care What People Think and Not Just What They Do.” Proceedings of the National Academy of Sciences of the United States of America 112 (6): 1727–32. https://doi.org/10.1073/pnas.1417904112. Hsee, Christopher K, Jiao Zhang, Zoe Y Lu, and Fei Xu. 2013. “Unit Asking : A Method to Boost Donations and Beyond.” https://doi.org/10.1177/0956797613482947. Jamison, Julian, Dean Karlan, and Laura Schechter. 2008. “To Deceive or Not to Deceive: The Effect of Deception on Behavior in Future Laboratory Experiments.” Journal of Economic Behavior &amp; Organization 68 (3): 477–88. Jenni, Karen, and George Loewenstein. 1997. “Explaining the Identifiable Victim Effect.” Journal of Risk and Uncertainty 14 (3): 235–57. https://doi.org/10.1023/A:1007740225484. Jin, Ginger Zhe, and Alan T Sorensen. 2006. “Information and Consumer Choice: The Value of Publicized Health Plan Ratings.” Journal of Health Economics 25 (2): 248–75. Jordan, Jillian J., Moshe Hoffman, Martin A. Nowak, and David G. Rand. 2016. “Uncalculating Cooperation Is Used to Signal Trustworthiness.” Proceedings of the National Academy of Sciences of the United States of America 113 (31): 8658–63. https://doi.org/10.1073/pnas.1601280113. Kahane, Guy, Jim AC Everett, Brian D Earp, Lucius Caviola, Nadira S Faber, Molly J Crockett, and Julian Savulescu. 2018. “Beyond Sacrificial Harm: A Two-Dimensional Model of Utilitarian Psychology.” Psychological Review 125 (2): 131. Kahneman, Daniel. 2011. Thinking, Fast and Slow. Penguin Books. Kahneman, Daniel, Jack L Knetsch, and Richard H Thaler. 1986. “Fairness and the Assumptions of Economics.” Journal of Business, S285–S300. Kahneman, Daniel, and Amos Tversky. 1979. “Prospect Theory: An Analysis of Decision Under Risk.” Econometrica 47 (2): 263–91. https://doi.org/10.2307/1914185. Karlan, Dean, and Daniel H. Wood. 2017a. “The Effect of Effectiveness: Donor Response to Aid Effectiveness in a Direct Mail Fundraising Experiment.” Journal of Behavioral and Experimental Economics 66: 1–8. https://doi.org/10.1016/j.socec.2016.05.005. ———. 2017a. “The Effect of Effectiveness: Donor Response to Aid Effectiveness in a Direct Mail Fundraising Experiment.” Journal of Behavioral and Experimental Economics 66: 1–8. https://doi.org/10.1016/j.socec.2016.05.005. ———. 2017a. “The Effect of Effectiveness: Donor Response to Aid Effectiveness in a Direct Mail Fundraising Experiment.” Journal of Behavioral and Experimental Economics 66: 1–8. https://doi.org/10.1016/j.socec.2016.05.005. Kinsbergen, Sara, and Jochem Tolsma. 2013. “Explaining Monetary Donations to International Development Organisations: A Factorial Survey Approach.” Social Science Research 42 (6): 1571–86. https://doi.org/10.1016/j.ssresearch.2013.06.011. Kogut, Tehila, and Ilana Ritov. 2005a. “The ‘Identified Victim’ Effect: An Identified Group, or Just a Single Individual?” Journal of Behavioral Decision Making 18 (3): 157–67. https://doi.org/10.1002/bdm.492. ———. 2005b. “The Singularity Effect of Identified Victims in Separate and Joint Evaluations.” Organizational Behavior and Human Decision Processes 97 (2): 106–16. ———. 2011. “The Identifiable Victim Effect: Causes and Boundary Conditions.” The Science of Giving: Experimental Approaches to the Study of Charity, 133–45. Landry, Craig E, Andreas Lange, John A List, Michael K Price, and Nicholas G Rupp. 2010. “Is a Donor in Hand Better Than Two in the Bush? Evidence from a Natural Field Experiment.” American Economic Review 100 (3): 958–83. Lichtenstein, Sarah, Paul Slovic, Baruch Fischhoff, Mark Layman, and Barbara Combs. 1978. “Judged Frequency of Lethal Events.” Journal of Experimental Psychology: Human Learning and Memory 4 (6): 551. Linda, M, Not-for-profit Organizations, and Linda M Parsons. 2007. “The Impact of Financial Information and Voluntary Disclosures on Contributions to Not-for-Profit Organizations,” 179–96. Loewenstein, George, and Deborah A Small. 2007a. “The Scarecrow and the Tin Man : The Vicissitudes of Human Sympathy and Caring” 11 (2): 112–26. https://doi.org/10.1037/1089-2680.11.2.112. ———. 2007a. “The Scarecrow and the Tin Man : The Vicissitudes of Human Sympathy and Caring” 11 (2): 112–26. https://doi.org/10.1037/1089-2680.11.2.112. Macaskill, William. 2015. Doing Good Better. Guardian Books. Mayo, and Tinsley. 2009. “‘Warm Glow and Charitable Giving: Why the Wealthy Do Not Give More to Charity?’.” Meer, J. 2014. “Effects of the Price of Charitable Giving: Evidence from an Online Crowdfunding Platform.” Journal of Economic Behavior &amp; Organization. https://doi.org/10.1016/j.jebo.2014.04.010. Meer, Jonathan. 2011. “Brother, Can You Spare a Dime? Peer Pressure in Charitable Solicitation.” Journal of Public Economics 95 (7-8): 926–41. https://doi.org/10.1016/j.jpubeco.2010.11.026. ———. 2017. “Does Fundraising Create New Giving?” Journal of Public Economics 145: 82–93. https://doi.org/10.1016/j.jpubeco.2016.11.009. Metzger, Laura, and Isabel Günther. 2019a. “Making an Impact ? The Relevance of Information on Aid E Ff Ectiveness for Charitable Giving . A Laboratory Experiment.” Journal of Development Economics 136 (September 2018): 18–33. https://doi.org/10.1016/j.jdeveco.2018.08.015. ———. 2019b. “Making an Impact ? The Relevance of Information on Aid E Ff Ectiveness for Charitable Giving . A Laboratory Experiment.” Journal of Development Economics 136 (September 2018): 18–33. https://doi.org/10.1016/j.jdeveco.2018.08.015. ———. 2019c. “Making an Impact? The Relevance of Information on Aid Effectiveness for Charitable Giving. A Laboratory Experiment.” Journal of Development Economics 136: 18–33. Morewedge, Carey K, and Daniel Kahneman. 2010. “Associative Processes in Intuitive Judgment.” Trends in Cognitive Sciences 14 (10): 435–40. Mulesky, Suzie. 2020. “The Demand (or Lack Thereof) for Honest, Rigorous Impact Information in Charity.” Rigorous Impact Information in Charity (March 16, 2020). Null, C. 2011. “Warm Glow, Information, and Inefficient Charitable Giving.” Journal of Public Economics 95 (5-6): 455–65. https://doi.org/10.1016/j.jpubeco.2010.06.018. Ord, Toby. 2020. The Precipice: Existential Risk and the Future of Humanity. Hachette Books. Pollak, Robert A. 1969. “Conditional Demand Functions and Consumption Theory.” The Quarterly Journal of Economics 83 (1): 60–78. https://doi.org/10.2307/1883993. Portillo, Javier E, and Joseph Stinn. 2018. “Overhead Aversion: Do Some Types of Overhead Matter More Than Others?” Journal of Behavioral and Experimental Economics 72: 40–50. Press, Illinois. 2018. “The Direct Measurement of Utility and Subjective Probability Author ( S ): Eugene Galanter Source : The American Journal of Psychology , Vol . 75 , No . 2 ( Jun ., 1962 ), Pp . 208-220 Published by : University of Illinois Press Stable URL : http://www.js” 75 (2): 208–20. Read, Daniel, and George Loewenstein. 1995. “Diversification Bias: Explaining the Discrepancy in Variety Seeking Between Combined and Separated Choices.” Journal of Experimental Psychology: Applied 1 (1): 34. Reinstein, David. 2011. “Substitution Between (and Motivations for) Charitable Contributions: An Experimental Study.” Mimeo. Reinstein, David A. n.d. “Does One Charitable Contribution Come at the Expense of Another?” The BE Journal of Economic Analysis &amp; Policy 11 (1). Reinstein, David, and Christopher J Snyder. 2005. “The Influence of Expert Reviews on Consumer Demand for Experience Goods: A Case Study of Movie Critics.” Journal of Industrial Economics. https://doi.org/10.1111/j.0022-1821.2005.00244.x. Reinstein, D, G Riener, and C Kellner. 2018. “Commitments to Give-If-You-Win Exceed Donations After a Win.” Scharf, Kimberley, Sarah Smith, and Mark Ottoni-Wilhelm. 2017. “Lift and Shift: The Effect of Fundraising Interventions in Charity Space and Time.” https://doi.org/10.1920/wp.ifs.2017.W1720. Schelling, Thomas C. 1968. “The Life You Save May Be Your Own.” Problems in Public Expenditure, 127–62. Schmitz, Jan. 2019. “Temporal Dynamics of Pro-Social Behavior: An Experimental Analysis.” Experimental Economics 22 (1). https://doi.org/10.1007/s10683-018-9583-2. ———. n.d. “Inter-Charity Competition for Individuals ’ Contributions- Experimental Testing of Substitution- , Complementary- , and Crowding Out Effects,” no. January 2013. Schubert, Stefan. 2020. “The Focus of Collective Attention and the Long-Run Future.” Stefan Schubert. https://stefanfschubert.com/blog/2020/7/24/the-focus-of-collective-attention-and-the-long-run-future. Shrout, Patrick E, and Joseph L Rodgers. 2018. “Psychology, Science, and Knowledge Construction: Broadening Perspectives from the Replication Crisis.” Annual Review of Psychology 69: 487–510. Simler, Kevin, and Robin Hanson. 2017. The Elephant in the Brain: Hidden Motives in Everyday Life. Oxford University Press. Slovic, Paul. 2007. “Psychic Numbing and Genocide: (718332007-003).” American Psychological Association. https://doi.org/10.1037/e718332007-003. Slovic, Paul, Baruch Fischhoff, and Sarah Lichtenstein. 1981a. “Perceived Risk: Psychological Factors and Social Implications.” Proceedings of the Royal Society of London. A. Mathematical and Physical Sciences 376 (1764): 17–34. ———. 1981b. “Rating the Risks.” In Risk/Benefit Analysis in Water Resources Planning and Management, 193–217. Springer. Small, Deborah A. 2010. “Reference-Dependent Sympathy.” Organizational Behavior and Human Decision Processes 112 (2): 151–60. Small, Deborah A, and George Loewenstein. 2003. “Helping a Victim or Helping the Victim: Altruism and Identifiability.” Journal of Risk and Uncertainty 26 (1): 5–16. https://doi.org/10.1023/A:1022299422219. Small, Deborah A, George Loewenstein, and Paul Slovic. 2007. “Sympathy and Callousness: The Impact of Deliberative Thought on Donations to Identifiable and Statistical Victims.” Organizational Behavior and Human Decision Processes 102 (2): 143–53. Smeets, Paul, Rob Bauer, and Uri Gneezy. 2015. “Giving Behavior of Millionaires.” Proceedings of the National Academy of Sciences 112 (34): 10641–4. Spence, C. 2006. “Mismatching Money and Need.” Stanford Social Innovation Review 4 (1). Spence, M. 1973. “Job Market Signaling.” Quarterly Journal of Economics 87 (3): 355–74. https://doi.org/10.2307/1882010. Steinberg. 1986. “\"Should Donors Care About Fundraising.\".” Sudhir, K, Subroto Roy, and Mathew Cherian. 2016. “Do Sympathy Biases Induce Charitable Giving? The Effects of Advertising Content.” Marketing Science 35 (6): 849–69. https://doi.org/10.1287/mksc.2016.0989. Summers, C, P Slovic, D Hine, and D Zuliani. 1994. “‘Psychophysical Numbing’: An Empirical Basis for Perceptions of Collective Violence.” Collective Violence: Harmful Behavior in Groups and Governments. Tinkelman, Daniel. 1998. “Differences in Sensitivity of Financial Statement Users to Joint Cost Allocations: The Case of Nonprofit Organizations.” Journal of Accounting, Auditing &amp; Finance 13 (4): 377–93. “Top Charities.” n.d. GiveWell. https://www.givewell.org/charities/top-charities. Trussel, John M, and Linda M Parsons. 2007. “Financial Reporting Factors Affecting Donations to Charitable Organizations.” Advances in Accounting 23: 263–85. Tversky, A, and D Kahneman. 1991. “Loss Aversion in Riskless Choice: A Reference-Dependent Model.” The Quarterly Journal of Economics 106 (4): 1039–61. https://doi.org/10.2307/2937956. Tversky, Amos, and Daniel Kahneman. 1973. “Availability: A Heuristic for Judging Frequency and Probability.” Cognitive Psychology 5 (2): 207–32. Ubel, Peter A, Michael L DeKay, Jonathan Baron, and David A Asch. 1996. “Cost-Effectiveness Analysis in a Setting of Budget ConstraintsIs It Equitable?” New England Journal of Medicine 334 (18): 1174–7. “U.S. Charitable Giving Tops $400 Billion for First Time.” n.d. https://www.cbsnews.com/news/u-s-charitable-giving-tops-400-billion-for-first-time/. van Iwaarden, Jos, Ton Van Der Wiele, Roger Williams, and Claire Moxham. 2009. “Charities: How Important Is Performance to Donors?” International Journal of Quality &amp; Reliability Management. Vesterlund, L. 2003. “The Informational Value of Sequential Fundraising.” Journal of Public Economics. Weitzman, Martin L. 1998. “Why the Far-Distant Future Should Be Discounted at Its Lowest Possible Rate.” Journal of Environmental Economics and Management 36 (3): 201–8. Yörük, Barış K. 2009. “How Responsive Are Charitable Donors to Requests to Give?” Journal of Public Economics 93 (9-10): 1111–7. https://doi.org/10.1016/J.JPUBECO.2009.06.001. Yörük, B K. 2016. “Charity Ratings.” Journal of Economics &amp; Management Strategy. https://doi.org/10.1111/jems.12139. Zweig, Jason. 1998. “Five Investing Lessons from America’s Top Pension Fund.” Money 27 (1): 115–88. "]
]
