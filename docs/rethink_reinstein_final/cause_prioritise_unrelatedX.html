<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Cause prioritization research: fundamental considerations vs. intervention effectiveness: task for Rethink Priorities</title>
  <meta name="description" content="Cause prioritization research: fundamental considerations vs. intervention effectiveness: task for Rethink Priorities" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Cause prioritization research: fundamental considerations vs. intervention effectiveness: task for Rethink Priorities" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Cause prioritization research: fundamental considerations vs. intervention effectiveness: task for Rethink Priorities" />
  
  
  

<meta name="author" content="David Reinstein" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  


<script src="book_assets/header-attrs-2.3/header-attrs.js"></script>
<script src="book_assets/jquery-2.2.3/jquery.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="book_assets/accessible-code-block-0.0.1/empty-anchor.js"></script>



<link rel="stylesheet" href="support/tufte_plus.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path=""><a href="#prioritizing-prioritization-research-in-global-poverty-crucial-considerations-vs.-understanding-intervention-effectiveness"><i class="fa fa-check"></i><b>1</b> Prioritizing prioritization research in global poverty: Crucial considerations vs. understanding intervention effectiveness</a></li>
<li class="chapter" data-level="2" data-path=""><a href="#crucial-def"><i class="fa fa-check"></i><b>2</b> Crucial Considerations Research (“CCR”) in global poverty research - definition and examples</a>
<ul>
<li class="chapter" data-level="" data-path=""><a href="#a.-conceptual-and-philosophical-questions"><i class="fa fa-check"></i>A. Conceptual and philosophical questions</a></li>
<li class="chapter" data-level="" data-path=""><a href="#b.-big-empirical-questions-some-examples"><i class="fa fa-check"></i>B. ‘Big’ empirical questions (some examples)</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path=""><a href="#crucial-considerations-what-the-best-ea-funded-additional-research-could-achieve"><i class="fa fa-check"></i><b>3</b> Crucial considerations: what the best (EA-funded, additional) research could achieve</a></li>
<li class="chapter" data-level="4" data-path=""><a href="#some-examples-of-ccr-work-considering-neglectedness"><i class="fa fa-check"></i><b>4</b> Some examples of CCR work; considering ‘neglectedness’</a>
<ul>
<li class="chapter" data-level="4.1" data-path=""><a href="#existing-funding"><i class="fa fa-check"></i><b>4.1</b> Existing funding</a></li>
<li class="chapter" data-level="4.2" data-path=""><a href="#successes-and-limitations"><i class="fa fa-check"></i><b>4.2</b> Successes and limitations</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path=""><a href="#ier-def"><i class="fa fa-check"></i><b>5</b> Intervention Effectiveness Research (henceforth ‘IER’): Definition and examples</a>
<ul>
<li class="chapter" data-level="5.1" data-path=""><a href="#successses-and-limitations-what-the-best-ea-funded-additional-research-could-achieve"><i class="fa fa-check"></i><b>5.1</b> Successses and limitations: What the best (EA-funded, additional) research could achieve</a></li>
<li class="chapter" data-level="5.2" data-path=""><a href="#existing-funding-and-evidence"><i class="fa fa-check"></i><b>5.2</b> Existing funding and evidence</a>
<ul>
<li class="chapter" data-level="" data-path=""><a href="#underover-funded-from-an-ea-perspective"><i class="fa fa-check"></i>Under/over-funded from an EA perspective?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path=""><a href="#best"><i class="fa fa-check"></i><b>6</b> Recommmendation: EA-focused ‘Evaluation, communication, and sensitivity testing of intervention effectiveness work’</a>
<ul>
<li class="chapter" data-level="" data-path=""><a href="#meta-analysis-and-robustness-checking"><i class="fa fa-check"></i>1. Meta-analysis and robustness checking</a></li>
<li class="chapter" data-level="" data-path=""><a href="#translation-communication-and-tailoring-work"><i class="fa fa-check"></i>2. Translation, communication, and tailoring work</a></li>
<li class="chapter" data-level="" data-path=""><a href="#extending-and-interpreting-work-beyond-the-narrow-statistical-significance-and-academic-reporting"><i class="fa fa-check"></i>3. Extending and interpreting work beyond the ‘narrow statistical significance’ and academic reporting</a></li>
<li class="chapter" data-level="6.1" data-path=""><a href="#existing-workunderfunding"><i class="fa fa-check"></i><b>6.1</b> Existing work/(under)funding?</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path=""><a href="#limitations"><i class="fa fa-check"></i><b>7</b> Overall considerations and limitations; next steps</a></li>
<li class="chapter" data-level="" data-path=""><a href="#works-cited"><i class="fa fa-check"></i>Works cited</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Cause prioritization research: fundamental considerations vs. intervention effectiveness: task for Rethink Priorities</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">Cause prioritization research: fundamental considerations vs. intervention effectiveness: task for Rethink Priorities</h1>
<p class="author"><em>David Reinstein</em></p>
<p class="date"><em>8/23/2020</em></p>
</div>
<script type="text/javascript">
$(document).ready(function() {
  $folds = $(".fold");
  $folds.wrapInner("<div class=\"fold-blck\">"); // wrap a div container around content
  $folds.prepend("<button class=\"fold-btn\">Unfold</button>");  // add a button
  $(".fold-blck").toggle();  // fold all blocks
  $(".fold-btn").on("click", function() {  // add onClick event
    $(this).text($(this).text() === "Fold" ? "Unfold" : "Fold");  // if the text equals "Fold", change it to "Unfold"or else to "Fold"
    $(this).next(".fold-blck").toggle("linear");  // "swing" is the default easing function. This can be further customized in its speed or the overall animation itself.
  })
});
</script>
<div id="prioritizing-prioritization-research-in-global-poverty-crucial-considerations-vs.-understanding-intervention-effectiveness" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Prioritizing prioritization research in global poverty: Crucial considerations vs. understanding intervention effectiveness</h1>
<p>Suppose an EA-aligned donor has donated 1M USD to be used strictly for ‘global poverty prioritization’ research – research to help us understand <em>where</em> to allocate money – within the global poverty domain.</p>
<div class="marginnote">
<p>I will mostly ignore the question of cross-domain allocation here.</p>
</div>
<p>Should we spend this funding on:</p>
<ol style="list-style-type: decimal">
<li>…research into <strong>fundamental ‘crucial considerations’</strong>— philosophical and ‘big empirical’ questions that could overturn our basic calculus (definitions and examples <a href="#crucial-def">below</a>),</li>
</ol>
<p>… or should we put it into</p>
<ol start="2" style="list-style-type: decimal">
<li>research into the <strong>effectiveness of specific interventions</strong> research (also defined/detailed <a href="#ier-def">below</a>)?</li>
</ol>
<p>In this post, I evaluate the case for each of these. I consider the benefits of such research in terms of its affect on the desired outcome: improvement in ‘the appropriate measure of global welfare in this domain.’</p>
<div class="marginnote">
<p>Note: I may want to think more about how to evaluate this question itself considering our current uncertainty about what that appropriate measure is.</p>
</div>
<p>I focus on the impact of the research on the <em>poverty/welfare outcome.</em> The main causal channel I propose: prioritization research will yield a better understanding of the long-term effectiveness of different interventions, as well as a better understanding of ‘what we should care about in terms of these outcomes’. This in turn should lead to a better allocation of philanthropic and other resources (e.g., political influence).</p>
<div class="marginnote">
<p>There may also be side benefits; e.g., less uncertainty and better explanations might lead to less self-serving reasoning and thus greater philanthropy.</p>
</div>
<p>I consider the above question loosely following the <a href="https://concepts.effectivealtruism.org/concepts/importance-neglectedness-tractability/">‘importance, tractability, and neglectedness’</a> framework as a reasonable starting heuristic.</p>
<p><br />
</p>
<div class="marginnote">
<p>If I were to pursue this further, I would aim for more explicit quantification.</p>
</div>
<p><font color='gray'>Aside: There may be a trade-off between ‘the research that leads to EAs (or the general population) actually doing the most good’ … and ‘the research that will lead to the most certainty and feeling of confidence that we know how to do the most good’. For example, two interventions may be roughly equivalent in terms of outcomes, and <em>knowing this</em> would not drive a better outcome. Our intuitive perception of the ‘decision-making value of certainty’ may also differ from the actual value. We should watch out for our own self-serving bias towards the ‘greater certainty’ research.</font></p>
<p>(For a summary of my key findings and arguments, as well as caveats and limitations, please jump to the <a href="#best">recommendation</a> and <a href="#conclusion">conclusion</a> sections.</p>
</div>
<div id="crucial-def" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Crucial Considerations Research (“CCR”) in global poverty research - definition and examples</h1>
<p>I begin with Nick Bostrom’s definition<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<blockquote>
<p>Within a utilitarian context … a crucial consideration is a consideration that radically changes the expected value of pursuing some high-level subgoal.</p>
</blockquote>
<p>I flesh this out, dividing this (broadly) as research into <em>A. conceptual/philosophical questions</em> and <em>B. ‘big’ empirical questions</em>.</p>
<div id="a.-conceptual-and-philosophical-questions" class="section level2 unnumbered" number="">
<h2>A. Conceptual and philosophical questions</h2>
<p><em>How</em> can we define and evaluate</p>
<ol style="list-style-type: decimal">
<li><p>the outcomes of value (in this domain), and the trade-offs between outcomes of value that seem to fall in very distinct spheres,</p></li>
<li><p>the impact of ‘known uncertain interventions’,</p>
<div class="marginnote">
<p>This is distinct from Intervention Effectiveness research: Point 2 instead asks “how shall we consider the relative value of two distinct interventions given the evidence we have on the entire (subjective) probability distribution over the results of these interventions?”</p>
</div></li>
<li><p>the ‘means to an end’ employed (also considering deontological concerns)?</p></li>
</ol>
<p><br />
</p>
<p>More specific philosophical CCR questions in the poverty domain include (approximately corresponding to the same question categories 1-3):</p>
<ol style="list-style-type: decimal">
<li>What are reasonable ways to value human welfare, potentially trading off average consumption/health against a more unequal distribution? How should we put a value on an intervention that leads to more (or fewer) ‘net-positive-life’ people being born? (Population ethics).</li>
</ol>
<ul>
<li><p>… Is it possible to measure and weigh one person’s suffering against another? How can we consider the value of lives improved at different ages (e.g., young people versus the elderly)?</p></li>
<li><p>How should we evaluate and assess human gains against potentially negative indirect consequences of economic development (e.g., increased factory farming and reduced animal welfare)?</p></li>
</ul>
<div class="marginnote">
<p>While this post considers <em>only</em> the prioritization <em>among</em> global poverty interventions and organisations, the tradeoff with other cause areas may inform this choice. For example, certain poverty interventions might be expected to lead to greater meat consumption than others.</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li><p>(How) should we value a certain outcome versus a higher-expected value uncertain outcome? How should we consider Knightian uncertainty (aka ambiguity)? How can we consider the value of long-term systemic change relative to concrete individual lives improved?</p></li>
<li><p>Is it justifiable to promote policies and research programs that we know will harm some individuals if we anticipate that the net effect will be positive?</p></li>
</ol>
</div>
<div id="b.-big-empirical-questions-some-examples" class="section level2 unnumbered" number="">
<h2>B. ‘Big’ empirical questions (some examples)</h2>
<p>CCR also includes ‘big’ empirical questions. These reflect massive deep issues, whose resolution will massively reshape our ‘direction of travel’, altering consideration of the effectiveness of general approaches to interventions and evidence.</p>
<div class="marginnote">
<p>I believe this clearly falls in the category of “crucial considerations work” in this domain. However, I am sure whether these would be considered “<em>fundamental</em> questions.”</p>
</div>
<p>Some frequently-discussed ‘big empirical’ questions:</p>
<ol start="4" style="list-style-type: decimal">
<li><p>Should we expect that funds devoted towards systemic change (e.g., lobbying for pro-growth policies <a href="https://forum.effectivealtruism.org/posts/bsE5t6qhGC65fEpzN/growth-and-the-case-against-randomista-development">as advocated by Halstead and Hillebrandt and others</a>) will be more effective than individual health interventions?</p></li>
<li><p>Will longer-term interventions (and the long-term impact of interventions) overwhelm more measurable, short and medium-term effects?</p></li>
</ol>
<p>Some ‘big empirical’ questions I find interesting:</p>
<ol start="6" style="list-style-type: decimal">
<li><p>Are large charities such as Oxfam and MSF more successful at cultivating long-term support and infrastructure for pro-poor policies among mainstream audiences, even if individual interventions are less efficient?</p></li>
<li><p>(How) does charitable giving crowd-out or crowd-in government spending on similar causes (both considering international aid and domestic spending by poor country governments)</p></li>
</ol>
</div>
</div>
<div id="crucial-considerations-what-the-best-ea-funded-additional-research-could-achieve" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Crucial considerations: what the best (EA-funded, additional) research could achieve</h1>
<p>CCR offers a great deal of potential and would seem to be ideally suited for EA funding. Most of the above issues are still widely debated among the EA community and of the larger society (including in debates with EA skeptics).</p>
<p>The population ethics question is not only relevant for the “current global poverty versus long-termism” allocation issue, but also <em>within</em> this domain in highly-impactful ways. It informs the choice to ‘save lives vs. reduce suffering’, as well as between programs and interventions believed to boost population and encourage fertility, and those that do the opposite</p>
<div class="marginnote">
<p>Time-permitting, I would back this up with specific examples and research backed numbers. I believe the argument (<a href="https://forum.effectivealtruism.org/posts/3h3mscSSTwGs6qbei/givewell-s-charity-recommendations-require-taking-a">made here - (I skimmed)</a> is that the AMF, by saving the lives of children, makes it less likely that parents will have a additional child to replace the child who died. From a total-population ethics view, the 35 life years added from saving the child is considered an overstated benefit.</p>
</div>
<p>However, as I argue below, I do not anticipate that research into philosophical questions like this one will prove particularly fruitful in terms of outcome-driven prioritization benefits.</p>
</div>
<div id="some-examples-of-ccr-work-considering-neglectedness" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Some examples of CCR work; considering ‘neglectedness’</h1>
<p>The <em>philosophical</em> questions have (unsurprisingly) been a principally dealt with by philosophers; economic theorists and mathematicians have also played an important role. Researchers at the <a href="https://globalprioritiesinstitute.org/">GPI</a> (e.g., Hilary Greaves) have taken on many of these questions. I believe that this research has been conducted with somewhat of an explicit moral-utilitarian and EA-aligned perspective. They (seem to) have specifically focused on questions in decision theory involving long-termism/’discounting, and the reasonableness of specific decision criteria in <a href="https://globalprioritiesinstitute.org/christian-tarsney-exceeding-expectations-stochastic-dominance-as-a-general-decision-theory/">general decision-theory</a> and <a href="https://globalprioritiesinstitute.org/andreas-mogensen-maximal-cluelessness/">with a (long-termist) EA perspective</a>.</p>
<p>I believe that GPI’s work supplements a larger range of (prior and present) work in these disciplines as a whole, e.g.,Google Scholar records nearly 3000 papers with the phrase ‘population ethics,’ such as
<a href="https://www.jstor.org/stable/2171771?casa_token=6oG1TquJOPIAAAAA:IHFr96wgi4DPoty5NxgCja5dHmGerMRIPU6Ppy0mdUdd_bYNzTHPv916DS7eKguLsP-d4kmszKa8dlt92tZH5XmHOQaPaDtm1M2Tv7kutyKihScTEjQ">Blackorby et al “Intertemporal population ethics: critical-level utilitarian principles.” Econometrica, 1995</a></p>
<p>The reasonableness, consistency and use of a ‘Social welfare function’ for weighing outcomes between individuals (and with uncertainty, and over time…) has long been a core topic in Economics, particularly in microeconomic theory and public economics/public choice. A Google Scholar search for ‘“welfare functions” distribution poverty’; yields nearly 10,000 results, including papers such as “Poverty: An ordinal approach to measurement” <span class="citation">(Sen <a href="#ref-senPovertyOrdinalApproach1976" role="doc-biblioref">1976</a>)</span>.</p>
<div class="marginnote">
<p>Further work here would involve a more careful and well-defined search using filtering tools offered by the web of science, and diving into the Economic literature, starting with the Journal of Economic Perspectives, and with the discussion of Sen’s work following his Nobel prize.</p>
</div>
<p>Considering the ‘big empirical’ CCR questions, many broad issues involving paths to systemic change and the impact of aid on government policy have been long studied by development economists, political economists, political scientists, policy analysts, and others. However, I believe that some important questions in this domain remain under-researched. In my own research I have focused substantially on the issue <a href="https://www.degruyter.com/view/journals/bejeap/11/1/article-bejeap.2011.11.1.2487.xml.xml">‘Does one charitable contribution come at the expense of another?’</a>, and I put together a range of broad database of articles on ‘motivating charitable giving’ (see <a href="innovationsinfundraising.org">here</a>; access to more updated Airtable is available by request). However, while the “crowding out effect” of government expenditure and private charity is a well studied issue, I have seen little research on crowding out in the opposite direction.</p>
<div class="marginnote">
<p>Only a small amount of recent work, see <a href="https://www.nber.org/papers/w26928">Deserrano et al, 2020</a> and <a href="https://www.sciencedirect.com/science/article/pii/S0165176518302696?casa_token=3DRFqgnoxCoAAAAA:Jag61hc7VrPHQJXZ87Z_hHFIl7UyOxKJ3JMKlM1u7ku8_wOSwEJWK0xbgiFZXQnc0AmZoaCJZA">Werfel, 2018</a>)]</p>
</div>
<p><br />
</p>
<div id="existing-funding" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Existing funding</h2>
<div class="marginnote">
<p>I put this text in gray because I consider this simply to be my proposed next steps.</p>
</div>
<p><font color='grey'>We should consider the amounts of funding devoted to this category of work, both directly and indirectly. These numbers may be foundwithin the ‘EA-sphere’; we can consider the amounts allocated to organizations like GPI, the Open Philanthropy Project, and Founders pledge, and the share of these specifically addressing the aforementioned philosophical questions. I would also consider (perhaps looking on ResearchGate, Web of Science, and Google Scholar), the number of academic philosophers, economists, and others specifically listing particularly relevant keywords as central to their research.</font></p>
</div>
<div id="successes-and-limitations" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Successes and limitations</h2>
<p><em>Successes</em></p>
<p><font color='grey'>I would next discuss some of the successes of this research in providing theoretical backgrounds to these thorny problems and in changing peoples minds particularly in the EA movement. I would also consider historical successes in bringing meaningful frameworks to ethical issues and changing peoples minds on these ethical issues. I suspect that there will be little ‘hard evidence’ on this and the discussion here would be largely anecdotal.</font></p>
<p><em>Limitations</em></p>
<p>With respect to the population ethics question I find it highly unlikely that we will gain an answer that convinces many people to substantially switch their positions. I doubt that the research will convince a large majority of philosophers and experts in one direction. The evidence (on a range of questions not including this one) from the recent <a href="https://philpapers.org/surveys/#:~:text=The%20PhilPapers%20Survey%20was%20a,carried%20out%20in%20November%202009.&amp;text=The%20Metasurvey%20was%20taken%20by,and%20210%20philosophy%20graduate%20students">“philosopher’s survey”</a> <span class="citation">(“David Bourget &amp; David J. Chalmers, What Do Philosophers Believe? - PhilPapers,” <a href="#ref-DavidBourgetDavid" role="doc-biblioref">n.d.</a>)</span> is not encouraging in this regard.</p>
<p>I see more value in providing tailored calculations and answers to the “how to do the most good” question that allows people to input their own values for particular outcomes. I discuss this further <a href="#best">below</a>.</p>
<p>Further work should expand the discussion of successes and limitations of the population issue, as well as a similar discussion of other key issues. In particular, I would focus on the successes and limitations to research into the empirical questions raised in <a href="https://forum.effectivealtruism.org/posts/bsE5t6qhGC65fEpzN/growth-and-the-case-against-randomista-development#Summary">Hauke Hilebrand’s post</a>. (Unfold for further discussion of this issue.)</p>

<div class="fold">
<p>Here, in particular, I would focus on the evidence (and the potential pathways to evidence) on <em>how</em> to affect policy changes in poor countries, as well as in trade and immigration policies of wealthy countries, and the cost-effectiveness of this. This ‘potential for influence’ may be a promising avenue to explore. (I would not focus on research into “do we know what the best economic policies are” in general; this has been studied extensively for centuries, and is studied but roughly half of all Economists and related policymakers at universities and NGO’s throughout the world.)</p>
</div>
</div>
</div>
<div id="ier-def" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Intervention Effectiveness Research (henceforth ‘IER’): Definition and examples</h1>
<p>The most prominent category of IER, for our purposes, is the ‘randomized controlled trials’ (RCTs) on particular interventions in poor countries. These are now the bread-and-butter of development economists, and this has been acknowledged in a recent Nobel prize. <code>malaria bednets rct</code> yields over 6000 Google Scholar hits, with papers such as “Micro-loans, insecticide-treated bednets, and malaria: evidence from a randomized controlled trial in Orissa, India”
<span class="citation">(Tarozzi et al. <a href="#ref-tarozziMicroloansInsecticidetreatedBednets2014" role="doc-biblioref">2014</a>)</span>.</p>
<div id="successses-and-limitations-what-the-best-ea-funded-additional-research-could-achieve" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Successses and limitations: What the best (EA-funded, additional) research could achieve</h2>
<p>It seems likely that this research has led to large concrete benefits in terms of targeting aid and philanthropy. Some programs have been found to be surprisingly effective; others surprisingly ineffective (see <span class="citation">Duflo (<a href="#ref-dufloFieldExperimentsPractice2020" role="doc-biblioref">2020</a>)</span> for a partial review.)</p>
<p>This research has enabled careful measurements of specific interventions in a wide variety of environments, with careful control and treatment groups. These have also measured a variety of medium term and indirect outcomes on individual welfare, and even considered direct versus network effects.</p>
<p>However, unresolved questions remain, as well as reason for skepticism about the robustness of these results. The overall long-term benefit of <a href="https://journals.plos.org/plosntds/article?id=10.1371/journal.pntd.0006940">different types of de-worming interventions is hotly debated</a> <span class="citation">(Majid, Kang, and Hotez <a href="#ref-majidResolvingWormWars2019" role="doc-biblioref">2019</a>)</span>.</p>
<p>There are also strong concerns that:</p>
<ol style="list-style-type: decimal">
<li>Publication bias and ‘p-hacking’ have lead the scientific record to overstate the impacts of interventions</li>
</ol>
<p>Further work here should discuss and define publication bias and p-hacking in more detail. (Unfold for more discussion.)</p>

<div class="fold">
In pursuing this further, I would consider the extent that these issues are particularly relevant for development RCT work. I would discuss the progress that has been made in addressing these problems; this includes public pre-registration and sharing of RCT data to enable meta-analysis. It also includes new methods and tools to diagnose and ‘correct’ for p-hacking and publication bias (e.g., p-curves, researcher degrees of freedom corrections; I collect some of these resources <a href="https://airtable.com/shrqNt0YAa3eLiK5S">here</a>)
</div>
<ol start="2" style="list-style-type: decimal">
<li>“Limited generalizability”: Results from particular trials of interventions may not carry over into other contexts, or into larger scale programs</li>
</ol>
<p>These concerns are highlighted in the <a href="https://pubs.aeaweb.org/doi/pdf/10.1257/aer.p20151015">work of Eva Vivalt</a> <span class="citation">(Vivalt <a href="#ref-vivaltHeterogeneousTreatmentEffects2015a" role="doc-biblioref">2015</a>)</span>; [larger working paper](<a href="http://repositorio.minedu.gob.pe/bitstream/handle/123456789/4623/How%20Much%20Can%20We%20Generalize%20from%20Impact%20Evaluations.pdf?sequence=1" class="uri">http://repositorio.minedu.gob.pe/bitstream/handle/123456789/4623/How%20Much%20Can%20We%20Generalize%20from%20Impact%20Evaluations.pdf?sequence=1</a>] <span class="citation">(Vivalt <a href="#ref-vivaltHowMuchCan2016" role="doc-biblioref">2016</a>)</span>. Her Bayesian meta-analysis of roughly 600 papers found (in some reports) a study-to-study effect size heterogeneity with a standard error roughly equal to the median reported effect sizes. She also notes:</p>
<blockquote>
<p>systematic variation in effect sizes that is surprisingly robust across different interventions and outcomes</p>
</blockquote>
<blockquote>
<p>Government-implemented programs also had smaller effect sizes than academic/NGO-implemented programs, even after controlling for sample size.</p>
</blockquote>
</div>
<div id="existing-funding-and-evidence" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Existing funding and evidence</h2>
<p>This discussion should be supplemented by a deep dive into measuring the amount spent on RCTs in development research worldwide. (Unfold for next steps…)</p>

<div class="fold">
<p>I could consider the amount of grant funding, looking in detail at budgets of organizations such as USAID and DFiD. I believe that a substantial component of ODA is now funneled through RCTs. I would also go to the Web of Science to get a measure of the number of researchers listing ‘randomised controlled trials’ and ‘development’ among their interests.</p>
</div>
<p>We should next consider the cost effectiveness of money put into RCTs in terms of changing giving and aid strategies in ways that save lives. This would be challenging; we might be able to cherry pick a particular studies that seems to change thinking dramatically and attribute all the benefits to these, but this would clearly be overstating the average benefit/cost of research.</p>
<div class="marginnote">
<p>Before pursuing an original analysis here, I would look to the literature, both in Economics, in EA, and from NGO’s and governments examining the question “are we funding development RCT’s enough?”</p>
</div>
<div id="underover-funded-from-an-ea-perspective" class="section level3 unnumbered" number="">
<h3>Under/over-funded from an EA perspective?</h3>
<p>As I suggest above, there is already a great deal of existing funding for research into the efficacy of specific health interventions (and other individual poverty interventions involving migration and education). The EA community has also directly funded these RCTs, including <a href="https://www.openphilanthropy.org/giving/grants">millions of dollars in grants from Open Philanthropy</a>.</p>
<p>Should we expect this to be underfunded/neglected from an EA perspective? In some ways, the incentives may seem well aligned for government development officers, and NGOs, to fund this work in ways that will determine the most effective interventions for improving human welfare. However:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Governments</strong> supporting development may have particular political and strategic incentives that do diverge with the welfare of people with certain countries.</p></li>
<li><p><strong>NGOs and charities funding this research may have goals (both in terms of human welfare</strong> and in terms of organisational success) that do not fully align with common EA principles (e.g., considering marginality, cause-neutrality, moral utilitarianism).</p></li>
</ol>
<p><br />
</p>
<ol start="3" style="list-style-type: decimal">
<li><strong>Academia</strong></li>
</ol>
<p>What about academics, particularly Development Economists? Given “tournament” incentives in academia, and incentives to publish work for the purposes of career progression we might even imagine an ‘oversupply’ of studies in this area are more than necessary. However, academic incentives are also not fully aligned with scientific progress, and perhaps even less aligned with promoting good outcomes in an EA sense. The (so-called) ‘randomista’ emphasis on measurable benefit cost outcomes is actually rather new and often criticized in our profession. Economists have been particular rewarded for connecting their work to elegant theoretical models of human behavior that relate to classical economics, for making advances in techniques and metrics (that do not always correspond to advances in results), and in general for ‘innovating and being the first to discover something.’ We also generally adopt a ‘frequentist’ statistical framework, and publish ‘strongly significant results’, sometimes prioritizing (apparent) scientific precision over informative information (in a ‘Bayesian updating’ sense.)</p>
<p>I believe we <em>neglect</em> and <em>fail</em> to reward (with ‘top publications’ <span class="math inline">\(\rightarrow\)</span> career progression):</p>
<ul>
<li>work that revisits earlier work, carefully checking data and assumptions to reconsider and refine estimates in economically meaningful ways,</li>
<li>adjusting one’s previous work (once published) to maintain it’s currency, incorporate methodological developments, and correct errors</li>
<li>meta-analysis and careful synthesis of previous work,</li>
<li>sharing of data and code to foster future work by other academics and professionals,</li>
<li>translating our work and providing tools that policymakers, NGOs, and donors/charities can employ fruitfully.</li>
</ul>
<p>Thus, I suspect that ‘standard RCTs and economic development work’ may be adequately funded. However, I believe that EA funding (perhaps working together Open Science organisations) may be productive in shaping this research (and it’s dissemination, use, and evaluation) in ways that substantially improve the allocation of resources (from an EA perspective.)</p>
</div>
</div>
</div>
<div id="best" class="section level1" number="6">
<h1><span class="header-section-number">6</span> Recommmendation: EA-focused ‘Evaluation, communication, and sensitivity testing of intervention effectiveness work’</h1>
<p>Overall, I suspect that using these funds for a certain type of ‘intervention effectiveness research’ (interlaced with communication work), will be the most effective. Admittedly, this work will <em>build on</em> some crucial considerations work.</p>
<p>Although I am ambivalent towards EA’s directly funding “more RCT work”, I see a stronger case for funding several mutually-compatible initiatives:</p>
<div id="meta-analysis-and-robustness-checking" class="section level2 unnumbered" number="">
<h2>1. Meta-analysis and robustness checking</h2>
<p>We have reasons to be carefully skeptical of the robustness and generalizability of some of these results. In particular, calculations done by GiveWell and ImpactMatters depend crucially of particularly relevant ‘estimated parameters’ of this RCT work (as well as on other parameters that have been less carefully studied, such as the displacement of government funds). These judgement of ‘which is the most effective charity’ also depend on personal ethical parameters (population ethics, the value of life versus suffering, long-termism/discounting, etc.) in ways that may yield even <em>greater</em> sensitivity to the estimates.</p>
Meta-analysis, in the mold of Eva Vivalt’s AidGrade, can meaningfully address these questions. However, AidGrade itself has little funding; thus it not been updated for years, it is very narrowly targeted, it doesn’t incorporate ‘sensitivity to ethical parameters’.
<div class="marginnote">
<p>Their proposed ‘portfolio’ builder hints at this, but it has not been built</p>
</div>
<p>Furthermore, it has not yet found ways to become a <em>collaborative</em> project, engaging the academic and policy community to dynamically consider and adjust to new information and critiques. (However, Eva’s work on prediction markets goes somewhat in this direction.)</p>
<p>The Open-Science movement (e.g., OSF and the Franklin Fetzer fund) is already eager to find this sort of work, but it’s funds are divided over many fields and approaches. If EA money could correctly leverage and steer these funds (rather than displace them) this could yield great value per dollar.</p>
</div>
<div id="translation-communication-and-tailoring-work" class="section level2 unnumbered" number="">
<h2>2. Translation, communication, and tailoring work</h2>
<p>As I note above, I find it unlikely that philosophical work will meaningfully resolve deep ethical questions.</p>
<p>However, I see untapped value in providing tailored calculations and answers to the “how to do the most good” questions. This should allow people to input their own values for particular outcomes caused/averted, in terms of population, suffering, and other key values. This will improve our allocation of funds, considering our own goals. Moreover, I suspect that making this more concrete and clear will lead people to donate more and reduce their “excuse driven“ self-justifying reasoning for not donating (see discussion and evidence, e.g. in <span class="citation">(Exley <a href="#ref-exleyExcusingSelfishnessCharitable2016a" role="doc-biblioref">2016</a>)</span>).</p>
</div>
<div id="extending-and-interpreting-work-beyond-the-narrow-statistical-significance-and-academic-reporting" class="section level2 unnumbered" number="">
<h2>3. Extending and interpreting work beyond the ‘narrow statistical significance’ and academic reporting</h2>
<p>I also see value in making efforts to ‘look beyond the light of the streetlamp’, to consider what probabilistic statements we can make about harder-to-measure interventions. We will necessarily have limited evidence, and far less confidence in long-term and indirect effects of programs. While this work is hard to publish in academic Economics journals, it can nonetheless yield great insight in targeting our donation choices. The standard ‘Bayesian policy’ story… ‘When we need to make a decision between A and B, we need to know the preponderance of evidence for A versus B. We do not need to have 99% confidence that the data rejects A in favor of B, nor vice versa’.</p>
</div>
<div id="existing-workunderfunding" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Existing work/(under)funding?</h2>
<p>Several organizations are already doing some of the above work to <em>some</em> extent. However, I believe these remain under-funded and under-achieving.<br />
</p>
<p><strong>Meta-analysis:</strong> I have already noted that <strong>AidGrade</strong> is a strong proof of concept, but it is under-funded and thus limited in many respects. I have done a brief literature review and web search and I have seen no comparable, updated work. For example <a href="https://www.poverty-action.org/">Innovations for Poverty Action</a> does not prominently present any meta-analysis or comparison tool.</p>
<p><br />
</p>
<p><strong>Translation work</strong> (as well as ‘EA-relevant meta-analysis’):</p>
<p>Givewell is the most prominent organization here, and they do strong work. However, their approach is limited in several ways:</p>
<ol style="list-style-type: decimal">
<li><p>There is no clear ‘interactive’ tool I can use to determine my preferred charity considering my beliefs and preferences. The analyses presented are based on their raters’ own <a href="https://www.givewell.org/how-we-work/our-criteria/cost-effectiveness/comparing-moral-weights">“philosophical values”</a></p></li>
<li><p>While they make all of their materials and spreadsheets, and (many) discussions open to the public, the overall organization and presentation makes this hard to track, and hard to interact with. A modern data science perspective could lead to greater transparency and could enable outside researchers and toolmakers to better interact with, use, and inform their work.</p></li>
</ol>
<p>(I discussed this in a recent post on the Rethink Tech projects Slack; unfold if interested.)</p>

<div class="fold">
<p>The Google sheets with GiveWell’s models and evaluations are very much untidy and not as transparent and organised as one might like.
<a href="https://docs.google.com/spreadsheets/d/1zLmPuddUmKsy3v55AfG_e1Quk-ngDdNzW-FDx0T-Y94/edit#gid=1362437801" class="uri">https://docs.google.com/spreadsheets/d/1zLmPuddUmKsy3v55AfG_e1Quk-ngDdNzW-FDx0T-Y94/edit#gid=1362437801</a></p>
<p>Wouldn’t it be a cool collaborative project to try to turn these into a more organised relational database of data matrices, including formulae etc, perhaps building an API etc?</p>
<p>I think this would have a lot of value:</p>
<ul>
<li>In making it clearer to GiveWell and others how their model worked, possibly spotting bugs/anomolies</li>
<li>Making the data more use-able by researchers outside of GiveWell, helping data scientists and academics engage with it…</li>
<li>Foster the building of apps (e.g., personal evaluation tools with your own parameters) based on this data</li>
</ul>
</div>
<p><br />
</p>
<ol start="3" style="list-style-type: decimal">
<li>Limited set of causes/charities analyzed, even within the Global Poverty domain</li>
</ol>
<p>Givewell has largely focused on those interventions and charities that they can most easily evaluate because there has been the most scientific work, the charities’ program are well defined and limited, and the charities have cooperated with their transparency standards. However, for some effective donors with different priorities and values, or those who have the potential to influence donations and policy in other ways (e.g., you may be able to convince your community group to support Oxfam or UNICEF, but not AMF), a broader analysis would be welcome.</p>
<p><br />
</p>
<p><strong><a href="https://www.impactmatters.org/">Impact Matters</a></strong> seems to do a better job in terms of considering a broader set of charities. However, my impression is that their analysis is even less transparent and easy to interact with, allows less customization based on one’s philosophical values, and is somewhat less aligned with EA values.</p>
<p><br />
</p>
</div>
</div>
<div id="limitations" class="section level1" number="7">
<h1><span class="header-section-number">7</span> Overall considerations and limitations; next steps</h1>
<p>This post considered “which category to allocate prioritization research funds in order to achieve the best global poverty outcomes.” In the <a href="#best">prior</a> section, I recommended that this money be used for evaluation, communication, and tailoring of existing empirical intervention effectiveness research.</p>
<p>Overall, it is difficult to asses the benefits of ‘pure thought’ and ‘pure science’, and compare this to more definitive empirical results.
My argument relied mainly on the importance, neglectedness and tractability framework, and on my own experience-driven intuition.</p>
<p>Here are some reasons why my above arguments may be limited, biased, or wrong:</p>
<ul>
<li><p>As an Economist and a (mostly) empirical researcher, I may have limited exposure to the real progress that has been made in philosophical questions in the areas discussed.</p></li>
<li><p>The above discussion is largely based on my impressions rather than careful quantitative study (which I would like to follow up with).</p></li>
<li><p>If certain areas are massively funded it does not mean that they are necessarily underfunded.</p></li>
<li><p>There is already a great deal of movement in the direction of “more credible” results, replication evidence, and Open Science. If this is already heavily funded, EA research funding may not be as impactful.</p></li>
<li><p>Producing analyses and decision tools that incorporate individual donors’ beliefs and preferences may prove difficult. Some of the empirical results (e.g., trading off population versus suffering) may embody great uncertainty. It may be difficult for individuals to express their own preferences in stable ways.</p></li>
<li><p>Although Givewell, Impact matters, and other evaluation/translation organizations are not as transparent and easy to read as I would like, they may already be moving in this direction. It may also be very costly to hire in the sort of expertise (with both quantitative, IT, and communication skills) that could accomplish this.</p></li>
</ul>
<p>Throughout the text above, I have outlined the next steps I would take in addressing and writing about this question. In particular:</p>
<ul>
<li><p>Delve more into the empirical questions, particularly considering existing funding and estimates of the benefits of particular research initiatives</p></li>
<li><p>Broader and more in depth-survey of the philosophical research and it’s impact; similarly for the ‘big empirical crucial considerations’ questions</p></li>
<li><p>Consideration of potential ‘side-benefits’ of each type of research (e.g., contributions to general knowledge and science)</p></li>
<li><p>Further research and engage with organizations and individuals doing the meta-analysis (e.g., Eva Vivalt) and EA-evaluation and translation work (e.g., Givewell and Impact matters); as well as Open Science organisations</p></li>
</ul>

<div class="tip">
In general, the question I addressed in this post was rather broad. This post may be somewhat too long, and if I expanded in the ways proposed, it would be far too long. I would prefer to divide it into smaller sub-questions and tackle each of these separately. I might return to the larger question afterwards, synthesizing this work.
</div>
</div>
<div id="works-cited" class="section level1 unnumbered" number="">
<h1>Works cited</h1>
<div id="refs" class="references hanging-indent">
<div id="ref-DavidBourgetDavid">
<p>“David Bourget &amp; David J. Chalmers, What Do Philosophers Believe? - PhilPapers.” n.d. https://philpapers.org/rec/BOUWDP.</p>
</div>
<div id="ref-dufloFieldExperimentsPractice2020">
<p>Duflo, Esther. 2020. “Field Experiments and the Practice of Policy.” <em>American Economic Review</em> 110 (7): 1952–73.</p>
</div>
<div id="ref-exleyExcusingSelfishnessCharitable2016a">
<p>Exley, Christine L. 2016. “Excusing Selfishness in Charitable Giving: The Role of Risk.” <em>Review of Economic Studies</em>. <a href="https://doi.org/10.1093/restud/rdv051">https://doi.org/10.1093/restud/rdv051</a>.</p>
</div>
<div id="ref-majidResolvingWormWars2019">
<p>Majid, Muhammad Farhan, Su Jin Kang, and Peter J. Hotez. 2019. “Resolving" Worm Wars": An Extended Comparison Review of Findings from Key Economics and Epidemiological Studies.” <em>PLoS Neglected Tropical Diseases</em> 13 (3): e0006940.</p>
</div>
<div id="ref-senPovertyOrdinalApproach1976">
<p>Sen, Amartya. 1976. “Poverty: An Ordinal Approach to Measurement.” <em>Econometrica: Journal of the Econometric Society</em>, 219–31.</p>
</div>
<div id="ref-tarozziMicroloansInsecticidetreatedBednets2014">
<p>Tarozzi, Alessandro, Aprajit Mahajan, Brian Blackburn, Dan Kopf, Lakshmi Krishnan, and Joanne Yoong. 2014. “Micro-Loans, Insecticide-Treated Bednets, and Malaria: Evidence from a Randomized Controlled Trial in Orissa, India.” <em>American Economic Review</em> 104 (7): 1909–41.</p>
</div>
<div id="ref-vivaltHeterogeneousTreatmentEffects2015a">
<p>Vivalt, Eva. 2015. “Heterogeneous Treatment Effects in Impact Evaluation.” <em>American Economic Review</em> 105 (5): 467–70.</p>
</div>
<div id="ref-vivaltHowMuchCan2016">
<p>———. 2016. “How Much Can We Generalize from Impact Evaluations?”</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Transcript of 29 July 2014 talk, available at <a href="http://www.stafforini.com/blog/bostrom/" class="uri">http://www.stafforini.com/blog/bostrom/</a><a href="#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="book_assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
